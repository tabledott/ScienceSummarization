is combined in a manner similar to that used by the local classifier component of TLC.
    With supervised training of up to 70 sentences per sense, performance on three homographs was quite good (88-100% correct); with fewer training examples and semantically related senses, performance on two additional words was less satisfactory (73-77% correct).
    Gale, Church, and Yarowsky (1992a) developed a topical classifier based on Bayesian decision theory.
    The only information the classifier uses is an unordered list of words that co-occur with the target in training examples.
    No other cues, such as part-of-speech tags or word order, are used.
    Leacock, Towel!, and Voorhees (1993) compared this Bayesian classifier with a content vector classifier as used in information retrieval and a neural network with backpropagation.
    The classifiers were compared using different numbers of senses (two, three, or six manually tagged senses of line) and different amounts of training material (50, 100, and 200 ex