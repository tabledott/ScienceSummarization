training with constraints is critical when the amount labeled data is small.
    Figure 4 further strengthens this point.
    In the citations domain, H&amp;W&amp;C+I achieves with 20 labeled samples similar performance to the supervised version without constraints with 300 labeled samples.
    (Grenager et al., 2005) and (Haghighi and Klein, 2006) also report results for semi-supervised learning for these domains.
    However, due to different preprocessing, the comparison is not straightforward.
    For the citation domain, when 20 labeled and 300 unlabeled samples are available, (Grenager et al., 2005) observed an increase from 65.2% to 71.3%.
    Our improvement is from 70.1% to 79.4%.
    For the advertisement domain, they observed no improvement, while our model improves from 68.1% to 74.6% with 20 labeled samples.
    Moreover, we successfully use out-of-domain data (web data) to improve our model, while they report that this data did not improve their unsupervised model.
    (Haghighi and Klein, 2006)