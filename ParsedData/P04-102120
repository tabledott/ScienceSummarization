 and return values at terminal nodes.
    Similar to n-gram TM, for unseen names in open test, ID3 has backoff smoothing, which lies on the default case which returns the most probable value as its best guess for a partial tree path according to the learning set.
    In the case of E2C transliteration, we form a learning vector of 6 attributes by combining 2 left and 2 right letters around the letter of focus ek and 1 previous Chinese unit ck&#8722;1 .
    The process is illustrated in Table 8, where both English and Chinese contexts are used to infer a Chinese character.
    Similarly, 4 attributes combining 1 left, 1 centre and 1 right Chinese character and 1 previous English unit are used for the learning vector in C2E test.
    An aligned bilingual dictionary is needed to build the decision tree.
    To minimize the effects from alignment variation, we use the same alignment results from section 4.
    Two trees are built for two directions, E2C and C2E.
    The results are compared with those 3-gram TM i