 those documents that had been given more than one label in the training data.
    On these documents, the results were again mixed, but Labeled LDA comes out ahead.
    For MacroF1, L-LDA beat SVMs on four datasets, SVMs beat L-LDA on one dataset, and three were a statistical tie.3 On MicroF1, L-LDA did much better than on the larger subset, outperforming on four datasets with the other four a statistical tie.
    It is worth noting that the Yahoo datasets are skewed by construction to contain many documents with highly overlapping content: because each collection is within the same super-class such as &#8220;Arts&#8221;, &#8220;Business&#8221;, etc., each sub-categories&#8217; of the named Yahoo directory categories.
    Numbers in parentheses are standard deviations across runs.
    L-LDA outperforms SVMs on 5 subsets with MacroF1, but on no subsets with MicroF1. vocabularies will naturally overlap a great deal.
    L-LDA&#8217;s credit attribution mechanism is most effective at partitioning semantically d