n(Z) =&#65533; Y )] is estimated, where bEd[&#183;] is the expectation on empirical development corpus distribution.
    While each iteration lowers the Boost loss on the training corpus, a graph of the misclassification rate on the development corpus versus iteration number is a noisy U-shaped curve, rising at later iterations due to overlearning.
    The value of &#945;&#65533; returned word token in our training data.
    We developed a method for quickly identifying such extensionally equivalent feature pairs based on hashing XORed random bitmaps, and deleted all but one of each set of extensionally equivalent features (we kept a feature with the smallest number of conditioning variables). by the estimator is the one that minimizes the misclassficiation rate on the development corpus; typically the minimum is obtained after about 12,000 iterations, and the feature weight vector &#945;&#65533; contains around 8000 nonzero feature weights (since some weights are adjusted more than once).3 This subsection de