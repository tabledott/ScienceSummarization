n-grain model.
    Usually, an n-gram model refers to a Markov process where the probability of a particular token being generating is dependent on the values of the previous n &#8212; 1 tokens generated by the same process.
    By this definition, an n-gram model has I WI&amp;quot; parameters, where IWI is the number of unique tokens generated by the process.
    However, here let's define an n-gram model more loosely as a model which defines a probability distribution on a random variable given the values of n-1 random variables, P(.flhi h2 .
    &#8226; . hn-1).
    There is no assumption in the definition that any of the random variables F or Hi range over the same vocabulary.
    The number of parameters in this n-gram model is IFI H IHil.
    Using this definition, an n-gram model can be represented by a decision-tree model with n &#8212; 1 questions.
    For instance, the part-of-speech tagging model P(t11w2t1&#8212;iti-2) can be interpreted as a 4gram model, where HI is the variable denoting the word 