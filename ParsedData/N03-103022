e use both 18 labels and 110 labels for the discourse relations.
    The recall and precision figures are combined into an F-score figure in the usual manner.
    The discourse parsing model uses syntactic trees produced by Charniak&#8217;s parser (2000) and discourse segments produced by the algorithm described in Section 3.
    We compare the performance of our model ( ) with the performance of the decision-based discourse parsing model ( ) proposed by (Marcu, 2000), and with the performance of a baseline algorithm ( ).
    The baseline algorithm builds right-branching discourse trees labeled with the most frequent relation encountered in the training set (i.e., ELABORATION-NS).
    We also compute the agreement between human annotators on the discourse parsing task ( ), using the doubly-annotated discourse corpus mentioned in Section 2.
    The results are shown in Table 2.
    The baseline algorithm has a performance of 23.4% and 20.7% F-score, when using 18 labels and 110 labels, respectively.
    Our al