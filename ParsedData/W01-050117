
    Furthermore, co-training for base NP identification seems to be quite sensitive to the CT parameter settings.
    For example, with L = 200 the co-training classifiers appear not to be accurate enough to sustain co-training, while with L = 1000, they are too accurate, in the sense that co-training contributes very little accuracy before the labeled data deteriorates (Figure 5).
    In the next sections, we address the problems of data degradation and parameter sensitivity for co-training.
    Corrected Co-Training.
    As shown above, the degradation of the labeled data introduces a scalability problem for co-training because successive view classifiers use successively poorer quality data for training.
    A straightforward solution to this problem is to have a human anized, as co-training achieves 95.03% accuracy, just 0.14% away from the goal, after 600 iterations (and reaches 95.12% after 800 iterations).
    Additionally, the human annotator reviews 6000 examples and corrects only 358.
    Thus, by 