in of 0.6 F-Measure.
    This result suggests that while the link information is useful for improving FMeasure, our improved methods for training are producing much larger improvements.
  
  
    The symmetrized alignments from the last iteration of EMD were used to build phrasal SMT systems, as were the symmetrized Model 4 alignments (the baseline).
    Aside from the final alignment, all other resources were held constant between the baseline and contrastive SMT systems, including those based on lower level alignments models such as IBM Model 1.
    For all of our experiments, we use two language models, one built using the English portion of the training data and the other built using additional English news data.
    We run Maximum BLEU (Och, 2003) for 25 iterations individually for each system.
    Table 8 shows our results.
    We report BLEU (Papineni et al., 2001) multiplied by 100.
    We also show the F-measure after heuristic symmetrization of the alignment test sets.
    The table shows that 4We w