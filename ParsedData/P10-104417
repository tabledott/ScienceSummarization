the corpus as well as the number of topics.
    In addition, there are several scalability enhancements such as SparseLDA (Yao et al., 2009), and an approximation of the Gibbs Sampling procedure can be efficiently parallelized (Newman et al., 2009).
    Finally we note that, once a topic distribution has been learned over a set of training relations, one can efficiently apply inference to unseen relations (Yao et al., 2009).
  
  
    We perform three main experiments to assess the quality of the preferences obtained using topic models.
    The first is a task-independent evaluation using a pseudo-disambiguation experiment (Section 4.2), which is a standard way to evaluate the quality of selectional preferences (Rooth et al., 1999; Erk, 2007; Bergsma et al., 2008).
    We use this experiment to compare the various topic models as well as the best model with the known state of the art approaches to selectional preferences.
    Secondly, we show significant improvements to performance at an end-task of textual 