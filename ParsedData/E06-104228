valuate the system and to arrive at an optimal configuration.
    Through our enhancements we were able to produce results that are, on average, 16.9% higher than the core algorithm and 24.4% higher than the baseline.
    Finally, we used our optimal configuration of TroFi, together with active learning and iterative augmentation, to build the TroFi Example Base, a publicly available, expandable resource of literal/nonliteral usage clusters that we hope will be useful not only for future research in the field of nonliteral language processing, but also as training data for other statistical NLP tasks.
  

