ours.
    Additionally, the performance of perceptron-trained HMMs is very competitive on a number of tasks; e.g., in shallow parsing, where Algorithm 1 Hidden Markov average perceptron algorithm. the perceptron performance is comparable to that of Conditional Random Field models (Sha and Pereira, 2003), The tendency to overfit of the perceptron can be mitigated in a number of ways including regularization and voting.
    Here we apply averaging and straightforwardly extended Collins algorithm, summarized in Algorithm 1.
    We used the following combination of spelling/morphological and contextual features.
    For each observed word xi in the data &#65533; extracts the following features: described below.
    In addition sh; = low if the first character of xi is lowercase, sh; = cap brk if the first character of xi is uppercase and xi&#8722;1 is a full stop, question or exclamation mark, or xi is the first word of the sentence, sh; = cap nobrk otherwise; Word features (1) are morphologically simplified usin