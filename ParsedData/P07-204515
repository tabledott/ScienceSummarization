ents with confusion networks, we have focused so far on the speech translation case, where the input is generated by a speech recognizer.
    Namely, our goal is to improve performance of spoken language translation by better integrating speech recognition and machine translation models.
    Translation from speech input is considered more difficult than translation from text for several reasons.
    Spoken language has many styles and genres, such as, formal read speech, unplanned speeches, interviews, spontaneous conversations; it produces less controlled language, presenting more relaxed syntax and spontaneous speech phenomena.
    Finally, translation of spoken language is prone to speech recognition errors, which can possibly corrupt the syntax and the meaning of the input.
    There is also empirical evidence that better translations can be obtained from transcriptions of the speech recognizer which resulted in lower scores.
    This suggests that improvements can be achieved by applying machine transla