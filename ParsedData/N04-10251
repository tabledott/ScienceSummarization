ables such as type-token ratio gave the best performance on commercial calibrated test passages, while our language modeling approach gave better accuracy for Web documents and very short passages (less than 10 words).
  
  
    In the course of constructing a search engine for students, we wanted a method for retrieving Web pages that were not only relevant to a student's query, but also well-matched to their reading ability.
    Widely-used traditional readability formulas such as Flesch-Kincaid usually perform poorly in this scenario.
    Such formulas make certain assumptions about the text: for example, that the sample has at least 100 words and uses welldefined sentences.
    Neither of these assumptions need be true for Web pages or other non-traditional documents.
    We seek a more robust technique for predicting reading difficulty that works well on a wide variety of document types.
    To do this, we turn to simple techniques from statistical language modeling.
    Advances in this field in the pas