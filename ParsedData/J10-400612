it runs the risk of overfitting the model to a specific task, while losing sight of its adaptivity&#8212;a highly desirable feature for any intelligent system.
    Think, by contrast, of WordNet (Fellbaum 1998), a single, general purpose network of semantic information that has been adapted to all sorts of tasks, many of them certainly not envisaged by the resource creators.
    We think that it is not by chance that no comparable resource has emerged from DSM development.
    In this article, we want to show that a unified approach is not only a desirable goal, but it is also a feasible one.
    With this aim in mind, we introduce Distributional Memory (DM), a generalized framework for distributional semantics.
    Differently from other current proposals that share similar aims, we believe that the lack of generalization in corpus-based semantics stems from the choice of representing co-occurrence statistics directly as matrices&#8212;geometrical objects that model distributional data in terms of binary rel