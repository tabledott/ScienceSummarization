e used the results of the manual evaluation to analyze the translation quality of the different systems that were submitted to the workshop.
    In our analysis, we aimed to address the following questions: Table 6 shows best individual systems.
    We define the best systems as those which had no other system that was statistically significantly better than them under the Sign Test at p G 0.1.4 Multiple systems are listed for many language pairs because it was not possible to draw a statistically significant difference between the systems.
    Commercial translation software (including Google, Systran, Morphologic, PCTrans, Eurotran XP, and anonymized RBMT providers) did well in each of the language pairs.
    Research systems that utilized 4In one case this definition meant that the system that was ranked the highest overall was not considered to be one of the best systems.
    For German-English translation RBMT5 was ranked highest overall, but was statistically significantly worse than RBMT2. only the pro