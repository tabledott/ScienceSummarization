ential sources of error.
    Evaluation is based on the corpora described in the algorithm's Step 2.
    In all experiments, 4/5 of the data was used for training and the remaining 1/5 held out for testing.
    More accurate measures of algorithm performance were obtained by repeating each experiment 5 times, using a different 1/5 of the data for each test, and averaging the results.
    Note that in every experiment, results were measured on independent test data not seen in the training phase.
    It should be emphasized that the actual percent correct is higher than these agreement figures, due to errors in the original corpus.
    The relatively low agreement rate on words with accented i's (1) is a result of this.
    To study this discrepancy further, a human judge fluent in Spanish determined whether the corpus or decision list algorithm was correct in two cases of disagreement.
    For the ambiguity case of mi/mi, the corpus was incorrect in 46% of the disputed tokens.
    For the ambiguity anunciol a