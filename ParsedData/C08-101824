each CFG production or delete up to two of its children.
			This is illustrated in Table 2 where the last two rules are derived from the CFG production NP?DT NN inthe source tree.
			All trees are rooted with a distinguished TOP non-terminal which allows the ex plicit modelling of sentence spanning sub-trees.
			These grammars each had 44,199 (pivot), 7,813 (train) and 22,555 (copy) rules.
			We took their union, resulting in 58,281 unique rules and 13,619 unique source elementary trees.
			Model Parameters Our model was trainedon 480 sentences, 36 sentences were used for de velopment and 59 for testing.
			We used a variety of syntax-based, lexical and compression-specific 6 The software and corpus can be downloaded from http://homepages.inf.ed.ac.uk/tcohn/paraphrase.
			For every rule: origin of rule for each origin, o: log p o (s, t), log p o (s|t), log p o (t|s) s R , t R , s R ? t R s, t, s ? t, s = t both s and t are pre-terminals and s = t or s 6= t number of terminals/variables/dropped variables order