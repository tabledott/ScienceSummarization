ly overgeneralize.
    Hierarchical clusters provide one way around the problem by avoiding commitment to any particular granularity in advance.
    However, the dominant trend during the past decade toward generative models has made integration of such hierarchical clusters difficult.
    Because the nested clusters surrounding each word are highly correlated, it is unreasonable to treat them as independent.
    Unfortunately, any treatment in a generative framework other than independent requires considerable ingenuity.
    Interestingly, before generative models began to dominate parsing, the Spatter parser (Magerman, 1995) achieved extremely promising results using a nongenerative statistical model.
    Of particular interest is the fact that Spatter used hierarchical word clusters for estimating its lexical attachment probabilities.
    However, the statistical decision trees underlying Spatter&#8217;s probability model never gained widespread acceptance, and indeed, our own limited experience with them 