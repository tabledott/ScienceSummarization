 the candidate translation.
    To prevent very short translations that try to maximize their precision scores, BLEU adds a brevity penalty, BP, to the formula: Where |c |is the length of the candidate translation and |r |is the length of the reference translation.
    The BLEU formula is then written as follows: N is set at 4 and wn, the weighting factor, is set at 1/N.
    For summaries by analogy, we can express equation (1) in terms of n-gram matches following equation (2): Where Countmatch(n-gram) is the maximum number of n-grams co-occurring in a peer summary and a model unit and Count(n-gram) is the number of n-grams in the model unit.
    Notice that the average n-gram coverage score, Cn, as shown in equation 5 is a recall metric 8 The number of instances is 14 (11 systems, 2 humans, and 1 baseline) for the single document task and is 16 (12 systems, 2 humans, and 2 baselines) for the multi-document task. ings versus human ranking for the multidocument task data from DUC 2001.
    The same system is a