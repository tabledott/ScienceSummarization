 More precisely, the statistical methods we use do not seem to be effective on low frequency words (fewer than 100 occurrences).
    If the word is not frequently used in the corpus or if the corpus is too small, then the distribution of its collocates will not be big enough.
    For example, from AP, which contains about 1,000 occurrences of the word &amp;quot;rain,&amp;quot; Xtract produced over 170 collocations at stage 1 involving it.
    In contrast, DJ only contains some 50 occurrences of &amp;quot;rain&amp;quot;' and Xtract could only produce a few collocations with it.
    Some collocations with &amp;quot;rain&amp;quot; and &amp;quot;hurricane&amp;quot; extracted from AP are listed in Figure 15.
    Both words are high-frequency words in AP and low-frequency words in DJ.
    In short, to build a lexicon for a computational linguistics application in a given domain, one should make sure that the important words in the domain are frequent enough in the corpus.
    For a subdomain of the stock market des