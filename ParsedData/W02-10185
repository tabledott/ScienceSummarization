.
    We briefly describe a decoding algorithm that works in conjunction with our model (Section 4) and evaluate the performance of a translation system that uses the joint-probability model (Section 5).
    We end with a discussion of the strengths and weaknesses of our model as compared to other models proposed in the literature.
    2 A Phrase-Based Joint Probability Model 2.1 Model 1 In developing our joint probability model, we started out with a very simple generative story.
    We assume that each sentence pair in our corpus is generated by the following stochastic process: 1.
    Generate a bag of concepts.
    2.
    For each concept , generate a pair of phrases , according to the distribution contain at least one word.
    3.
    Order the phrases generated in each language so as to create two linear sequences of phrases; these sequences correspond to the sentence pairs in a bilingual corpus.
    For simplicity, we initially assume that the bag of concepts and the ordering of the generated phrases a