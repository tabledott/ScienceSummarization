From a theoretical perspective, corpusbased models hold promise as large-scale simulations of how humans acquire and use conceptual and linguistic information from their environment (Landauer and Dumais 1997).
    However, existing DSMs lack exactly the multi-purpose nature that is a hallmark of human semantic competence.
    The common view in cognitive (neuro)science is that humans resort to a single semantic memory, a relatively stable long-term knowledge database, adapting the information stored there to the various tasks at hand (Murphy 2002; Rogers and McClelland 2004).
    The fact that DSMs need to go back to their environment (the corpus) to collect ad hoc statistics for each semantic task, and the fact that different aspects of meaning require highly different distributional representations, cast many shadows on the plausibility of DSMs as general models of semantic memory.
    From a practical perspective, going back to the corpus to train a different model for each application is inefficient, and 