man judgments when translating into English, with MaxSim and RTE following closely behind.
    TERp and wpBleu were best when translating into other languages.
    Automatically predicting human judgments at the sentence-level proved to be quite challenging with many of the systems performing around chance.
    We performed an analysis that showed that if metrics&#8217; system-level scores are used in place of their scores for individual sentences, that they do quite a lot better.
    This suggests that prior probabilities ought to be integrated into sentencelevel scoring.
    All data sets generated by this workshop, including the human judgments, system translations and automatic scores, are publicly available for other researchers to analyze.8
  
  
    This work was supported in parts by the EuroMatrix project funded by the European Commission (6th Framework Programme), the GALE program of the US Defense Advanced Research Projects Agency, Contract No.
    HR0011-06-C-0022, and the US National Science Foun