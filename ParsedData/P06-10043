dagogical considerations call for fluent transitions between different topics in a lecture, further complicating the segmentation task.
    Our experimental results confirm our hypothesis: considering long-distance lexical dependencies yields substantial gains in segmentation performance.
    Our graph-theoretic approach compares favorably to state-of-the-art segmentation algorithms and attains results close to the range of human agreement scores.
    Another attractive property of the algorithm is its robustness to noise: the accuracy of our algorithm does not deteriorate significantly when applied to speech recognition output.
  
  
    Most unsupervised algorithms assume that fragments of text with homogeneous lexical distribution correspond to topically coherent segments.
    Previous research has analyzed various facets of lexical distribution, including lexical weighting, similarity computation, and smoothing (Hearst, 1994; Utiyama and Isahara, 2001; Choi, 2000; Reynar, 1998; Kehagias et al., 2003; Ji a