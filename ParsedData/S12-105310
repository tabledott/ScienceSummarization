t when German T1s are translated into English.
    The comparison with baselines results leads to interesting observations.
    First of all, while all systems significantly outperform the lowest 1-class baseline (0.25), both other baselines are surprisingly hard to beat.
    This shows that, despite the effort in keeping the distribution of the entailment classes uniform across different length diff values, eliminating the correlation between sentences&#8217; length and correct entailment decisions is difficult.
    As a consequence, although disregarding semantic aspects of the problem, features considering such information are quite effective.
    In general, systems performed better on the SPEN dataset, with most results above the binary baseline (8 out of 10), and half of the systems above the multi-class baseline.
    For the other language pairs the results are lower, with only 3 out of 8 participants above the two baselines in all datasets.
    Average results reflect this situation: the average score