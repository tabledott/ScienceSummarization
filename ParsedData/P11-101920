ner, E2 to the second etc. to the upper bound for the task.
    Human&#8211;machine agreement is comparable to that of human&#8211;human agreement, with the exception of Pearson&#8217;s correlation with examiner E4 and Spearman&#8217;s correlation with examiners E1 and E4, where the discrepancies are higher.
    It is likely that a larger training set and/or more consistent grading of the existing training data would help to close this gap.
    However, our system is not measuring some properties of the scripts, such as discourse cohesion or relevance to the prompt eliciting the text, that examiners will take into account.
  
  
    The practical utility of an AA system will depend strongly on its robustness to subversion by writers who understand something of its workings and attempt to exploit this to maximise their scores (independently of their underlying ability).
    Surprisingly, there is very little published data on the robustness of existing systems.
    However, Powers et al. (2002) invited writing