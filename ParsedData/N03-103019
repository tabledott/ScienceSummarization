he metric we use to evaluate the discourse segmenter records the accuracy of the discourse segmenter with respect to its ability to insert inside-sentence discourse boundaries.
    That is, if a sentence has 3 edus, which correspond to 2 inside-sentence discourse boundaries, we measure the ability of our algorithm to correctly identify these 2 boundaries.
    We report our evaluation results using recall, precision, and Fscore figures.
    This metric is harsher than the metric previously used by Marcu (2000), who assesses the performance of a discourse segmentation algorithm by counting how often the algorithm makes boundary and noboundary decisions for every word in a sentence.
    We compare the performance of our probabilistic discourse segmenter with the performance of the decisionbased segmenter proposed by (Marcu, 2000) and the performance of two baseline algorithms.
    The first baseline ( ) uses punctuation to determine when to insert a boundary; because commas are often used to indicate breaks insi