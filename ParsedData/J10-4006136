deled with different, prima facie incompatible data structures; (2) using this common representation to address a large battery of semantic experiments, achieving a performance at least comparable to that of state-of-art, taskspecific DSMs.
    We can now safely claim that DM satisfies both these desiderata, and thereby represents a genuine step forward in the quest for a general purpose approach to distributional semantics.
    DM addresses point (1) by modeling distributional data as a structure of weighted tuples that is formalized as a labeled third-order tensor.
    This is a generalization with respect to the common approach of many corpus-based semantic models (the structured DSMs) that rely on distributional information encoded into word&#8211;link&#8211;word tuples, associated with weights that are functions of their frequency of co-occurrence in the corpus.
    Existing structured DSMs still couch this information directly in binary structures, namely, co-occurrence matrices, thereby giving rise to 