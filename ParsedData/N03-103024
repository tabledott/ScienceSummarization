;s parser at 90% accuracy ( ) with the corresponding Penn Treebank syntactic parse trees produced by human annotators ( ).
    We also replace the discourse boundaries produced by our discourse segmenter at 83% accuracy ( ) with the discourse boundaries taken from (RST-DT, 2002), which are produced by the human annotators ( ).
    The results are shown in Table 3.
    The results in column show that using perfect syntactic trees leads to an error reduction of 14.5% (F-score improvement from 49.0% to 56.4%) when using 18 labels, and an error reduction of 12.9% (F-score improvement from 45.6% to 52.6%) when using 110 labels.
    The results in column show that the impact of perfect discourse segmentation is double the impact of perfect syntactic trees.
    Human-level performance on discourse segmentation leads to an error reduction of 29.0% (F-score improvement from 49.0% to 63.8%) when using 18 labels, and an error reduction of 25.6% (F-score improvement from 45.6% to 59.5%) when using 110 labels.
    Togethe