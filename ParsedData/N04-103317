res the words in the two sentences ignoring the word order.
    This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences (Papineni et al., 2001).
    BLEU measures accuracy, i.e. large BLEU scores are better.
    This score is similar to BLEU.
    It is a weighted ngram precision in combination with a penalty for too short sentences (Doddington, 2002).
    NIST measures accuracy, i.e. large NIST scores are better.
    For the Verbmobil task, we have multiple references available.
    Therefore on this task, we compute all the preceding criteria with respect to multiple references.
    To indicate this, we will precede the acronyms with an m (multiple) if multiple references are used.
    For the other two tasks, only single references are used.
    In this section, we will describe the systems that were used.
    On the one hand, we have three different variants of the single-word based model IBM4.
    On the 