 about other cooccurrences that were observed in the corpus, and contain words that are similar to the given ones.
    For example, to estimate the probability of the unobserved cooccurrence 'negative results', we use cooccurrences such as 'positive results' and 'negative numbers', that do occur in our corpus.
    The analogies we make are based on the assumption that similar word cooccurrences have similar values of mutual information.
    Accordingly, our similarity metric was developed to capture similarities between vectors of mutual information values.
    In addition, we use an efficient search heuristic to identify the most similar words for a given word, thus making the method computationally affordable.
    Figure 1 illustrates a portion of the similarity network induced by the similarity metric (only some of the edges, with relatively high values, are shown).
    This network may be found useful for other purposes, independently of the estimation method.
    The estimation method was implemented usi