arison with State-of-the-Art Methods.
    We compared the performance of our algorithm against two state-of-the-art models proposed by Foltz, Kintsch, and Landauer (1998) and Barzilay and Lee (2004).
    These models rely largely on lexical information for assessing document coherence, contrary to our models which are in essence unlexicalized.
    Recall from Section 3 that our approach captures local coherence by modeling patterns of entity distribution in discourse, without taking note of their lexical instantiations.
    In the following we briefly describe the lexicalized models we employed in our comparative study and motivate their selection.
    Foltz, Kintsch, and Landauer (1998) model measures coherence as a function of semantic relatedness between adjacent sentences.
    The underlying intuition here is that coherent texts will contain a high number of semantically related words.
    Semantic relatedness is computed automatically using Latent Semantic Analysis (LSA; Landauer and Dumais 1997) from ra