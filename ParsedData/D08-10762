ting the model parameters such that the decision under the zero-one loss function maximizes some end-to-end performance measure on a development corpus.
    In combination with log-linear models, the training procedure allows for a direct optimization of the unsmoothed error count.
    The criterion can be derived from Bayes&#8217; decision rule as follows: Let ff1, ..., fi denote a source sentence (&#8217;French&#8217;) which is to be translated into a target sentence (&#8217;English&#8217;) ee1, ..., eI.
    Under the zero-one loss function, the translation which maximizes the a posteriori probability is chosen: earg max Prpe|fq( (1) e Since the true posterior distribution is unknown, Prpe|fqis modeled via a log-linear translation model which combines some feature functions hmpe, fq ) with feature function weights am, m~1, ..., M: The feature function weights are the parameters of the model, and the objective of the MERT criterion is to find a parameter set aM that minimizes the error count on a representat