er of this paper, we will adopt the simple but arbitrary threshold, and ignore pairs with small counts.
    Technically, the association ratio is different from mutual information in two respects.
    First, joint probabilities are supposed to be symmetric: P(x,y)= P(y,x), and thus, mutual information is also symmetric: 1(x,y) = 1(y ,x).
    However, the association ratio is not symmetric, since f(x,y) encodes linear precedence.
    (Recall that f(x,y) denotes the number of times that word x appears before y in the window of w words, not the number of times the two words appear in either order.)
    Although we could fix this problem by redefining f(x,y) to be symmetric (by averaging the matrix with its transpose), we have decided not to do so, since order information appears to be very interesting.
    Notice the asymmetry in the pairs below (computed from 36 million words of 1988 AP text), illustrating a wide variety of biases ranging from sexism to syntax.
    Some Un-interesting Associations with &amp;quo