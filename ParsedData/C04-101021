he F-score drops to 95.7%.
			The corre sponding F-measures for our best parser (Model 2, BG) are 99.0% and 94.7%.
			For the larger B set, our best parser achieves an F-measure of 96.9% (DEP labels included), which can be compared with 97.0% for a similar (but larger) set of labels inCollins (1999).6 Although none of the previous re sults on labeling accuracy is strictly comparable to ours, it nevertheless seems fair to conclude that the 6This F-measure is based on the recall and precision figures reported in Figure 7.15 in Collins (1999).
			Model 1 Model 2 G B BG G B BG UAS 86.4 86.7 85.8 87.1 LAS 85.3 84.0 85.5 84.6 84.4 86.0 Table 1: Parsing accuracy: Attachment score (BG = evaluation of B restricted to G labels) DA RA CM Charniak 92.1 95.2 45.2 Collins 91.5 95.2 43.3 Yamada  Matsumoto 90.3 91.6 38.4 Nivre  Scholz 87.3 84.3 30.4 Table 2: Comparison with related work (Yamada and Matsumoto, 2003) labeling accuracy of the present parser is close to the state of the art, even if its capacity to derive correc