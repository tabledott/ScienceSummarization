option 3 are determined in a similar manner, but different accuracy figures are computed for each part-of-speech.
    Table 1 shows the dependency accuracy and root accuracy (number of times the root of the dependency tree was identified correctly divided by the number of sentences) for each of the parsers, and for each of the different weight settings in the reparsing experiments (numbered according to their descriptions above).
    The parsers that were used in the constituent reparsing experiments are: (1) Charniak and Johnson&#8217;s (2005) reranking parser; (2) Henderson&#8217;s (2004) synchronous neural network parser; (3) Bikel&#8217;s (2002) implementation of the Collins (1999) model 2 parser; and (4) two versions of Sagae and Lavie&#8217;s (2005) shift-reduce parser, one using a maximum entropy classifier, and one using support vector machines.
    Henderson and Brill&#8217;s voting scheme mentioned in section 3 can be emulated by our reparsing approach by setting all weights to 1.0 and t to (m + 1)/