reated by combining models trained on the Arabic side of the parallel training data (347 million tokens), the ar gigaword and ar webnews data sets, and additional Arabic web data.
    As shown in Table 3, adding the predictive classbased model trained on the ar webnews data set leads to small improvements in dev and nist06 scores but causes the test score to decrease.
    However, adding the class-based model trained on the ar gigaword data set to the other class-based and the word-based model results in further improvement of the dev score, but also in large improvements of the test and nist06 scores.
    We performed experiments to eliminate the possibility of data overlap between the training data and the machine translation test data as cause for the large improvements.
    In addition, our experiments showed that when there is overlap between the training and test data, the class-based models lead to lower scores as long as they are trained only on data also used for training the word-based model.
    On