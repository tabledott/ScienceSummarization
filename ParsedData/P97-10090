
  Using Syntactic Dependency As Local Context To Resolve Word Sense Ambiguity
  
    Most previous corpus-based algorithms disambiguate a word with a classifier trained from previous usages of the same word.
    Separate classifiers have to be trained for different words.
    We present an algorithm that uses the same knowledge sources to disambiguate different words.
    The algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts.
  
  
    Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context.
    WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution.
    In several recent proposals (Hearst, 1991; Bruce and Wiebe, 1994; Leacock, Towwell, and Voorhees, 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1994), statisti