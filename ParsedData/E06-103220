ith Bleu using a set of 2,000 held out sentence pairs, using the same normalization and tokenization schemes on both systems&#8217; output.
    We then built a number of SMT systems with various portions of the training corpus, and selected one that was trained with 1 of the data, which had a Bleu score that was close to, but still higher than that for the rule-based system.
    We then performed a manual evaluation where we had three judges assign fluency and adequacy ratings for the English translations of 300 French sentences for each of the three systems.
    These scores are plotted against the systems&#8217; Bleu scores in Figure 4.
    The graph shows that the Bleu score for the rule-based system (Systran) vastly underestimates its actual quality.
    This serves as another significant counter-example to Bleu&#8217;s correlation with human judgments of translation quality, and further increases the concern that Bleu may not be appropriate for comparing systems which employ different translation strateg