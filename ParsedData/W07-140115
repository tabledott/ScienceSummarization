f the pairs in the dataset were removed from the test set due to disagreement.
    The disagreement was generally due to the fact that the h was more specific than the t, for example because it contained more information, or made an absolute assertion where t proposed only a personal opinion.
    In addition, 9.4 % of the remaining pairs were discarded, as they seemed controversial, too difficult, or too similar when compared to other pairs.
    As far as the texts extracted from the web are concerned, spelling and punctuation errors were sometimes fixed by the annotators, but no major change was allowed, so that the language could be grammatically and stylistically imperfect.
    The hypotheses were finally double-checked by a native English speaker.
  
  
    The evaluation of all runs submitted in RTE-3 was automatic.
    The judgments (classifications) returned by the system were compared to the Gold Standard compiled by the human assessors.
    The main evaluation measure was accuracy, i.e. the percentag