nstrate the competitiveness of this approach: We used a parallel English-French corpus containing 1.5 million sentences of Microsoft technical data (e.g., support articles, product documentation).
    We selected a cleaner subset of this data by eliminating sentences with XML or HTML tags as well as very long (&gt;160 characters) and very short (&lt;40 characters) sentences.
    We held out 2,000 sentences for development testing and parameter tuning, 10,000 sentences for testing, and 250 sentences for lambda training.
    We ran experiments on subsets of the training data ranging from 1,000 to 300,000 sentences.
    Table 4.1 presents details about this dataset.
    We parsed the source (English) side of the corpus using NLPWIN, a broad-coverage rule-based parser developed at Microsoft Research able to produce syntactic analyses at varying levels of depth (Heidorn, 02).
    For the purposes of these experiments we used a dependency tree output with part-of-speech tags and unstemmed surface words.
    For wor