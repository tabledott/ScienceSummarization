el under a two-tailed paired t-test.
    Table 5.2 compares Pharaoh and the Treelet system at different phrase sizes.
    While all the differences are statistically significant at the 99% confidence level, the wide gap at smaller phrase sizes is particularly striking.
    We infer that whereas Pharaoh depends heavily on long phrases to encapsulate reordering, our dependency treebased ordering model enables credible performance even with single-word &#8216;phrases&#8217;.
    We conjecture that in a language pair with large-scale ordering differences, such as English-Japanese, even long phrases are unlikely to capture the necessary reorderings, whereas our tree-based ordering model may prove more robust.
    Table 5.3 compares the same systems at different training corpus sizes.
    All of the differences are statistically significant at the 99% confidence level.
    Noting that the gap widens at smaller corpus sizes, we suggest that our tree-based approach is more suitable than string-based phrasal SMT when 