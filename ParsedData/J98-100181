nd in some cases worse than chance (see also Ahlswede [1992, 19931, Ahlswede and Lorand [19931).
    Jorgensen (1990) found the level of agreement in her experiment using data from the Brown Corpus to be about 68%.
    The difficulty of comparing results in WSD research has recently become a concern within the community, and efforts are underway to develop strategies for evaluation of WSD.
    Gale, Church, and Yarowsky (1992b) attempt to establish lower and upper bounds for evaluating the performance of WSD systems; their proposal for overcoming the problem of agreement among human judges in order to establish an upper bound provides a starting point, but it has not been widely discussed or implemented.
    A recent discussion at a workshop sponsored by the ACL Special Interest Group on the Lexicon (SIGLEX) on &amp;quot;Evaluating Automatic Semantic Taggers&amp;quot; (Resnik and Yarowsky [1997a]; see also Resnik and Yarowsky [1997b], Kilgarriff [19971) has sparked the formation of an evaluation effort for WS