: if the words that occur rarely in a corpus are found to be distributionally similar to more frequently occurring words, then one may be able to make better inferences on rare words.
    However, to unleash the real power of clustering one has to work with large amounts of text.
    The NLP community has started working on noun clustering on a few gigabytes of newspaper text.
    But with the rapidly growing amount of raw text available on the web, one could improve clustering performance by carefully harnessing its power.
    A core component of most clustering algorithms used in the NLP community is the creation of a similarity matrix.
    These algorithms are of complexity O(n2k), where n is the number of unique nouns and k is the feature set length.
    These algorithms are thus not readily scalable, and limit the size of corpus manageable in practice to a few gigabytes.
    Clustering algorithms for words generally use the cosine distance for their similarity calculation (Salton and McGill, 1983).
    H