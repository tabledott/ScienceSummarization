ensively rely on lexico-semantic resources (Haghighi et al., 2005; Harabagiu et al., 2001), and we believe that our method for contextual substitution can be beneficial in that context.
    Automatic Evaluation Measures A variety of automatic evaluation methods have been recently proposed in the machine translation community (NIST, 2002; Melamed et al., 2003; Papineni et al., 2002).
    All these metrics compute n-gram overlap between a reference and a system output, but measure the overlap in different ways.
    Our method for reference paraphrasing can be combined with any of these metrics.
    In this paper, we report experiments with BLEU due to its wide use in the machine translation community.
    Recently, researchers have explored additional knowledge sources that could enhance automatic evaluation.
    Examples of such knowledge sources include stemming and TF-IDF weighting (Babych and Hartley, 2004; Banerjee and Lavie, 2005).
    Our work complements these approaches: we focus on the impact of parap