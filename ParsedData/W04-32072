ent.
    It might also be beneficial to include the predictions of an L parser, trained on any available annotated L data, however few.
    This paper describes how simple, commonly understood statistical models&#8212;statistical dependency parsers, probabilistic context-free grammars (PCFGs), and word translation models (TMs)&#8212;can be effectively combined into a unified framework that jointly searches for the best English parse, L parse, and word alignment, where these hidden structures are all constrained to be consistent.
    This inference task is carried out by a bilingual parser.
    At present, the model used for parsing is completely factored into the two parsers and the TM, allowing separate parameter estimation.
    First, we discuss bilingual parsing (&#167;2) and show how it can solve the problem of joint English-parse, L-parse, and word-alignment inference.
    In &#167;3 we describe parameter estimation for each of the factored models, including novel applications of log-linear models to Eng