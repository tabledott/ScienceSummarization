 and observe an small improvement in the performance.
    Next, we add all part-of-speech based features and observe a gain of 3.28% over the unigram baseline.
    We see an additional increase in accuracy by 0.64% when we add other prior polarity features (rows f2, f3, f4, f9 in Table 4).
    These results are in line with our observations for the 2-way classification task.
    Once again, the main contribution comes from features that involve prior polarity of parts-ofspeech.
    The top ranked unigram features for the 3-way classification task are mostly similar to that of the 2-way classification task, except several terms with neutral polarity appear to be discriminative features, such as to, have, and so.
  
  
    We presented results for sentiment analysis on Twitter.
    We use previously proposed state-of-the-art unigram model as our baseline and report an overall gain of over 4% for two classification tasks: a binary, positive versus negative and a 3-way positive versus negative versus neutral.
   