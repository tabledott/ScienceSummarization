ttle computational effort to induce and to apply.
    In addition to the quantitative differences between the word-to-word model and the IBM model, there is an important qualitative difference, illustrated in Figure 6.
    As shown in Table 1, the most common kind of error for the word-to-word model was a missing link, whereas the most common error for IBM's Model 2 was a wrong link.
    Missing links are more informative: they indicate where the model has failed.
    The level at which the model trusts its own judgement can be varied directly by changing the likelihood cutoff in Step 1 of the competitive linking algorithm.
    Each application of the word-to-word model can choose its own balance between link token precision and recall.
    An application that calls on the word-to-word model to link words in a bitext could treat unlinked words differently from linked words, and avoid basing subsequent decisions on uncertain inputs.
    It is not clear how the precision/recall tradeoff can be controlled in the