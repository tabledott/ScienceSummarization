 GSSN parsers at the very end of training did not result in any improvement on this task.
    This suggests that at least some of the advantage of the DSSN models is due to the fact that re-ranking is a simpler task than parsing from scratch.
    But additional experimental work would be necessary to make any definite conclusions about this issue.
    For comparison to previous results, table 2 lists the results for our best model (DGSSNFreq&gt;20, rerank)9 and several other statistical parsers (Ratnaparkhi, 1999; Collins, 1999; Collins and Duffy, 2002; Charniak, 2000; Collins, 2000; Bod, 2003) on the entire testing set.
    Our best performing model is more accurate than all these previous models except (Bod, 2003).
    This DGSSN parser achieves this result using much less lexical knowledge than other approaches, which mostly use at least the words which occur at least 5 times, plus morphological features of the remaining words.
    However, the fact that the DGSSN uses a large-vocabulary tagger (Ratnaparkh