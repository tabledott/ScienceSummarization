e average segment length, clue words, named entities, and so on (Reynar, 1999; Beeferman et al., 1999).
    Our proposed algorithm naturally estimates the probabilities of words in segments.
    These probabilities, which are called word densities, have been used to detect important descriptions of words in texts (Kurohashi et al., 1997).
    This method is based on the assumption that the density of a word is high in a segment in which the word is discussed (defined and/or explained) in some depth.
    It would be interesting to apply our method to this application.
  
  
    We have proposed a statistical model for domainindependent text segmentation.
    This method finds the maximum-probability segmentation of a given text.
    The method has been shown to be more accurate than or at least as accurate as previous methods.
    We are planning to build a segmentation corpus for Japanese and evaluate our method against this corpus.
  
  
    We thank Freddy Y. Y. Choi for his text segmentation package.
  

