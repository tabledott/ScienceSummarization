ataset.
    As a concrete example, consider the excerpt of text from the del.icio.us dataset in Figure 5.
    The document itself has several tags, including design and programming.
    Initially, many of the likelihood probabilities p(wllabel) for the (content) words in this excerpt are higher for the label programming than design, including &#8220;content&#8221;, &#8220;client&#8221;, &#8220;CMS&#8221; and even &#8220;designed&#8221;, while design has higher likelihoods for just &#8220;website&#8221; and &#8220;happy&#8221;.
    However, after performing inference on this document using L-LDA, the inferred document probability for design (p(design)) is much higher than it is for programming.
    In fact, the higher probability for the tag more than makes up the difference in the likelihood for all the words except &#8220;CMS&#8221; (Content Management System), so underline) words are generated from the design tag; red (dashed underline) from the programming tag.
    By themselves, most words used here have 