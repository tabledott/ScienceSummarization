, collocations, and mappings between them.
    The quality of an NLG system depends on the quality of its inputs and knowledge bases.
    Given that perfect KBs do not yet exist, an important question arises: can we build high-quality NLG systems that are robust against incomplete KBs and inputs?
    Although robustness has been heavily studied in natural language understanding (Weischedel and Black, 1980; Hayes, 1981; Lavie, 1994), it has received much less attention in NLG (Robin, 1995).
    We describe a hybrid model for natural language generation which offers improved performance in the presence of knowledge gaps in the generator (the grammar and the lexicon), and of errors in the semantic input.
    The model comes out of our practical experience in building a large Japanese-English newspaper machine translation system, JAPANGLOSS (Knight et al., 1994; Knight et al., 1995).
    This system translates Japanese into representations whose terms are drawn from the SENSUS ontology (Knight and Luk, 1994), a 7