rs to focus on challenges that may arise in future humanitarian crises.
    We invited Will Lewis, Rob Munro and Stephan Vogel to publish a paper about their experience developing translation technology in response to the crisis (Lewis et al., 2011).
    They provided the data used in the Haitian Creole featured translation task.
    We hope that the introduction of this new dataset will provide a testbed for dealing with low resource languages and the informal language usage found in SMS messages.
    &#8226; Tunable metric shared task &#8211; We conducted a pilot of a new shared task to use evaluation metrics to tune the parameters of a machine translation system.
    Although previous workshops have shown evaluation metrics other than BLEU are more strongly correlated with human judgments when ranking outputs from multiple systems, BLEU remains widely used by system developers to optimize their system parameters.
    We challenged metric developers to tune the parameters of a fixed system, to see if their 