   This work shows &amp;quot;The maximum possible error rate reduction is 50.1%, or the mean applicability discussed in Section 2.
    'This difference is even more striking given that Schiitze's data exhibit a higher baseline probability (65% vs. 55%) for these words, and hence constitute an easier task. that leveraging bilingual lexicons and monolingual language models can overcome the need for aligned bilingual corpora.
    Hearst (1991) proposed an early application of bootstrapping to augment training sets for a supervised sense tagger.
    She trained her fully supervised algorithm on hand-labelled sentences, applied the result to new data and added the most confidently tagged examples to the training set.
    Regrettably, this algorithm was only described in two sentences and was not developed further.
    Our current work differs by eliminating the need for handlabelled training data entirely and by the joint use of collocation and discourse constraints to accomplish this.
    Schiitze (1992) has pion