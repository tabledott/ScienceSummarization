for English using the latter.
    In that work, we obtained improvements even without specifying exactly which grammar probabilities covaried.
    While empirical Bayes learning permits these covariances to be discovered without supervision, we found that by initializing the covariance to encode beliefs about which grammar probabilities should covary, further improvements were possible.
    Specifically, we grouped the Penn Treebank part-of-speech tags into coarse groups based on the treebank annotation guidelines and biased the initial covariance matrix for each child distribution &#952;c(&#183;  |&#183;, &#183;) so that the probabilities of child tags from the same coarse group covaried.
    For example, the probability that a past-tense verb (VBD) has a singular noun (NN) as a right child may be correlated with the probability that it has a plural noun (NNS) as a right child.
    Hence linguistic knowledge&#8212;specifically, a coarse grouping of word classes&#8212;can be encoded in the prior.
    A per-di