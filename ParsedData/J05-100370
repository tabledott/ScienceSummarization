d is therefore exponential in size.
    See also Sha and Pereira (2003) for more recent work on CRFs.
    Optimizing a log-linear model with a Gaussian prior (i.e., choosing parameter values which achieve the global minimum of the objective function in equation (28)) is a plausible alternative to the feature selection approaches described in the current article or to the feature selection methods previously applied to log-linear models.
    The Gaussian prior (i.e., the Pk a2k/72k penalty) has been found in practice to be very effective in combating overfitting of the parameters to the training data (Chen and Rosenfeld 1999; Johnson et al. 1999; Lafferty, McCallum, and Pereira 2001; Riezler et al.
    2002).
    The function in equation (28) can be optimized using variants of gradient descent, which in practice require tens or at most hundreds of passes over the training data (see, e.g., Sha and Pereira 2003).
    Thus log-linear models with a Gaussian prior are likely to be comparable in terms of efficiency 