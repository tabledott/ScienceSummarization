roblems with the thesaurus and assignment algorithm used.
    A simpler algorithm that just posits relations among terms that are a small distance apart according to WordNet (Miller et al. 1990), modeled after Morris and Hirst's heuristics, might work better.
    Therefore, the issue should not be considered closed, but rather as an area for future exploration, with this work as a baseline for comparison.
    The approach to similarity comparison suggested by Kozima (1993), while very expensive to compute, might also prove able to improve results.
    Other ways of computing semantic similarity, such as those of Schiltze (1993) or Resnik (1995), may also prove useful.
    As a related point, experimentation should be done with variations in tokenization strategies, and it may be especially interesting to incorporate phrase or bigram information into the similarity computation.
    The methods for computing lexical score also have the potential to be improved.
    Some possibilities are weighting terms accordi