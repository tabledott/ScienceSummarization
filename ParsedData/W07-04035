is employed when the alignment distributions cannot be calculated efficiently.
    This statistically-motivated process is much more appealing than the flat counting described in Section 2.1, but it does not directly include phrases.
    The joint phrasal translation model (Marcu and Wong, 2002), or JPTM, applies the same statistical techniques from the IBM models in a phrasal setting.
    The JPTM is designed according to a generative process where both languages are generated simultaneously.
    First, a bag of concepts, or cepts, C is generated.
    Each ci E C corresponds to a bilingual phrase pair, ci = (ei, &#65533;fi).
    These contiguous phrases are permuted in each language to create two sequences of phrases.
    Initially, Marcu and Wong assume that the number of cepts, as well as the phrase orderings, are drawn from uniform distributions.
    That leaves a joint translation distribution p(ei, &#65533;fi) to determine which phrase pairs are selected.
    Given a lexicon of possible cepts and a pred