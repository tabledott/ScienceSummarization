ies a domain-specific set of examples which are (for the most part) degraded (&#167;2).
    This class of implicit negative evidence provides the source of probability mass for the observed example.
    We discuss the application of CE to loglinear models in &#167;3.
    We are particularly interested in log-linear models over sequences, like the conditional random fields (CRFs) of Lafferty et al. (2001) and weighted CFGs (Miyao and Tsujii, 2002).
    For a given sequence, implicit negative evidence can be represented as a lattice derived by finite-state operations (&#167;4).
    Effectiveness of the approach on POS tagging using unlabeled data is demonstrated (&#167;5).
    We discuss future work (&#167;6) and conclude (&#167;7).
  
  
    Natural language is a delicate thing.
    For any plausible sentence, there are many slight perturbations of it that will make it implausible.
    Consider, for example, the first sentence of this section.
    Suppose we choose one of its six words at random and remove it;