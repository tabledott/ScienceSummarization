g two questions: (i) Can we exploit cross-lingual patterns to improve unsupervised analysis?
    (ii) Will this joint analysis provide more or less benefit when the languages belong to the same family?
    The model and results presented in this paper answer the first question in the affirmative, at least for the task of morphological segmentation.
    We also provided some evidence that considering closely related languages may be more beneficial than distant pairs if the model is able to explicitly represent shared language structure (the characterto-character phonetic correspondences in our case).
    In the future, we hope to apply similar multilingual models to other core unsupervised analysis tasks, including part-of-speech tagging and grammar induction, and to further investigate the role that language relatedness plays in such models.
    7
  

