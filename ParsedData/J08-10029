p(x, y) is the relative frequency of (x, y) in the training data. fi is a feature function, which represents a characteristic of probabilistic events by mapping an event into a real value. &#955;i is the model parameter of a corresponding feature function fi, and is determined so as to maximize the likelihood of the training data (i.e., the optimization in this definition).
    Y(x) is a set of y for given x; for example, in parsing, x is a given sentence and Y(x) is a parse forest for x.
    An advantage of maximum entropy models is that feature functions can represent any characteristics of events.
    That is, independence assumptions are unnecessary for the design of feature functions.
    Hence, this method provides a principled solution for the estimation of consistent probabilistic distributions over feature structure grammars.
    The remaining issue is how to estimate parameters.
    Several numerical algorithms, such as Generalized Iterative Scaling (GIS) (Darroch and Ratcliff 1972), Improved Iterat