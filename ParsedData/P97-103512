 be expected by chance, n =0.
    When there is total agreement, K = 1. ic is superior to other measures of success such as transaction success (Danieli and Gerbino, 1995), concept accuracy (Simpson and Fraser, 1993), and percent agreement (Gale, Church, and Yarowsky, 1992) because n takes into account the inherent complexity of the task by correcting for chance expected agreement.
    Thus rc provides a basis for comparisons across agents that are performing different tasks.
    When the prior distribution of the categories is unknown, P(E), the expected chance agreement between the data and the key, can be estimated from the distribution of the values in the keys.
    This can be calculated from confusion matrix M, since the columns represent the values in the keys.
    In particular: P(A) is the proportion of times that the AVMs for the actual set of dialogues agree with the AVMs for the scenario keys, and P(E) is the proportion of times that the AVMs for the dialogues and the keys are expected to agree 7K