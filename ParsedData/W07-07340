
  METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments
  
    an automatic metric for Machine Translation evaluation which has been demonstrated to have high levels of correlation with human judgments of translation quality, significantly outperforming the more used It is one of several automatic metrics used in this year&#8217;s shared task within the ACL WMT-07 workshop.
    This paper recaps the technical details underlying the metric and describes recent improvements in the metric.
    The latest release includes improved metric parameters and extends the metric to support evaluation of MT output in Spanish, French and
  
  
    Automatic Metrics for MT evaluation have been receiving significant attention in recent years.
    Evaluating an MT system using such automatic metrics is much faster, easier and cheaper compared to human evaluations, which require trained bilingual evaluators.
    Automatic metrics are useful for comparing the performance of differen