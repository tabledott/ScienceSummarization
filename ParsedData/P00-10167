d to give us reasonable labelling variation over the samples, but also would not cause the processing phase to take a long time.
    To divide the corpus into the different subsets in Step 3, we tried using two approaches: bagging and n-fold partitioning.
    In bagging, we randomly sentences selected by active learning and annotated sentences selected sequentially shows that active learning reduces the amount of data needed to reach a given level of performance by approximately a factor of two.
    Most of the published work on active learning are simulations of an idealized situation.
    One has a large annotated corpus, and the new tags for the &amp;quot;newly annotated&amp;quot; sentences are simply drawn from what was observed in the annotated corpus, as if the gold standard annotator was producing this feedback in real time, while the test set itself is, of course, not used for this feedback.
    This is an idealized situation, since it assumes that a true active learning situation would have access to