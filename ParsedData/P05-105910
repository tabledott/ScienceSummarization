ng to the Model 1 Viterbi alignment) in each column, falling either in the upper or lower outside shaded corner.
    This can be also be thought of as squeezing together the four outside corners, creating a new cell whose probability is estimated using IBM Model 1.
    Mathematically, our figure of merit for the cell (l, m, i, j) is a product of the inside Model 1 probability and the outside Model 1 probability: alignments included in the figure of merit for bitext cell (l, m, i, j) (Equation 1); solid black cells show the Model 1 Viterbi alignment within the shaded area.
    (b) shows how to compute the inside probability of a unit-width cell by combining basic cells (Equation 2), and (c) shows how to compute the inside probability of any cell by combining unit-width cells (Equation 3). where (l, m) and (i, j) represent the complementary spans in the two languages.
    &#955;L1,L2 is the probability of any word alignment template for a pair of L1word source string and L2-word target string, which we model as