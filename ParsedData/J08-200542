reports the performance of the argument identifier on the test set using the direct predictions of the trained binary classifier.
  The recall and precision of the Table 3 The overall system performance when argument boundaries are known.
  Full Parsing Shallow Parsing Prec Rec F1 Prec Rec F1 Gold 91.58 91.90 91.74 ?
  0.51 91.14 91.48 91.31 ?
  0.51 Auto 90.71 91.14 90.93 ?
  0.53 90.50 90.88 90.69 ?
  0.53 272 Punyakanok, Roth, and Yih Importance of Parsing and Inference in SRL Table 4 The performance of argument identification after pruning (based on the gold standard full parse trees).
  Full Parsing Shallow Parsing Prec Rec F1 Prec Rec F1 Gold 96.53 93.57 95.03 ?
  0.32 93.66 91.72 92.68 ?
  0.38 Auto 94.68 90.60 92.59 ?
  0.39 92.31 88.36 90.29 ?
  0.43 full parsing?based system are around 2 to 3 percentage points higher than the shallow parsing?based system on the gold-standard data.
  As a result, the F1 score is 2.5 percent- age points higher.
  The performance on automatic parse data is unsurprising