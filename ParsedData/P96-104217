ting examples individually for their informativeness a large batch of examples is examined, and the m best are selected for annotation.
    The batch selection algorithm, executed for each batch B of N examples, is as follows: This procedure is repeated sequentially for successive batches of N examples, returning to the start of the corpus at the end.
    If N is equal to the size of the corpus, batch selection selects the m globally best examples in the corpus at each stage (as in (Lewis and Catlett, 1994)).
    On the other hand, as N decreases, batch selection becomes closer to sequential selection.
  
  
    This section presents results of applying committeebased sample selection to bigram part-of-speech tagging, as compared with complete training on all examples in the corpus.
    Evaluation was performed using the University of Pennsylvania tagged corpus from the ACL/DCI CD-ROM I.
    For ease of implementation, we used a complete (closed) lexicon which contains all the words in the corpus.
    The com