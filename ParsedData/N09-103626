short rather than long, it tends to produce analyses with shorter words than batch initialization does.
    Goldwater et al. (2006a) show that Brent&#8217;s incremental segmentation algorithm (Brent, 1999) has a similar property.
    We favor batch initialization because we are inbatch initialization, no table label resampling incremental initialization, table label resampling batch initialization, table label resampling terested in understanding the properties of our models (expressed here as adaptor grammars), and batch initialization does a better job of finding the most probable analyses under these models.
    However, it might be possible to justify incremental initialization as (say) cognitively more plausible.
    Unlike the previous two implementation choices which apply to a broad range of algorithms, table label resampling is a specialized kind of Gibbs step for adaptor grammars and similar hierarchical models that is designed to improve mobility.
    The adaptor grammar algorithm described in John