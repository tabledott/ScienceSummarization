for classifying input examples.
    Such modeling is absent in batch selection, and we hypothesize that this is the reason for its lower effectiveness.
  
  
    Annotating large textual corpora for training natural language models is a costly process.
    We propose reducing this cost significantly using committee7The use of a single model is also criticized in (Cohn, Atlas, and Ladner, 1994). based sample selection, which reduces redundant annotation of examples that contribute little new information.
    The method can be applied in a semiinteractive process, in which the system selects several new examples for annotation at a time and updates its statistics after receiving their labels from the user.
    The implicit modeling of uncertainty makes the selection system generally applicable and quite simple to implement.
    Our experimental study of variants of the selection method suggests several practical conclusions.
    First, it was found that the simplest version of the committee-based method, using 