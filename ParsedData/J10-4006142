 like a seamless way to integrate new terms in the model incrementally, based on just a few extra data points, but we leave it to further research to study how this could be accomplished, together with the undoubtedly many further practical and theoretical problems that will emerge.
    We will conclude, instead, by discussing some general advantages that follow from the DM approach of separating corpus-based model building, the multi-purpose long term distributional memory, and different views of the memory data to accomplish different semantic tasks, without resorting to the source corpus again.
    First of all, we would like to make a more general point regarding parameter tuning and task-specific optimization, by going back to the analogy with WordNet as a semantic multi-purpose resource.
    If you want to improve performance of a WordNetbased system, you will probably not wait for its next release, but rather improve the algorithms that work on the existing WordNet graph.
    Similarly, in the DM appro