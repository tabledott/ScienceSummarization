v and Henderson, 2007).
    A hallmark of many of these models is that they can be implemented very efficiently.
    Thus, transition-based parsers normally run in linear or quadratic time, using greedy deterministic search or fixed-width beam search (Nivre et al., 2004; Attardi, 2006; Johansson and Nugues, 2007; Titov and Henderson, 2007), and graph-based models support exact inference in at most cubic time, which is efficient enough to make global discriminative training practically feasible (McDonald et al., 2005a; McDonald et al., 2005b).
    However, one problem that still has not found a satisfactory solution in data-driven dependency parsing is the treatment of discontinuous syntactic constructions, usually modeled by non-projective dependency trees, as illustrated in Figure 1.
    In a projective dependency tree, the yield of every subtree is a contiguous substring of the sentence.
    This is not the case for the tree in Figure 1, where the subtrees rooted at node 2 (hearing) and node 4 (scheduled) b