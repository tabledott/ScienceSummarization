
  Statistical Significance Tests For Machine Translation Evaluation
  
    If two translation systems differ differ in performance on a test set, can we trust that this indicates a difference in true system quality?
    To answer this question, we describe bootstrap resampling methods to compute statistical significance of test results, and validate them on the concrete example of the Even for small test sizes of only 300 sentences, our methods may give us assurances that test result differences are real.
  
  
    Recently, the field of machine translation has been changed by the emergence both of effective statistical methods to automatically train machine translation systems from translated text sources (so-called parallel corpora) and of reliable automatic evaluation methods.
    Machine translation systems can now be built and evaluated from black box tools and parallel corpora, with no human involvement at all.
    The evaluation of machine translation systems has changed dramatically in the last few y