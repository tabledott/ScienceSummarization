 for the edit distance test set versus 83.7% for the F2 test set, suggestive of the greater variability in the latter data set.
			3.3 Data Alignment.
			Each corpus was used as input to the word alignment algorithms available in Giza++ (Och &amp; Ney 2000).
			Giza++ is a freely available implementation of IBM Models 1-5 (Brown et al 1993) and the HMM alignment (Vogel et al 1996), along with various improvements and modifications motivated by experimentation by Och &amp; Ney (2000).
			Giza++ accepts as input a corpus of sentence pairs and produces as output a Viterbi alignment of that corpus as well as the parameters for the model that produced those alignments.
			While these models have proven effective at the word alignment task (Mihalcea &amp; Pedersen 2003), there are significant practical limitations in their output.
			Most fundamentally, all alignments have either zero or one connection to each target word.
			Hence they are unable to produce the many-to many alignments required to identify correspo