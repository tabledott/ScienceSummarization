
	Single Malt or Blended? A Study in Multilingual Parser Optimization
		We describe a two-stage optimization of the MaltParser system for the ten languages in the multilingual track of the CoNLL 2007 shared task on dependency parsing.
		The first stage consists in tuning a single-parsersystem for each language by optimizing parameters of the parsing algorithm, the fea ture model, and the learning algorithm.
		Thesecond stage consists in building an ensemble system that combines six different parsing strategies, extrapolating from the opti mal parameters settings for each language.
		When evaluated on the official test sets, the ensemble system significantly outperforms the single-parser system and achieves the highest average labeled attachment score.
	
	
			In the multilingual track of the CoNLL 2007 shared task on dependency parsing, a single parser must be trained to handle data from ten different languages: Arabic (Hajic?
			et al, 2004), Basque (Aduriz et al, 2003), Catalan, (Mart??
			et al, 2007), Chin