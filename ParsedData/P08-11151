e models) from modeling the relationship between source and target language (translation models).
    Today, virtually all statistical translation systems seek the best hypothesis e for a given input f in the source language, according to consider all possibilities for f by encoding the alternatives compactly as a confusion network or lattice (Bertoldi et al., 2007; Bertoldi and Federico, 2005; Koehn et al., 2007).
    Why, however, should this advantage be limited to translation from spoken input?
    Even for text, there are often multiple ways to derive a sequence of words from the input string.
    Segmentation of Chinese, decompounding in German, morphological analysis for Arabic &#8212; across a wide range of source languages, ambiguity in the input gives rise to multiple possibilities for the source word sequence.
    Nonetheless, state-of-the-art systems commonly identify a single analysis f during a preprocessing step, and decode according to the decision rule in (1).
    In this paper, we go beyond 