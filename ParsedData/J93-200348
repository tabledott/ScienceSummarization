ng a vocabulary into classes so as to preserve mutual information between adjacent classes in running text.
    We construct A and B as functions with 50 distinct values by dividing the English and French vocabularies each into 50 classes according to this algorithm.
    By assuming that the probability depends on the previous cept and on the identity of the French word being placed, we can account for such facts as the appearance of adjectives before nouns in English but after them in French.
    We call j - 01-1 the displacement for the head of cept i.
    It may be either positive or negative.
    We expect di (-1 IA(e), BM) to be larger than d1(+ 11A(e),8(f)) when e is an adjective and f is a noun.
    Indeed, this is borne out in the trained distortion probabilities for Model 4, where we find that di (-1 IA(government' s), (developpement)) is 0.7986, while d1(-i- 1 IA(government' s), B(developpement)) is 0.0168.
    Suppose, now, that we wish to place the kth word of cept i for [i] &gt; 0, k&gt; 1.
    W