rformance in sentence-level evaluation.
    Sentence-level correlation reflects the relative qualities of different hypotheses in a MT system, which does not indicate any information for the relative qualities of different systems.
    If we uniformly decrease or increase every hypothesis&#8217;s automatic score in a MT system, the sentence-level correlation with human judgments will remain the same, but the corpus-level correlation will be changed.
    So we might possibly get inconsistent corpus-level and sentence-level correlations.
    From the results, we can see that with the increase of n-grams length, the performance of BLEU and HWCM will first increase up to length 5, and then starts decreasing, where the optimal n-gram length of 5 corresponds to our usual setting for BLEU algorithm.
    This shows that corpus-level evaluation, compared with the sentence-level evaluation, is much less sensitive to the sparse data problem and thus leaves more space for making use of comprehensive evaluation metrics.
 