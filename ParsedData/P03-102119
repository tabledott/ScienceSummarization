terion and the statistical models used remain unchanged in the minimum Bayes risk approach.
    In the field of natural language processing this approach has been applied for example in parsing (Goodman, 1996) and word alignment (Kumar and Byrne, 2002).
  
  
    We presented alternative training criteria for loglinear statistical machine translation models which are directly related to translation quality: an unsmoothed error count and a smoothed error count on a development corpus.
    For the unsmoothed error count, we presented a new line optimization algorithm which can efficiently find the optimal solution along a line.
    We showed that this approach obtains significantly better results than using the MMI training criterion (with our method to define pseudoreferences) and that optimizing error rate as part of the training criterion helps to obtain better error rate on unseen test data.
    As a result, we expect that actual &#8217;true&#8217; translation quality is improved, as previous work has shown