urrence is reordered, and let S be an integer-valued random variable that indicates how many source words are spanned by the nonterminal occurrence.
    We can estimate P(R  |S) via relativefrequency estimation from the rules as they are extracted from the parallel text, and incorporate this probability as a new feature of the model.
    Fine-grained features A difficulty with the coarse-grained reordering features is that the grammar extraction process finds overlapping rules in the training data and might not give a sensible probability estimate; moreover, reordering statistics from the training data might not carry over perfectly into the translation task (in particular, the training data may have some very freely-reordering translations that one might want to avoid replicating in translation).
    As an alternative, we introduce a fine-grained version of our distortion model that can be trained directly in the translation task as follows: define a separate binary feature for each value of (R, S), where R 