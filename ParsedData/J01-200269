e explained by the difference in training/test split.
    What is more puzzling is the substantial difference for the transformation-based tagger.
    Possible explanations are that Brill and Wu used a much better parametrization of this system or that they used a different version of the WSJ material.
    Be that as it may, the final results are comparable and it is clear that the lower numbers in relation to LOB are caused by the choice of test material (WSJ) rather than by the methods used.
    In Tufi* (1999), a single tagger generator is trained on different corpora representing different language registers.
    For the combination, a method called credibility profiles worked best.
    In such a profile, for each component tagger, information is kept about its overall accuracy, its accuracy for each tag, etc.
    In another recent study, Marquez et al. (1999) investigate several types of ensemble construction in a decision tree learning framework for tagging specific classes of ambiguous words (as oppose