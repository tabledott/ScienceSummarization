rect, depending on the definition of correct&amp;quot;.
    We implemented a version of the algorithm described by Church.
    When trained and tested on the same samples used in our experiment, we found the error rate to be about 4.5%.
    [DeRose 88] quotes a 4% error rate; however, the sample used for testing was part of the training corpus.
    [Garside et al. 87] reports an accuracy of 96-97%.
    Their probabilistic tagger has been augmented with a handcrafted procedure to pretag problematic &amp;quot;idioms&amp;quot;.
    This procedure, which requires that a list of idioms be laboriously created by hand, contributes 3% toward the accuracy of their tagger, according to [DeRose 88].
    The idiom list would have to be rewritten if one wished to use this tagger for a different tag set or a different corpus.
    It is interesting to note that the information contained in the idiom list can be automatically acquired by the rule-based tagger.
    For example, their tagger had difficulty tagging as old as.
 