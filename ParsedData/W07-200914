 methods.
			The dis tributional methods, especially lin, show promising results given that these methods are automatic and 5The task website is at http://www.informatics.sussex.ac.uk/ research/nlp/mccarthy/task10index.html.
			6There is not a big difference between P and R because systems typically supplied answers for most items.
			51 Systems P R Mode P Mode R KU 12.90 12.90 20.65 20.65 UNT 12.77 12.77 20.73 20.73 MELB 12.68 12.68 20.41 20.41 HIT 11.35 11.35 18.86 18.86 USYD 11.23 10.88 18.22 17.64 IRST1 8.06 8.06 13.09 13.09 IRST2 6.95 6.94 20.33 20.33 TOR 2.98 2.98 4.72 4.72 Table 1: best results Systems P R Mode P Mode R WordNet 9.95 9.95 15.28 15.28 lin 8.84 8.53 14.69 14.23 l1 8.11 7.82 13.35 12.93 lee 6.99 6.74 11.34 10.98 jaccard 6.84 6.60 11.17 10.81 cos 5.07 4.89 7.64 7.40 Table 2: best baseline results don?t require hand-crafted inventories.
			As yet we haven?t combined the baselines with disambiguation methods.
			Only HIT attempted the mw task.
			It outperforms all baselines from WordNet.
			