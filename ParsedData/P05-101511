ly knows.
  
  
    feature space to a metric space.If we choose from a family of sufficiently &#8220;gradual&#8221; functions, then similar items necessarily receive similar labels.
    In particular, we consider linear,-insensitive SVM regression (Vapnik, 1995; Smola and Sch&#168;olkopf, 1998); the idea is to find the hyperplane that best fits the training data, but where training points whose labels are within distanceof the hyperplane incur no loss.
    Then, for (test) instance, the label preference function is the negative of the distance betweenand the value predicted for by the fitted hyperplane function.
    Wilson, Wiebe, and Hwa (2004) used SVM regression to classify clause-level strength of opinion, reporting that it provided lower accuracy than other methods.
    However, independently of our work, Koppel and Schler (2005) found that applying linear regression to classify documents (in a different corpus than ours) with respect to a three-point rating scale provided greater accuracy than OVA SVMs