sms of the ability of connectionist representations to handle complex structures (Smolensky, 1990; Plate, 1995).
    More recently, several proposals have been put forward for computing the meaning of word combinations in vector spaces.
    This renewed interest is partly due to the popularity of distributional methods and their application potential to tasks that require an understanding of larger phrases or complete sentences.
    For example, Mitchell and Lapata (2010) introduce a general framework for studying vector composition, which they formulate as a function f of two vectors u and v. Different composition models arise, depending on how f is chosen.
    Assuming that composition is a linear function of the Cartesian product of u and v allows to specify additive models which are by far the most common method of vector combination in the literature (Landauer and Dumais, 1997; Foltz et al., 1998; Kintsch, 2001).
    Alternatively, assuming that composition is a linear function of the tensor product of u