ees built by the analysts.
    Besides directly comparing the trees built by the program with those built by analysts, we also evaluated the impact that our trees could have on the task of summarizing text.
    A summarization program that uses the rhetorical parser described here recalled 66% of the sentences considered important by 13 judges in the same five texts, with a precision of 68%.
    In contrast, a random procedure recalled, on average, only 38.4% of the sentences considered important by the judges, with a precision of 38.4%.
    And the Microsoft Office 97 summarizer recalled 41% of the important sentences with a precision of 39%.
    We discuss at length the experiments from which the data presented above was derived in (Marcu, 1997).
    The rhetorical parser presented in this paper uses only the structural constraints that were enumerated in section 2.
    Co-relational constraints, focus, theme, anaphoric links, and other syntactic, semantic, and pragmatic factors do not yet play a role in ou