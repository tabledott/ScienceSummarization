rison of Supervised Taggers quality of the lexicon made available to unsupervised learner made the greatest difference to tagging accuracy.
			Filtering the possible part-of speech assignments contained in a basic lexicon automatically constructed from the commonly used Penn Treebank improved results by as much as 22%.
			This finding highlights the importance of the need for clean dictionaries whether they are constructed by hand or automatically when we seek to be fully unsupervised.
			In addition, we presented a variation on HMM model training in which the tag sequence and lexical probabilities are estimated in sequence.
			This helped stabilize training when estimation of lexical probabilities can be noisy.
			Finally, we experimented with using left and right context in the estimation of lexical probabilities, which we refer to as a contextualized HMM.
			Without supervision, this new HMM structure improved results slightly compared to a simple trigram tagger as described in Merialdo, which takes into a