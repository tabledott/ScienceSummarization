model used in the second machine translation experiment.
    This set consists of general web data collected in January 2006 (2 trillion tokens).
    For Arabic we used the following two different training data sets: ar gigaword: Consists of several Arabic news data sets provided by LDC (629 million tokens). ar webnews: Consists of data collected up to December 2005 from web pages containing primarily Arabic news articles (approximately 600 million tokens).
    Given a sentence f in the source language, the machine translation problem is to automatically produce a translation e&#65533; in the target language.
    In the subsequent experiments, we use a phrase-based statistical machine translation system based on the loglinear formulation of the problem described in (Och and Ney, 2002): where {hm(e, f)} is a set of M feature functions and {am} a set of weights.
    We use each predictive classbased language model as well as a word-based model as separate feature functions in the log-linear combination in Eq.
 