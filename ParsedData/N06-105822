value was around 0.7, which corresponds to substantial agreement (Landis and Koch, 1977).
    As Table 7 shows, the ranking between the accuracy of the different paraphrasing methods mirrors the ranking of the corresponding MT evaluation methods shown in Table 4.
    The paraphrasing method with the highest accuracy, ContextWN, contributes most significantly to the evaluation performance of BLEU.
    Interestingly, even methods with moderate accuracy, i.e.
    63% for WordNet, have a positive influence on the BLEU metric.
    At the same time, poor paraphrasing accuracy, such as LSA with 30%, does hurt the performance of automatic evaluation.
    To further understand the contribution of contextual filtering, we compare the substitutions made by WordNet and ContextWN on the same set of sentences.
    Among the 200 paraphrases proposed by WordNet, 73 (36.5%) were identified as incorrect by human judges.
    As the confusion matrix in Table 8 shows, 40 (54.5%) were eliminated during the filtering step.
    At t