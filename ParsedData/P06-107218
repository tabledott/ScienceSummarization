al Gaussian smoothing was applied, with different variances, and model selection was applied over smoothing conditions and the same initializers as before.
    Four of the languages have at least one effective CE condition, supporting our previous English results (Smith and Eisner, 2005b), but CE was harmful for Bulgarian and Mandarin.
    Perhaps better neighborhoods exist for these languages, or there is some ideal neighborhood that would perform well for all languages.
    Our approach of allowing broken trees (&#167;5) is a natural extension of the CE framework.
    Contrastive estimation views learning as a process of moving posterior probability mass from (implicit) negative examples to (explicit) positive examples.
    The positive evidence, as in MLE, is taken to be the observed data.
    As originally proposed, CE allowed a redefinition of the implicit negative evidence from &#8220;all other sentences&#8221; (as in MLE) to &#8220;sentences like xi, but perturbed.&#8221; Allowing segmentation of the t