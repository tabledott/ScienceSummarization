analysis.
    However, we believe that the impact of optimizer instability has been neglected by standard experimental methodology in MT research, where single-sample measurements are too often used to assess system differences.
    In this paper, we have provided evidence that optimizer instability can have a substantial impact on results.
    However, we have also shown that it is possible to control for it with very few replications (Table 2).
    We therefore suggest: set evaluation be performed at least three times; more replications may be necessary for experimental manipulations with more subtle effects; &#8226; Use of the median system according to a trusted metric when manually analyzing system output; preferably, the median should be determined based on one test set and a second test set should be manually analyzed.
  
  
    We thank Michael Denkowski, Kevin Gimpel, Kenneth Heafield, Michael Heilman, and Brendan O&#8217;Connor for insightful feedback.
    This research was supported in part by the 