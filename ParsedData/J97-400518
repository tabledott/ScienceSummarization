 might expect the best weights to yield D(1311q) = 0, but such is not the case.
    We have just seen, for example, that the best weights for grammar G1 yield distribution (ID yet D(311q1) = 0.32 &gt; 0.
    A closer inspection of the divergence calculation in Table 1 reveals that qi is sometimes less than 19, but never greater than /5.
    Could we improve the fit by increasing qi?
    For that matter, how can it be that qi is never greater than /5?
    As probability distributions, qi and /3 should have the same total mass, namely, one.
    Where is the missing mass for qi?
    The answer is of course that qi and /5 are probability distributions over L(Gi), but not all of L(G1) appears in the corpus.
    Two trees are missing, and they account for the missing mass.
    These two trees are given in Figure 5.
    Each of these trees has The trees from L(G1) that are missing in the training corpus. probability 0 according to /5 (hence they can be ignored in the divergence calculation), but probability 1/9 acco