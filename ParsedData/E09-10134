 faithfully model more fine-grained meaning distinctions.
    In our work, therefore, we create an individual model for every (ambiguous) word rather than a global model for an entire document collection.
    We also show how multiple information sources can be straightforwardly integrated without changing the underlying probabilistic model.
    For instance, besides lexical information we may want to consider parts of speech or dependencies in our sense induction problem.
    This is in marked contrast with previous LDA-based models which mostly take only word-based information into account.
    We evaluate our model on a recently released benchmark dataset (Agirre and Soroa, 2007) and demonstrate improvements over the state-of-the-art.
    The remainder of this paper is structured as follows.
    We first present an overview of related work (Section 2) and then describe our Bayesian model in more detail (Sections 3 and 4).
    Section 5 describes the resources and evaluation methodology used in our experime