ng various selection methods, viz.
    Random, Strategy1 and Strategy2.
    In GENIA, we find: Furthermore, when we apply our model to newswire domain (MUC-6) to recognize person, location and organization names, Strategy1 and Strategy2 show a more promising result by comparing with the supervised learning and Random, as shown in Table 2.
    On average, about 95% of the data can be reduced to achieve the same performance with the supervised learning in MUC-6.
    It is probably because NER in the newswire domain is much simpler than that in the biomedical domain (Shen et al. 2003) and named entities are less and distributed much sparser in the newswire texts than in the biomedical texts.
    In this section, we investigate the effectiveness of informativeness criterion in NER task.
    Figure 5 shows a plot of training data size versus F-measure achieved by the informativeness-based measures in Section 3.1.2: Info_Avg, Info_Min and Info_S/N as well as Random.
    We make the comparisons in GENIA corpus.
    