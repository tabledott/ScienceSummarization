eriments involving our model, we represent words using 100-dimensional word vectors.
    We explore the two settings mentioned in Sec.
    2.1.
    We compare performance on standard datasets when using randomly initialized word vectors (random word init.)
    or word vectors trained by the model of Collobert and Weston (2008) and provided by Turian et al. (2010).2 These vectors were trained on an unlabeled corpus of the English Wikipedia.
    Note that alternatives such as Brown clusters are not suitable since they do not capture sentiment information (good and bad are usually in the same cluster) and cannot be modified via backpropagation.
    The confessions section of the experience project website3 lets people anonymously write short personal stories or &#8220;confessions&#8221;.
    Once a story is on the site, each user can give a single vote to one of five label categories (with our interpretation): The EP dataset has 31,676 confession entries, a total number of 74,859 votes for the 5 labels above, th