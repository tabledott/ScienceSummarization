 contain &#8220;PML/RAR alpha,&#8221; &#8220;beta 2-M,&#8221; and &#8220;kappa B-specific DNA binding protein&#8221; all labeled with PROTEIN, the model might learn that the words &#8220;alpha,&#8221; &#8220;beta,&#8221; and &#8220;kappa&#8221; are indicative of proteins, but cannot capture the fact that they are all semantically related because they are Greek letters.
    Similarly, words with the feature WC=Aaa are often part of protein names, such as &#8220;Rab,&#8221; &#8220;Alu,&#8221; and &#8220;Gag.&#8221; But the model may have a difficult time setting the weights for this feature when confronted with words like &#8220;Phe,&#8221; &#8220;Arg,&#8221; and &#8220;Cys,&#8221; which are amino acid abbreviations and not often labeled as part of a protein name.
    This sort of semantic domain knowledge can be provided in the form of lexicons.
    I prepared a total of 17 such lexicons, which include 7 that were entered by hand (Greek letters, amino acids, chemical elements, known viruses, plus abbreviations