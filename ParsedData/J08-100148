 and smoothing parameters) affect their performance.
    These parameters were tuned on the development set and chosen so as to optimize the models&#8217; performance on the pairwise ranking task.
    Evaluation Metric.
    Given a set of pairwise rankings (an original document and one of its permutations), we measure accuracy as the ratio of correct predictions made by the model over the size of the test set.
    In this setup, random prediction results in an accuracy of 50%.
    Impact of Linguistic Representation.
    We first investigate how different types of linguistic knowledge influence our model&#8217;s performance.
    Table 5 shows the accuracy on the ordering task when the model is trained on different grid representations.
    As can be seen, in both domains, the full model Coreference+Syntax+Salience+ significantly outperforms a linguistically naive model which simply records the presence (and absence) of entities in discourse (Coreference&#8722;Syntax&#8722;Salience&#8722;).
    Moreover, we ob