some pages clustered only mentioned the name in passing, or in a specialized, commercial context (e.g.
    Amazon sales product).
    The pseudonames were created as follows.
    The retrieval results from two different randomlyselected people were taken, and all references to either name (in full or part) replaced by a unique, shared pseudoname.
    The resulting collection then consisted of documents which were ambiguous as to whom they talked about.
    The aim of the clustering was then to distinguish this artificially conflated pseudoname.
    In addition, a test set of four naturally occurring polysemous names (such as Jim Clark), containing an average of 60 instances each, was manually annotated with distinguishing nameID numbers and used for a parallel evaluation.
    The experiments consist of two parts.
    The first output is the clustering visualizations whose utility can be judged by inspection.
    The second is a quantitative analysis of the different methodologies.
    Both are conducted over 