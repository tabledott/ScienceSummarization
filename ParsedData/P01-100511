hes work by first training a seed learner (or family of learners) and then running the learner(s) over a set of unlabeled samples.
    A sample is presumed to be more useful for training the more uncertain its classification label is.
    Uncertainty can be judged by the relative weights assigned to different labels by a single classifier (Lewis and Catlett, 1994).
    Another approach, committee-based sampling, first creates a committee of classifiers and then judges classification uncertainty according to how much the learners differ among label assignments.
    For example, Dagan and Engelson (1995) describe a committee-based sampling technique where a part of speech tagger is trained using an annotated seed corpus.
    A family of taggers is then generated by randomly permuting the tagger probabilities, and the disparity among tags output by the committee members is used as a measure of classification uncertainty.
    Sentences for human annotation are drawn, biased to prefer those containing high uncerta