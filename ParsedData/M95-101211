ule-based correction of "more" .
  143 learned rules from Brills release 1 .1 (148 lexical rules, 283 contextual rules), for which Brill has measure d accuracies that are 2-3 percentage points higher than in our own smaller-scale experiments .
  For MUC-6, we combined these rules with 19 hand-crafted contextual rules that correct residual tagging errors that were especially detrimental to our NE performance.
  Tagger throughput is around 3000 words/sec.
  THE PHRASER The Alembic phrase finder, or phraser for short, performs the bulk of the systems syntactic analysis .
  As noted above, it has somewhat less recognition power than a finite-state machine, and as such shares many characteristics of pattern-matching systems, such as CIRCUS [10] or FASTUS [2] .
  Where it differs from these systems is in being driven by rule sequences.
  We have experimented with both automatically-learned rul e sequences and hand-crafted ones .
  In the system we fielded for Muc-6, we ended up running entirely with hand-crafted se