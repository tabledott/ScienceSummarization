has to be computed on a near-infinite number of test sentences.
    But the BLEU score computed on 30,000 test sentences is as good as any (assuming 30,000 is close to infinite).
    It is, as you recall from Table 1, 28.9%.
    For all but three test set, this near-true test score lies within the estimated confidence interval.
    Loosely speaking, the 95% confidence level is actually 97% correct.
  
  
    As stated earlier, the value of scoring metrics comes from being able to compare the quality of different translation systems.
    Typically, we want to compare two systems.
    We translate the same test set with the two systems, and measure the translation quality using an evaluation metric.
    One system will fare better than the other, with some difference in score.
    Can we conclude that the better scoring system is truly better?
    If the differences in score are small, we intuitively have some doubt. ples we make a 95% statistically significant conclusion that the Spanish system is better than 