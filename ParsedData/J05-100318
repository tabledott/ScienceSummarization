iew this work.
    Much of this work has focused on binary classification problems, and this section is also restricted to problems of this type.
    Later in the article we show how several of the ideas can be carried across to reranking problems.
    The general setup for binary classification problems is as follows: where each ak E R, hence a&#175; is an m-dimensional real-valued vector.
    We show that both logistic regression and boosting implement a linear, or hyperplane, classifier.
    This means that given an input example x and parameter values &#175;a, the output from the classifier is Collins and Koo Discriminative Reranking for NLP where hyperplane which passes through the origin4 of the space and has a&#175; as its normal.
    Points lying on one side of this hyperplane are classified as +1; points on the other side are classified as &#8212;1.
    The central question in learning is how to set the parameters &#175;a, given the training examples b&#240;x1, y1&#222;, &#240;x2, y2&#222;, ... ,&#24