
  Probabilistic Parsing For German Using Sister-Head Dependencies
  
    We present a probabilistic parsing model for German trained on the Negra treebank.
    We observe that existing lexicalized parsing models using head-head dependencies, while successful for English, fail to outperform an unlexicalized baseline model for German.
    Learning curves show that this effect is not due to lack of training data.
    We propose an alternative model that uses sister-head dependencies instead of head-head dependencies.
    This model outperforms the baseline, achieving a labeled precision and recall of up to 74%.
    This indicates that sister-head dependencies are more appropriate for treebanks with very flat structures such as Negra.
  
  
    Treebank-based probabilistic parsing has been the subject of intensive research over the past few years, resulting in parsing models that achieve both broad coverage and high parsing accuracy (e.g., Collins 1997; Charniak 2000).
    However, most of the existing models ha