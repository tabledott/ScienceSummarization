te the test sentences into MRs.
    Translation failed when there were constructs that the parser did not cover.
    We counted the number of sentences that were translated into an MR, and the number of translations that were correct.
    For ROBOCUP, a translation was correct if it exactly matched the correct MR. For GEOQUERY, a translation was correct if it retrieved the same answer as the correct query.
    Using these counts, we measured the performance of the parser in terms of precision (percentage of translations that were correct) and recall (percentage of test sentences that were correctly translated).
    For ROBOCUP, it took 47 minutes to learn a parser using IIS.
    For GEOQUERY, it took 83 minutes.
    Figure 6 shows the performance of WASP compared to four other algorithms: SILT (Kate et al., 2005), COCKTAIL (Tang and Mooney, 2001), SCISSOR (Ge and Mooney, 2005) and Zettlemoyer and Collins (2005).
    Experimental results clearly show the advantage of extra supervision in SCISSOR and Zettlemoye