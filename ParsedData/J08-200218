 use the CoNLL measure on the February 2004 data, because this earlier data was not available in a format which specifies which arguments should have the additional R-ARGX labels used in the CoNLL evaluation.3 Finally, these measures are better for comparison with early papers, because most research before 2005 did not distinguish referring arguments.
    We describe our argument-based measures in detail here in case researchers are interested in replicating our results for the February 2004 data.
    For the February 2004 data, we used the standard split into training, development, and test sets&#8212;the annotations from sections 02&#8211;21 formed the training set, section 24 the development, and section 23 the test set.
    The set of argument labels considered is the set of core argument labels (ARG0 through ARG5) plus the modifier labels (see Figure 1).
    The training set contained 85,392 propositions, the test set 4,615, and the development set 2,626.
    We evaluate semantic role labeling models on 