ations of each other.
    All these are part of our second lexicon, LLR-Ler, which we present in detail in Section 2.2.
    Subsequently, in Section 2.3, we present our algorithm for detecting parallel sub-sentential fragments.
    Our method for computing the probabilistic translation lexicon LLR-Ler is based on the the LogLikelihood-Ratio (LLR) statistic (Dunning, 1993), which has also been used by Moore (2004a; 2004b) and Melamed (2000) as a measure of word association.
    Generally speaking, this statistic gives a measure of the likelihood that two samples are not independent (i.e. generated by the same probability distribution).
    We use it to estimate the independence of pairs of words which cooccur in our parallel corpus.
    If source word and target word are independent (i.e. they are not translations of each other), we would expect that .
    Thus, we can split the set of cooccurring word pairs into positively and negatively associated pairs, and obtain a measure for each of the two association t