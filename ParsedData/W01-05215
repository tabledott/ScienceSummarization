ld nodes with their head siblings and parents.
    The probability models of Charniak (1997), Magerman (1995) and Ratnaparkhi (1997) differ in their details but are based on similar features.
    Models 2 and 3 of Collins (1997) add some slightly more elaborate features to the probability model, as do the additions of Charniak (2000) to the model of Charniak (1997).
    Our implementation of Collins' Model 1 performs at 86% precision and recall of labeled parse constituents on the standard Wall Street Journal training and test sets.
    While this does not reflect the state-of-the-art performance on the WSJ task achieved by the more the complex models of Charniak (2000) and Collins (2000), we regard it as a reasonable baseline for the investigation of corpus effects on statistical parsing.
  
  
    We conducted separate experiments using WSJ data, Brown data, and a combination of the two as training material.
    For the WSJ data, we observed the standard division into training (sections 2 through 21 of the 