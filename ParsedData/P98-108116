ght therefore to be advantageous to step away from the underlying mechanism of voting and to model the situations observed in Tune more closely.
    The practice of feeding the outputs of a number of classifiers as features for a next learner is usually called stacking (Wolpert 1992).
    The second stage can be provided with the first level outputs, and with additional information, e.g. about the original input pattern.
    The first choice for this is to use a MemoryBased second level learner.
    In the basic version (Tags), each case consists of the tags suggested by the component taggers and the correct tag.
    In the more advanced versions we also add information about the word in question (Tags+Word) and the tags suggested by all taggers for the previous and the next position (Tags+Context).
    For the first two the similarity metric used during tagging is a straightforward overlap count; for the third we need to use an Information Gain weighting (Daelemans et al. 1997).
    Surprisingly, none of the