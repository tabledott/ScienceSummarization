 in (Zens et al., 2004).
    The difference is that, here, we do not constrain the phrase reordering.
    Nevertheless the inverted/monotone concatenation of phrases in the BTG framework is similar to the left/right phrase orientation used here.
  
  
    In statistical machine translation, we are given a source language sentence fJ1 = f1 .
    .
    . fj ... fJ, which is to be translated into a target language sentence eI1 = e1 ... ei ... eI.
    Among all possible target language sentences, we will choose the sentence with the highest probability: The posterior probability Pr(eI1|fJ1 ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): (2) The denominator represents a normalization factor that depends only on the source sentence fJ1 .
    Therefore, we can omit it during the search process.
    As a decision rule, we obtain: This approach is a generalization of the sourcechannel approach (Brown et al., 1990).
    It has the advantage that additional models h(&#183;) ca