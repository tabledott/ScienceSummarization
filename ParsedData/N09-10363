    Nonparametric Bayesian methods produce state-of-the-art performance on this task (Goldwater et al., 2006a; Goldwater et al., 2007; Johnson, 2008).
    In a computational linguistics setting it is natural to try to align the HDP hierarchy with the hierarchy defined by a grammar.
    Adaptor grammars, which are one way of doing this, make it easy to explore a wide variety of HDP grammar-based models.
    Given an appropriate adaptor grammar, the features learned by adaptor grammars can correspond to linguistic units such as words, syllables and collocations.
    Different adaptor grammars encode different assumptions about the structure of these units and how they relate to each other.
    A generic adaptor grammar inference program infers these units from training data, making it easy to investigate how these assumptions affect learning (Johnson, 2008).1 However, there are a number of choices in the design of adaptor grammars and the associated inference procedure.
    While this paper studies the impact o