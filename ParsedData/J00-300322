within a conversation (not the ith word).
    To make both the modeling and the search for the best DA sequence feasible, we further require that our likelihood models are decomposable by utterance.
    This means that the likelihood given a complete conversation can be factored into likelihoods given the individual utterances.
    We use LI, for the ith DA label in the sequence U, i.e., U = (U1,.
    &#8226; ,U,, &#8226;&#8226;&#8226; where n is the number of utterances in a conversation.
    In addition, we use E, for that portion of the evidence that corresponds to the ith utterance, e.g., the words or the prosody of the ith utterance.
    Decomposability of the likelihood means that Applied separately to the three types of evidence Ai, Wi, and Fi mentioned above, it is clear that this assumption is not strictly true.
    For example, speakers tend to reuse The discourse HMM as Bayes network. words found earlier in the conversation (Fowler and Housum 1987) and an answer might actually be relevant to the qu