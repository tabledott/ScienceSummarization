odel C that ignored lexical dependencies be- tween parents and children, considering only de- pendencies between a parents tag and a childs tag.
  This model is similar to the model nsed by stochastic CFG.
  Model X did the same n-gram tagging as models A and B (~.
  = 2 for the prelim- inary experiment, rather than n = 3), but did not assign any links.
  Tables 1 -2 show the percentage of raw tokens that were correctly tagged by each model, as well as the proportion that were correctly attached to 344 All tokons Ntlll-llllnc NOLIn8 17~1 verbs [ A t~-  - ( C r - [ L~5.
  ,~  r 8 .1S~, ,a .~ 47.3 ~l  r~ sA rr.~ I ~  1 ~ ~ - L 4 0 : , &lt; ~ A _  - ~ ~_ l~d)le 2: ]{.csults of preli ininary (,Xl)crimcnts: Per.
  contage of tokens corrc0Lly attached Lo their par- onl;s by each model.
  Per tagging, baseline per[ol:lnance Wa, S I/leaSllied by assigniug each word ill the test set its most frequent tag (i[ any) [roiii the train- lug set.
  Thc iinusually low I)aseliue t)crJorillance I:esults [lOlll kL conil)iuation 