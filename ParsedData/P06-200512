, &#8220;ysnite&#8221; have to be normalized using an insertion transformation to become &#8220;don&#8217;t know&#8221; and &#8220;yesterday night&#8221;.
    Moreover, we also want the normalization to have better lexical affinity and linguistic equivalent, thus we extend the model to allow many words to many words alignment, allowing a sequence of SMS words to be normalized to a sequence of contiguous English words.
    We call this updated model a phrase-based normalization model.
  
  
    Given an English sentence e and SMS sentence s , if we assume that e can be decomposed into K phrases with a segmentation T , such that each phrase e in can be corresponded with m is the position of a word in san d its am ider only two types of probabilities: the alignment probabilities denoted by This is the basic function of the channel model for the phrase-based SMS normalization model, where we used the maximum approximation for the sum over all segmentations.
    Then we further We are now able to model the three t