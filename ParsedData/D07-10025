rameNet coverage and show howmuch it impacts performance in a TREC-style ques tion answering setting.
			In the following section we provide an overview of existing work on question answering systems that exploit semantic role-based lexical resources.
			Thenwe define our learning task and introduce our approach to semantic role assignment and answer ex traction in the context of QA.
			Next, we present our experimental framework and data.
			We conclude the paper by presenting and discussing our results.
	
	
			Question answering systems have traditionally de pended on a variety of lexical resources to bridge surface differences between questions and potential answers.
			WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004).
			Besides WordNet, recent QA systems increasingly rely on sy