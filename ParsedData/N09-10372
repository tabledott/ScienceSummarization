&#8220;one should solve the problem directly and never solve a more general problem as an intermediate step,&#8221; implying that building a joint model of two phenomena is more likely to harm performance on the individual tasks than to help it.
    Indeed, it has proven very difficult to build a joint model of parsing and semantic role labeling, either with PCFG trees (Sutton and McCallum, 2005) or with dependency trees.
    The CoNLL 2008 shared task (Surdeanu et al., 2008) was intended to be about joint dependency parsing and semantic role labeling, but the top performing systems decoupled the tasks and outperformed the systems which attempted to learn them jointly.
    Despite these earlier results, we found that combining parsing and named entity recognition modestly improved performance on both tasks.
    Our joint model produces an output which has consistent parse structure and named entity spans, and does a better job at both tasks than separate models with the same features.
    We first present the