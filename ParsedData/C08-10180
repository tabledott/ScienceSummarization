
	Sentence Compression Beyond Word Deletion
		In this paper we generalise the sentence compression task.
		Rather than sim ply shorten a sentence by deleting words or constituents, as in previous work, we rewrite it using additional operations such as substitution, reordering, and insertion.
		We present a new corpus that is suitedto our task and a discriminative tree-to tree transduction model that can naturallyaccount for structural and lexical mis matches.
		The model incorporates a novelgrammar extraction method, uses a lan guage model for coherent output, and canbe easily tuned to a wide range of compres sion specific loss functions.
	
	
			Automatic sentence compression can be broadly described as the task of creating a grammaticalsummary of a single sentence with minimal information loss.
			It has recently attracted much attention, in part because of its relevance to applications.
			Examples include the generation of sub titles from spoken transcripts (Vandeghinste and Pan, 2004), the display of text