
	The Infinite PCFG Using Hierarchical Dirichlet Processes
		We present a nonparametric Bayesian model of tree structures based on the hierarchical Dirichlet process (HDP).
		Our HDP-PCFG model allows the complexity of the grammar to grow as more training data is available.
		In addition to presenting a fully Bayesianmodel for the PCFG, we also develop an ef ficient variational inference procedure.
		Onsynthetic data, we recover the correct grammar without having to specify its complexity in advance.
		We also show that our tech niques can be applied to full-scale parsingapplications by demonstrating its effective ness in learning state-split grammars.
	
	
			Probabilistic context-free grammars (PCFGs) havebeen a core modeling technique for many aspects of linguistic structure, particularly syntac tic phrase structure in treebank parsing (Charniak, 1996; Collins, 1999).
			An important question when learning PCFGs is how many grammar symbols to allocate to the learning algorithm based on the amount of availab