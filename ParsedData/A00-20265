ble surface generator is to solve the above two problems in a way that reflects the observed usage of language in a corpus, but without the manual effort needed to construct a grammar or knowledge base.
    All the trainable NLG systems in this paper assume the existence of a large corpus of phrases in which the values of interest have been replaced with their corresponding attributes, or in other words, a corpus of generation templates.
    Figure 1 shows a sample of training data, where only words marked with a &amp;quot;8&amp;quot; are attributes.
    All of the NLG systems in this paper work in two steps as shown in Table 2.
    The systems NLG1, NLG2 and NLG3 all implement step 1; they produce a sequence of words intermixed with attributes, i.e., a template, from the the attributes alone.
    The values are ignored until step 2, when they replace their corresponding attributes in the phrase produced by step 1.
    The surface generation model NLG1 simply chooses the most frequent template in the training