varied with the training and skill of individual annotators).
  For the role classification kappa, we consider only nodes that were marked as arguments by both annotators and compute kappa over the choices of possible argument labels.
  For both role identification and role classification, we compute kappa for two ways of treating ArgM labels.
  The first is to treat ArgM labels as arguments like any other, in which case ArgM-TMP, ArgM-LOC, and so on are considered separate labels for the role classification kappa.
  In the second scenario, we ignore ArgM labels, treating them as unlabeled nodes, and calculate agreement for identification and classification of numbered arguments only.
  Kappa statistics for these various decisions are shown in Table 2.
  Agreement on role identification is very high (.99 under both treatments of ArgM), given the large number of obviously irrelevant nodes.
  Reassuringly, kappas for the more difficult role classification task are also high: .93 including all types of ArgM and 