is distribution.
    It is thus assumed that different senses will correspond to distinct lexical distributions.
    In this framework, sense distinctions arise naturally through the generative process: our model postulates that the observed data (word contexts) are explicitly intended to communicate a latent structure (their meaning).
    Our work is related to Latent Dirichlet Allocation (LDA, Blei et al. 2003), a probabilistic model of text generation.
    LDA models each document using a mixture over K topics, which are in turn characterized as distributions over words.
    The words in the document are generated by repeatedly sampling a topic according to the topic distribution, and selecting a word given the chosen topic.
    Whereas LDA generates words from global topics corresponding to the whole document, our model generates words from local topics chosen based on a context window around the ambiguous word.
    Document-level topics resemble general domain labels (e.g., finance, education) and cannot