tive frequency (Spearman&#8217;s p = &#8722;0.56).
    Although from a statistical perspective it is expected that we get better results where we have more data, from a linguistic point of view it is interesting that alm works best with extremely frequent, highly polysemous adjectives like new, large and different, that border on function words &#8211; a domain where distributional semantics has generally not been tested.
    Although, in relative terms and considering the difficulty of the task, alm performs well, it is still far from perfect &#8211; for 27% alm-predicted ANs, the observed vector is not even in the top 1K neighbor set!
    A qualitative look at some of the most problematic examples indicates however that a good proportion of them might actually not be instances where our model got the AN vector wrong, but cases of anomalous observed ANs.
    The left side of Table 4 compares the nearest neighbors (excluding each other) of the observed and alm-predicted vectors in 10 ranSIMILAR DISSIMILAR adj