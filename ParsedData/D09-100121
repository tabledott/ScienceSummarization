larly severe for log-linear models with hard constraints, which are common in MLNs.
    For example, in our USP MLN, conditioned on the fact that p E c, there is exactly one value of f that can satisfy the formula p E c n Form(p, f), and if we add some constant number to the weights of p E c n Form(p, f) for all f, the probability distribution stays the same.6 The learner can be easily confused by the infinitely many optima, especially in the early stages.
    To address this problem, we impose local normalization constraints on specific groups of formulas that are mutually exclusive and exhaustive, i.e., in each group, we require that Eki=1 ewi = 1, where wi are the weights of formulas in the group.
    Grouping is done in such a way as to encourage the intended mixture behaviors.
    Specifically, for the rule p E +c n Form(p,+f), all instances given a fixed c form a group; for each of the remaining three rules, all instances given a fixed a form a group.
    Notice that with these constraints the completio