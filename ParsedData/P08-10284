consider different classes of models.
    Specifically, we present both additive and multiplicative models of vector combination and assess their performance on a sentence similarity rating experiment.
    Our results show that the multiplicative models are superior and correlate significantly with behavioral data.
  
  
    The problem of vector composition has received some attention in the connectionist literature, particularly in response to criticisms of the ability of connectionist representations to handle complex structures (Fodor and Pylyshyn, 1988).
    While neural networks can readily represent single distinct objects, in the case of multiple objects there are fundamental difficulties in keeping track of which features are bound to which objects.
    For the hierarchical structure of natural language this binding problem becomes particularly acute.
    For example, simplistic approaches to handling sentences such as John loves Mary and Mary loves John typically fail to make valid representations i