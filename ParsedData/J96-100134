n the same.
    Specific mutual information falls somewhere in between the Dice coefficient and average mutual information: it is not completely symmetric but neither does it ignore 0-0 matches.
    This measure is very sensitive to the marginal probabilities (relative frequencies) of the &amp;quot;1&amp;quot;s in the two variables, tending to give higher values as these probabilities decrease.
    Adding 0-0 matches lowers the relative frequencies of &amp;quot;1&amp;quot;s, and therefore always increases the estimate of SI(X, Y).
    Furthermore, as the marginal probabilities of the two word groups become very small, SI(X, Y) tends to infinity, independently of the distribution of matches (including 1-1 and 0-0 ones) and mismatches, as long as the joint probability of 1-1 matches is not zero.
    By taking the limit of SI(X, Y) for p(X =1) &#8212;+0 or p(Y =1) &#8212;+0 in equation (2) we can easily verify that this happens even if the conditional probabilities p(X =1 I Y=1) and p(Y = 1 I X = 1) remain const