ent-based annotations are not provided in our training set.
    The aim of this challenge is to compare the performance of the participating systems in a fair environment.
    Open Challenge - systems can be developed making use of any kind of external tools and resources.
    The only condition is that such tools or resources must not have been developed with the annotations of the test set, both for the input and output annotations of the data.
    In this challenge, we are interested in learning methods which make use of any tools or resources that might improve the performance.
    For example, we encourage the use of semantic information, as provided by NE recognition or word-sense disambiguation (WSD) systems (such state-of-the-art annotations are provided by the organizers, see Table 2).
    Also, in this challenge participants are encouraged to use constituent-based parsers and SRL systems, as long as these systems were trained only with the sections of Penn Treebank used in the shared task training c