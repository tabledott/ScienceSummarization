ferent methods.
    Note that on some examples (around 2% of the test set) CoBoost abstained altogether; in these cases we labeled the test example with the baseline, organization, label.
    Fig.
    (3) shows learning curves for CoBoost.
    N, portion of examples on which both classifiers give a label rather than abstaining), and the proportion of these examples on which the two classifiers agree.
    With each iteration more examples are assigned labels by both classifiers, while a high level of agreement (&gt; 94%) is maintained between them.
    The test accuracy more or less asymptotes.
  
  
    Unlabeled examples in the named-entity classification problem can reduce the need for supervision to a handful of seed rules.
    In addition to a heuristic based on decision list learning, we also presented a boosting-like framework that builds on ideas from (Blum and Mitchell 98).
    The method uses a &amp;quot;soft&amp;quot; measure of the agreement between two classifiers as an objective function; we desc