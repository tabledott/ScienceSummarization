 is already quite high for simple context-free models with O(n3) parsing complexity, but it becomes prohibitive for lexicalized grammars with O(n5) parsing complexity.
    Dependency trees are an alternative syntactic representation with a long history (Hudson, 1984).
    Dependency trees capture important aspects of functional relationships between words and have been shown to be useful in many applications including relation extraction (Culotta and Sorensen, 2004), paraphrase acquisition (Shinyama et al., 2002) and machine translation (Ding and Palmer, 2005).
    Yet, they can be parsed in O(n3) time (Eisner, 1996).
    Therefore, dependency parsing is a potential &#8220;sweet spot&#8221; that deserves investigation.
    We focus here on projective dependency trees in which a word is the parent of all of its arguments, and dependencies are non-crossing with respect to word order (see Figure 1).
    However, there are cases where crossing dependencies may occur, as is the case for Czech (Haji&#711;c, 1998).
