ieve better results than IBM Model 3 in all training corpus sizes.
    Considering Model 3 E &#8594; C of GIZA++ and ours alone, greedy search algorithm described in Section 5 yields surprisingly better alignments than hillclimbing algorithm in GIZA++.
    Table 3 compares the results of log-linear models with IBM Model 5.
    The training scheme is 15H5354555.
    Our log-linear models still make use of the parameters generated by GIZA++.
    Comparing Table 3 with Table 2, we notice that our log-linear models yield slightly better alignments by employing parameters generated by the training scheme 15H5354555 rather than 15H535, which can be attributed to improvement of parameters after further Model 4 and Model 5 training.
    For log-linear models, POS information and an additional dictionary are used, which is not the case for GIZA++/IBM models.
    However, treated as a method for performing symmetrization, log-linear combination alone yields better results than intersection, union, and refined methods.
