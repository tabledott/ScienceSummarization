he larger m-oracle size seems to be harmful if coupled with the 1-best list.As indicated by the reduced active feature size, 1 best translation seems to be updated toward worse translations in 10-oracles that are ?close?
			in terms of features.
			We achieved significant improvements 770 Table 4: Two-fold cross validation experiments.
			closed test open test NIST BLEU NIST BLEU [%] [%] baseline 10.71 44.79 10.68 44.44 online 11.58 53.42 10.90 47.64 when the k-best list size was also increased.
			The use of sentence-wise BLEU as an objective provides almost no improvement in the 2005 test set, but is comparable for the 2004 test set.
			As observed in three experiments, the 2004/2005 test sets behaved differently, probably because ofthe domain mismatch.
			Thus, we conducted a two fold cross validation using the 2003/2004/2005 test sets to observe the effect of optimization as shown in Table 44.
			The MERT baseline system performedsimilarly both in closed and open tests.
			Our online large-margin training