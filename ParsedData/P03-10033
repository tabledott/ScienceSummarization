erlap with any question term, but it does contain the correct answer.
    To circumvent this limitation of word-based similarity metrics, QA researchers have developed methods through which they first map questions and sentences that may contain answers in different spaces, and then compute the &#8220;similarity&#8221; between them there.
    For example, the systems developed at IBM and ISI map questions and answer sentences into parse trees and surfacebased semantic labels and measure the similarity between questions and answer sentences in this syntactic/semantic space, using QA-motivated metrics.
    The systems developed by CYC and LCC map questions and answer sentences into logical forms and compute the &#8220;similarity&#8221; between them using inference rules.
    And systems such as those developed by IBM and BBN map questions and answers into feature sets and compute the similarity between them using maximum entropy models that are trained on question-answer corpora.
    From this perspective then,