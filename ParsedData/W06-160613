e fully realized.
    Our hope is that the rules headed by pseudo nonterminals could make available to an SPMT system all the rules that are typically available to a phrase-based system; and that the sibling rules could provide a sufficiently robust generalization layer for integrating pseudo, partially realized constituents into the overall decoding process.
    The SPMT composed model 2 uses all rule types described in the previous models.
    For each model, we extract all rule instances that are licensed by a symmetrized Giza-aligned parallel corpus and the constraints we put on the model.
    We condition on the root node of each rule and use the rule counts f(r) and a basic maximum likelihood estimator to assign to each rule type a conditional probability (see equation 5).
    It is unlikely that this joint probability model can be discriminative enough to distinguish between good and bad translations.
    We are not too concerned though because, in practice, we decode using a larger set of submodels (f