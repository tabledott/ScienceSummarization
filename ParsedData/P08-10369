d,i = gl choose global topic zd,i &#8764; &#65533;gl d , &#8211; if rd,i=loc choose local topic zd,i&#8764;&#65533;loc d,vd,i, &#8211; choose word wd,i from the word distribution &#65533;rd,i zd,i.
    Beta(&#945;mix) is a prior Beta distribution for choosing between local and global topics.
    In Figure 3a the corresponding graphical model is presented.
    MG-LDA constructs a set of topics that ideally correspond to ratable aspects of an entity (often in a many-to-one relationship of topics to aspects).
    A major shortcoming of this model &#8211; and all other unsupervised models &#8211; is that this correspondence is not explicit, i.e., how does one say that topic X is really about aspect Y?
    However, we can observe that numeric aspect ratings are often included in our data by users who left the reviews.
    We then make the assumption that the text of the review discussing an aspect is predictive of its rating.
    Thus, if we model the prediction of aspect ratings jointly with the construction of e