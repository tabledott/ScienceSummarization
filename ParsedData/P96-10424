les they consume.
    Finally, we study the effect of sample selection on the size of the model acquired by the learner.
  
  
    This section presents the framework and terminology assumed for probabilistic classification, as well as its instantiation for stochastic bigram part-ofspeech tagging.
    A probabilistic classifier classifies input examples e by classes c E C, where C is a known set of possible classes.
    Classification is based on a score function, Fm (c, e), which assigns a score to each possible class of an example.
    The classifier then assigns the example to the class with the highest score.
    Fm is determined by a probabilistic model M. In many applications, Fm is the conditional probability function, Pm (cle), specifying the probability of each class given the example, but other score functions that correlate with the likelihood of the class are often used.
    In stochastic part-of-speech tagging, the model assumed is a Hidden Markov Model (HMM), and input examples are sentences.
  