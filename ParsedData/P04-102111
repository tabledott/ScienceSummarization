ion algorithm The aligning process is different from that of transliteration given in eqn.
    (4) or (5) in that, here we have fixed bilingual entries, &#945; and &#946; .
    The aligning process is just to find the alignment segmentation &#947; between the two strings that maximizes the joint probability: A set of transliteration pairs that is derived from the aligning process forms a transliteration table, which is in turn used in the transliteration decoding.
    As the decoder is bounded by this table, it is important to make sure that the training database covers as much as possible the potential transliteration patterns.
    Here are some examples of resulting alignment pairs.
    Knowing that the training data set will never be sufficient for every n-gram unit, different smoothing approaches are applied, for example, by using backoff or class-based models, which can be found in statistical language modeling literatures (Jelinek, 1991).
    Although in the literature, most noisy channel models (NCM) a