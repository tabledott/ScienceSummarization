 vast majority of the contributions come from a single synset.
			1029 0.275 0.28 0.285 0.29 0.295 0.3 0.305 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 Accuracy Iteratio n Unsee ded Seede d with LDA 96000 94000 92000 90000 88000 86000 84000 82000 80000 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 Model Probability Iteratio n Unsee ded Seede d with LDA Figure 3: Topics seeded with LDA initially have a higher disambiguation accuracy, but are quickly matched by unseeded topics.
			The probability for the seeded topics starts lower and remains lower.
			4.2 Topics and the Weight of the Prior.
			Because the Dirichlet smoothing factor in partdetermines the topics, it also affects the disambiguation.
			Figure 4 shows the modal disambigua tion achieved for each of the settings of S = {0.1, 1, 5, 10, 15, 20}.
			Each line is one setting of K and each point on the line is a setting of S. Each data point is a run for the Gibbs sampler for 10,000 iterations.
			The disambiguation, taken at the mode,im