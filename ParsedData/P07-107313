other bags, subseguments.
    Words that are semantically correlated quence patterns containing these words will be given with either of the two arguments are likely to oc- too much weight in the learned model.
    This is probcur in many sentences.
    For example, consider the lematic, since these words can appear in many other sentences 51 and 52 from the bag associated with frames, and thus the learned model is likely to make &#8220;Google&#8221; and &#8220;YouTube&#8221; (as shown in Figure 1). errors.
    Instead, we would like the model to foThey both contain the words &#8220;search&#8221; &#8211; highly cor- cus on words that trigger the target relationship (in related with &#8220;Google&#8221;, and &#8220;video&#8221; &#8211; highly corre- FrameNet, these are the lexical units associated with lated with &#8220;YouTube&#8221;, and it is likely that a signifi- the target frame). cant percentage of sentences in this bag contain one 5.1 A Solution for Type I Bias of the two words (or both).
    The two e