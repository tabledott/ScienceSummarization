e the average performance of 3 treebanking experts on a set of 300 randomly selected test events from the WSJ corpus, first looking at the four head words alone, then using the whole sentence.
    A reasonable lower bound seems to be 72.2% as scored by the 'Most likely for each preposition' method.
    An approximate upper bound is 88.2% - it seems unreasonable to expect an algorithm to perform much better than a human.
  
  
    We will use the symbol f to denote the number of times a particular tuple is seen in training data.
    For example f(1, is, revenue, from, research) is the number of times the quadruple (is, revenue, from, research) is seen with a noun attachment.
    Counts of lower order tuples can also be made - for example 1(1, P = from) is the number of times (P = from) is seen with noun attachment in training data, f(V = is, N2 = research) is the number of times (V = is, N2 = research) is seen with either attachment and any value of Ni and P. A maximum likelihood method would use the training 