
    The system has been extended with automated language identification, and scaled up to the point where a nontrivial parallel corpus of English and French can be produced completely automatically from the World Wide Web.
    In the process, it was discovered that the most lightweight use of language identification, restricted to just the the language pair of interest, needed to be revised in favor of a strategy that includes identification over a wide range of languages.
    Rigorous evaluation using human judges suggests that the technique produces an extremely clean corpus &#8212; noise estimated at between 0 and 8% &#8212; even without human intervention, requiring no more resources per language than a relatively small sample of text used to train automatic language identification.
    Two directions for future work are apparent.
    First, experiments need to be done using languages that are less common on the Web.
    Likely first pairs to try include English-Korean, English-Italian, and English-Greek