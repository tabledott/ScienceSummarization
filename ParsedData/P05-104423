H is learning a correct distribution, but that distribution is not helpful for the task.
    The improvement from adding spelling features is striking: DELORTRANS1 and TRANS1 recover nearly completely (modulo the model selection problem) from the diluted dictionaries.
    LENGTH sees far less recovery.
    Hence even our improved feature sets cannot compensate for the choice of neighborhood.
    This highlights our argument that a neighborhood is not an approximation to log-linear EM; LENGTH tries very hard to approximate log-linear EM but requires a good dictionary to be on par with the other criteria.
    Good neighborhoods, rather, perform well in their own right.
  
  
    Foremost for future work is the &#8220;minimally supervised&#8221; paradigm in which a small amount of labeled data is available (see, e.g., Clark et al. (2003)).
    Unlike well-known &#8220;bootstrapping&#8221; approaches (Yarowsky, 1995), EM and CE have the possible advantage of maintaining posteriors over hidden labels (or structure