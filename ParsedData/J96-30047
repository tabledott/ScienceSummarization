 names such as 'Malaysia.'
    Again, famous place names will most likely be found in the but less well-known names, such as (as in the New Jersey town name 'New Brunswick') will not generally be found.
    In this paper we present a stochastic finite-state model for segmenting Chinese text into words, both words found in a (static) lexicon as well as words derived via the above-mentioned productive processes.
    The segmenter handles the grouping of hanzi into words and outputs word pronunciations, with default pronunciations for hanzi it cannot group; we focus here primarily on the system's ability to segment text appropriately (rather than on its pronunciation abilities).
    The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.
    It also incorporates the Good-Turing method (Baayen 1989; Church and Gale 1991) in estimating the likelihoods of previously unseen constructions, including morphological derivatives and personal