lowing characteristics: i) It performs learning and classification using structural information of text. ii) It uses a set of all subtrees (bag-of-subtrees) for the feature set without any constraints. iii) Even though the size of the candidate feature set becomes quite large, it automatically selects a compact and relevant feature set based on Boosting.
    This paper is organized as follows.
    First, we describe the details of our Boosting algorithm in which the subtree-based decision stumps are applied as weak learners.
    Second, we show an implementation issue related to constructing an efficient learning algorithm.
    We also discuss the relation between our algorithm and SVMs (Boser et al., 1992) with tree kernel (Collins and Duffy, 2002; Kashima and Koyanagi, 2002).
    Two experiments on the opinion and modality classification tasks are employed to confirm that subtree features are important.
  
  
    We first assume that a text to be classified is represented as a labeled ordered tree.
    The 