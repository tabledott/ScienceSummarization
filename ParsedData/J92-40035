 depends on a delicate interplay between the language model and other components of the system.
    One language model may surpass another as part of a speech recognition system but perform less well in a translation system.
    However, because it is expensive to evaluate a language model in the context of a complete system, we are led to seek an intrinsic measure of the quality of a language model.
    We might, for example, use each language model to compute the joint probability of some collection of strings and judge as better the language model that yields the greater probability The perplexity of a language model with respect to a sample of text, S. is the reciprocal of the geometric average of the probabilities of the predictions in S. If S has I S I words, then the perplexity is Pr (5)-1/1s1.
    Thus, the language model with the smaller perplexity will be the one that assigns the larger probability to S. Because the perplexity depends not only on the language model but also on the text with respect 