yielded mixed results.
    In the past few years, researchers have begun to view generative models as instances of a broader class of linear (or log-linear) models, and have introduced discriminative methods (e.g. conditional random fields) to estimate the model parameters.
    These estimation methods do not impose the same strict independence conditions as generative models.
    Armed with modern discriminative training methods, it seemed reasonable to us to revisit hierarchical clustering.
    Specifically, we picked up where Spatter left off, with the clustering algorithm of (Brown et al., 1990).
    We implemented this algorithm twice as part of our work.
    The first implementation derived directly from the description given in the Brown paper.
    Then, in the hope of achieving greater efficiency, we reverseengineered the clustering software in Spatter.
    While the mathematical details differ slightly between the two algorithms, both aim to cluster together words so as to minimize the bigram languag