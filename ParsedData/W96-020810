Wall Street Journal, the &amp;quot;product&amp;quot; sense is more than 5 times as common as any of the others.
    Previous studies have first sampled the data so that all senses were equally represented.
    Leacock et al. (1993b), Leacock, Towell, and Voorhees (1993a) and Voorhees, Leacock, and Towell (1995) present results on a Bayesian method (Gale, Church, &amp; Yarowsky, 1992a), a content vector method from information retrieval (Salton, Wong, &amp; Yang, 1975), and a neural network trained using backpropagation (Rumelhart, Hinton, &amp; Williams, 1986).
    The neural network architecture that performed at least as well as any other contained no hidden units, so was effectively equivalent to a perceptron.
    On the six-sense task trained on 1,200 examples and averaged over three random trials, they report the following generalization accuracies: Bayesian, 71%; content vectors, 72%; neural nets, 76%.
    None of these differences were statistically significant given the small number of trials.
    In 