e, is $f ,  = d)f,(h, d) h,d The values of these k parameters can be obtained by one of many iterative algorithms.
  For example, one can use the Gen- eralized Iterative Scaling algorithm of Darroch and Ratcliff [3].
  As one increases the number of features, the achievable maximum of the training data likelihood increases.
  We de- scribe in Section 3 a method for determining a reliable set of features.
  Features Feature functions allow us to use informative characteristics of the training set in estimating p(dlh).
  A feature is defined as follows: -.~(h,d) d~_f ~1, i f fd=OandVq6 Q~,q(h)= 1 O, otherwise.
  I. where Q~ is a set of binary-valued questions about h. We restrict he questions in any Q~ ask only about he following four head words: I.
  Head Verb (V) 2.
  Head Noun (N1) 3.
  Head Preposition (P) .
  Questions that involve the class membership of a head word.
  we use a binary hierarchy of classes derived by mutual information clustering which we describe below.
  Given a binary class hierarchy, w