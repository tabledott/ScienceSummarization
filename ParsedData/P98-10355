izes the above description of the sequential generation of a sentence with a complete parse.
    The unary transition is allowed only when the most recent exposed head is a leaf of the tree &#8212; a regular word along with its POStag &#8212; hence it can be taken at most once at a given position in the input word string.
    The second subtree in Figure 2 provides an example of a unary transition followed by a null transition.
    It is easy to see that any given word sequence with a possible parse and headword annotation is generated by a unique sequence of model actions.
    This will prove very useful in initializing our model parameters from a treebank &#8212; see section 3.5.
  
  
    The probability P(W,T) of a word sequence W and a complete parse T can be broken into: where: As can be seen, (wk,tk,Wk--171-1, Pt &#8226; &#8226; &#8226; 14 1) is one of the Nk word-parse k-prefixes WkTk at position k in the sentence, i = I, Nk.
    To ensure a proper probabilistic model (1) we have to make sure that (2)