fusion resulting from the fact that the two fields share much of the same vocabulary (e.g [ADDRESS 2525 Telegraph Ave.] vs. [NBRHD near Telegraph]).
    Acknowledgments We would like to thank the anonymous reviewers for their comments.
    This work is supported by a Microsoft / CITRIS grant and by an equipment donation from Intel.
  
  
    We have shown that distributional prototype features can allow one to specify a target labeling scheme in a compact and declarative way.
    These features give substantial error reduction on several induction tasks by allowing one to link words to prototypes according to distributional similarity.
    Another positive property of this approach is that it tries to reconcile the success of sequence-free distributional methods in unsupervised word clustering with the success of sequence models in supervised settings: the similarity guides the learning of the sequence model.
  

