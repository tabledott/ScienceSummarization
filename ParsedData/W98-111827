his system makes less use of dictionaries.
    On the other hand, his system looks at word suffixes and prefixes in the case of unknown words, which is something we haven't tried with MENE and looks at its own output by looking at its previous two tags when making its decision.
    We do this implicitly through our requirement that the futures we output be consistent, but we found that an attempt to do this more directly by building a consistency feature directly into the model had no effect on our results.
    At the MUC-7 conference, there were two other interesting systems using statistical techniques from the Language Technology Group/University of Edinborough (Mikheev and Grover, 1998) and BBN (Miller et al., 1998).
    Comparisons with the LTG system are difficult since it was a hybrid model in which the text was passed through a five-stage process, only three of which involved maximum entropy and over half of the system's recall came from the two non-statistical phases.
    The LTG system demonstrated 