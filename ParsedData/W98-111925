stem.
    They use Japanese newspaper articles tagged with discourse information as training examples for a machine-learning algorithm which is the C4.5 derision-tree algorithm by Quinlan (1993).
    They train their decision tree using (anaphora, antecedent) pairs together with a set of feature vectors.
    Among the 66 features are lexical, syntactic, semantic, and positional features.
    Their Machine Learning-based Resolver (MLR) is trained using decision trees with 1971 anaphoras (excluding those referring to multiple discontinuous antecedents) and they report an average success rate of 74.8%.
    Mitkov (1997) describes an approach that uses a set of factors as constraints and preferences.
    The constraints rule out implausible candidates and the preferences emphasize the selection of the most likely antecedent.
    The system is not entirely &amp;quot;statistical&amp;quot; in that it consists of various types of rule-based knowledge &#8212; syntactic, semantic, domain, discourse, and heuristic.
    