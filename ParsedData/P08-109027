ossible to learn narrative event chains unsupervised from raw text.
    Not only do our narrative relations show improvements over a baseline, but narrative chains offer hope for many other areas of NLP.
    Inference, coherence in summarization and generation, slot filling for question answering, and frame induction are all potential areas.
    We learned a new measure of similarity, the narrative relation, using the protagonist as a hook to extract a list of related events from each document.
    The 37% improvement over a verb-only baseline shows that we may not need presorted topics of documents to learn inferences.
    In addition, we applied state of the art temporal classification to show that sets of events can be partially ordered.
    Judgements of coherence can then be made over chains within documents.
    Further work in temporal classification may increase accuracy even further.
    Finally, we showed how the event space of narrative relations can be clustered to create discrete sets.
    While 