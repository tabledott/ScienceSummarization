n learning.
    Transformation-based error-driven learning has been applied to a number of natural language problems, including part of speech tagging, prepositional phrase attachment disambiguation, speech generation and syntactic parsing [Brill, 1992; Brill, 1994; Ramshaw and Marcus, 1994; Roche and Schabes, 1995; Brill and Resnik, 1994; Huang et al., 1994; Brill, 1993a; Brill, 1993b].
    Figure 1 illustrates the learning process.
    First, unannotated text is passed through an initial-state annotator.
    The initial-state annotator can range in complexity from assigning random structure to assigning the output of a sophisticated manually created annotator.
    Once text has been passed through the initial-state annotator, it is then compared to the truth as specified in a manually annotated corpus, and transformations are learned that can be applied to the output of the initial state annotator to make it better resemble the truth.
    In all of the applications explored to date, the following greedy sea