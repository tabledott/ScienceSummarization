w (Section 4.2).
    The second-best parameters according to the optimisation process were a context of 510 tokens taken before an emoticon, from a training set of 20,000 examples.
    We used these optimised parameters to evaluate the sentiments of texts in the test sets used to evaluate dependency in Section 2.
    Figures 5, 6 and 7 show the final, optimised results across topics, domains and time-periods respectively.
    These tables report the average accuracies over three folds, with the standard deviation as a measure of error.
  
  
    The emoticon-trained classifiers perform well (up to 70% accuracy) when predicting the sentiment of article extracts from the Emoticons dataset, which is encouraging when one considers the high level of noise that is likely to be present in the dataset.
    However, they perform only a little better than one would expect by chance when classifying movie reviews, and are not effective in predicting the sentiment of newswire articles.
    This is perhaps due to the natu