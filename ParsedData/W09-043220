 than the intermediate configuration (b), which seems the best one.
    In conclusion, we found that the size of the n-best list has essentially no effect on the quality of the final weights, but it impacts significantly on the computational time.
    Moreover, using the regular development set with few translation alternatives ends up to be the most efficient configuration in terms of computational effort, robustness, and performance.
    Our analysis suggests that it is important to dispose of a sufficiently large development set although reasonably good weights can be obtained even if such data are very few.
    A set of experiments was devoted to the adaptation of the LM only.
    We trained three different LMs on increasing portions of the EP and we employed them either alone or in combination with the background LM trained on the UN corpus.
    Percentage of monolingual English adaptation data systems.
    The absolute gain with respect to the baseline is fairly high, even with the smallest amount of ad