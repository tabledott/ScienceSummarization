ova et al, 2003) and achieved the best ac curacy on POS tagging on the Wall Street Journal corpus.
			As they pointed out in their paper, however,their method potentially suffers from ?collusion?
			ef fects which make the model lock onto conditionally consistent but jointly unlikely sequences.
			In theirmodeling, the local classifiers can always use the in formation about future tags, but that could cause a double-counting effect of tag information.
			In this paper we propose an alternative way of making use of future tags.
			Our inference method considers all possible ways of decomposition andchooses the ?best?
			decomposition, so the informa tion about future tags is used only in appropriate situations.
			We also present a deterministic versionof the inference method and show their effective ness with experiments of English POS tagging and chunking, using standard evaluation sets.
	
	
			The task of labeling sequence data is to find the se quence of tags t1...tn that maximizes the following probabilit