, which allow easy integration of context-specific features.
    Log-linear models, which are very suitable to incorporate additional dependencies, have been successfully applied to statistical machine translation (Och and Ney, 2002).
    In this paper, we present a framework for word alignment based on log-linear models, allowing statistical models to be easily extended by incorporating additional syntactic dependencies.
    We use IBM Model 3 alignment probabilities, POS correspondence, and bilingual dictionary coverage as features.
    Our experiments show that log-linear models significantly outperform IBM translation models.
    We begin by describing log-linear models for word alignment.
    The design of feature functions is discussed then.
    Next, we present the training method and the search algorithm for log-linear models.
    We will follow with our experimental results and conclusion and close with a discussion of possible future directions.
  
  
    Formally, we use following definition for al