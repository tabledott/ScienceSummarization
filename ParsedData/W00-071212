x.
    The product aw= avk is the projection of 6T into the k-dimensional latent semantic space.
    By storing an index to the words of the corpus as well as a sorted list of these words, one can efficiently build a set of semantic vectors which includes each word of interest.
    Morphologically-related words frequently share similar semantics, so we want to see how well semantic vectors of PPMVs correlate.
    If we know how PPMVs correlate in comparison to other word pairs from their same rulesets, we can actually determine the semantic-based probability that the variants are legitimate.
    In this section, we identify a measure for correlating PPMVs and illustrate how ruleset-based statistics help identify legitimate PPMVs.
    The cosine of the angle between two vectors v1 and v2 is given by, We want to determine the correlation between each of the words of every PPMV.
    We use what we call a normalized cosine score (NCS) as a correlation.
    To obtain a NCS, we first calculate the cosine between ea