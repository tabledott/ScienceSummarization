 sets, one for each of the components of the candidate NCC: (11) where terms in All the Equation 12 depend only on the probability distributions Pr(x, t), Pr(x : RC = y, t) and Pr(x : RC 0 y, t).
    All the terms in Equation 13 depend only on Pr(y, t), Pr(y : LC = x, t) and Pr(y : LC 0 x, t).
    These distributions can be computed efficiently by memory-external sorting and streamed accumulation.
  
  
    In bag-of-words translation, each word in the source text is simply replaced with its most likely translation.
    No target language model is involved.
    For this application, it is sufficient to predict only the maximum likelihood translation of each source word.
    The rest of the translational distribution can be ignored.
    Let mr(s) be the most likely translation of each source word s, according to the translation model: Again, I will write simply m(s) when T is clear from the context.
    The objective function V for this application follows by analogy with the mutual information function / in E