estigated, as they could lead to a sensible improvement of the performance.
    As for the LONG pairs, which represented a new element of this year&#8217;s challenge, no substantial difference was noted in the systems&#8217; performances: the average accuracy over the long pairs was 58.72%, compared to 61.93% over the short ones.
  
  
    At its third round, the Recognizing Textual Entailment task has reached a noticeable level of maturity, as the very high interest in the NLP community and the continuously increasing number of participants in the challenges demonstrate.
    The relevance of Textual Entailment Recognition to different applications, such as the AVE5 track at QA at CLEF6, has also been acknowledged.
    Furthermore, the debates and the numerous publications about the Textual Entailment have contributed to the better understanding the task and its nature.
    To keep a good balance between the consolidated main task and the need for moving forward, longer texts were introduced in the dataset, i