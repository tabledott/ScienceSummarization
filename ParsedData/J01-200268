ry clear anyway.
    For part-of-speech tagging, a significant increase in accuracy through combining the output of different taggers was first demonstrated in van Halteren, Zavrel, and Daelemans (1998) and Brill and Wu (1998).
    In both approaches, different tagger generators were applied to the same training data and their predictions combined using different combination methods, including stacking.
    Yet the latter paper reported much lower accuracy improvement figures.
    As we now apply the methods of van Halteren, Zavrel, and Daelemans (1998) to WSJ as well, it is easier to make a comparison.
    An exact comparison is still impossible, as we have not used the exact same data preparation and taggers, but we can put roughly corresponding figures side by side (Table 13).
    As for base taggers, the first two differences are easily explained: Unigram has to deal with unknown words, while LexProb does not, and TnT is a more advanced trigram system.
    The slight difference for Maximum Entropy might b