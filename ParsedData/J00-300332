 We found, however, that an ME model using n-gram constraints performed only slightly better than a corresponding backoff n-gram.
    Additional constraints such as DA triggers, distance-1 bigrams, separate encoding of speaker change and bigrams to the last DA on the same/other channel did not improve relative to the trigram model.
    The ME model thus confirms the adequacy of the backoff n-gram approach, and leads us to conclude that DA sequences, at least in the Switchboard domain, are mostly characterized by local interactions, and thus modeled well by low-order n-gram statistics for this task.
    For more structured tasks this situation might be different.
    However, we have found no further exploitable structure.
    We now describe in more detail how the knowledge sources of words and prosody are modeled, and what automatic DA labeling results were obtained using each of the knowledge sources in turn.
    Finally, we present results for a combination of all knowledge sources.
    DA labeling accurac