means.
    Both models have been used to achieve state-of-the-art accuracy for a wide range of languages, as shown in the CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007), but McDonald and Nivre (2007) showed that a detailed error analysis reveals important differences in the distribution of errors associated with the two models.
    In this paper, we consider a simple way of integrating graph-based and transition-based models in order to exploit their complementary strengths and thereby improve parsing accuracy beyond what is possible by either model in isolation.
    The method integrates the two models by allowing the output of one model to define features for the other.
    This method is simple &#8211; requiring only the definition of new features &#8211; and robust by allowing a model to learn relative to the predictions of the other.
  
  
    Given a set L = 1l1, ... ,l|L|} of arc labels (dependency relations), a dependency graph for an input sentence x = w0, w1,