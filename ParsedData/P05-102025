pt the common convention of assigning rank to the -th highest scored partition.
    (1) despite its modest improvement over the baselines, our approach offers robust performance across the data sets; and (2) we could obtain better scores by improving the ranking model and expanding our set of candidate partitions, as elaborated below.
    To improve the ranking model, we can potentially (1) design new features that better characterize a candidate partition (e.g., features that measure the size and the internal cohesion of a cluster), and (2) reserve more labeled data for training the model.
    In the latter case we may have less data for training coreference classifiers, but at the same time we can employ weakly supervised techniques to bootstrap the classifiers.
    Previous attempts on bootstrapping coreference classifiers have only been mildly successful (e.g., M&#168;uller et al. (2002)), and this is also an area that deserves further research.
    To expand our set of candidate partitions, we can potent