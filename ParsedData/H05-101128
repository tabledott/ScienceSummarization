ur.
	
	
			When the first version of this paper was submitted for review, we could honestly state, ?We are not aware of any previous work on discriminative word alignment models.?
			Callison-Burch et al (2004) had investigated the use of small amounts of annotated data to help train the IBM and HMMmodels, but the models were still generative and were trained using maximum-likelihood methods.Recently, however, three efforts nearly simultaneous with ours have made use of discriminative meth ods to train alignment models.
			Fraser and Marcu(2005) modify Model 4 to be a log-linear combina tion of 11 submodels (5 based on standard Model 4 parameters, and 6 based on additional features) and discriminatively optimize the submodel weights on each iteration of a Viterbi approximation to EM.
			Liu et al (2005) also develop a log-linear model,based on IBM Model 3.
			They train Model 3 us ing Giza++, and then use the Model 3 score of apossible alignment as a feature value in a discriminatively trained log-linear mode