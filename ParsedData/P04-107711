ni et al. 2001).
    In two recent large-scale machine translation evaluations sponsored by NIST, a closely related automatic evaluation method, simply called NIST score, was used.
    The NIST (NIST 2002) scoring method is based on BLEU.
    The main idea of BLEU is to measure the similarity between a candidate translation and a set of reference translations with a numerical metric.
    They used a weighted average of variable length ngram matches between system translations and a set of human reference translations and showed that the weighted average metric correlating highly with human assessments.
    BLEU measures how well a machine translation overlaps with multiple human translations using ngram co-occurrence statistics.
    N-gram precision in BLEU is computed as follows: Where Countclip(n-gram) is the maximum number of n-grams co-occurring in a candidate translation and a reference translation, and Count(ngram) is the number of n-grams in the candidate translation.
    To prevent very short translat