hat ASO-semi is also an &#8216;indirect approach&#8217;.
    On the other hand, our approach is a &#8216;direct approach&#8217; because the distribution of y obtained from JESS-CM is used as &#8216;seeds&#8217; of hidden states during MDF estimation for join PM parameters (see Section 4.1).
    In addition, MDF estimation over unlabeled data can effectively incorporate the &#8216;labeled&#8217; training data information via a &#8216;bias&#8217; since A included in A(x, y) is estimated from labeled training data.
  
  
    We proposed a simple yet powerful semi-supervised conditional model, which we call JESS-CM.
    It is applicable to large amounts of unlabeled data, for example, at the giga-word level.
    Experimental results obtained by using JESS-CM incorporating 1Gwords of unlabeled data have provided the current best performance as regards POS tagging, syntactic chunking, and NER for widely used large test collections such as PTB III, CoNLL&#8217;00 and &#8217;03 shared task data, respectively.
    We 