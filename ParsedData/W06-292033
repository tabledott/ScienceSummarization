ings of i are the already found children of j; structural context (sc) other than children/siblings: neighboring subtrees/spans, or ancestors of i and j; distance from i to j; information derived from all the tokens in between i and j (e.g. whether there is an intervening verb or how many intervening commas there are); global features (e.g. does the sentence contain a finite verb); explicit feature combinations (depending on the learner, these might not be necessary, e.g. a polynomial kernel routinely combines features); for classifier-based parsers: the previous actions, i.e. classifications; whether information about labels is used as input for other decisions.
    Finally, the precise set of features can be optimized per language.
  
  
    Table 5 shows the official results for submitted parser outputs.31 The two participant groups with the highest total score are McDonald et al. (2006) and Nivre et al.
    (2006).
    As both groups had much prior experience in multilingual dependency parsing (see Sectio