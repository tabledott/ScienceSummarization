tric like the NIST Machine Translation Workshop does (Przybocki and Peterson, 2008), we define the manual evaluation to be primary, and use 3Since the performance of systems varied significantly between the Europarl and News test sets, such weighting might not be optimal.
    However this was a level playing field, since none of the individual systems had development data for the News set either.
    Europarl corpus and from the Project Syndicate, a web site which collects political commentary in multiple languages.
    For Czech and Hungarian we use other available parallel corpora.
    Note that the number of words is computed based on the provided tokenizer and that the number of distinct words is the based on lowercased tokens. the human judgments to validate automatic metrics.
    Manual evaluation is time consuming, and it requires a monumental effort to conduct it on the scale of our workshop.
    We distributed the workload across a number of people, including shared task participants, interested volu