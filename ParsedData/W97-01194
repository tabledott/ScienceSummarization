e to shed some light on this question.
  
  
    In our experiments, we use two sets of non-parallel corpora: (1) Wall Street Journal (WSJ) from 1993 and 1994, divided into two non-overlapping parts.
    Each resulting English corpus has 10.36M bytes of data.
    (2) Wall Street Journal in English and Nikkei Financial News in Japanese, from the same time period.
    The WSJ text contains 49M bytes of data, and the Nikkei 127M bytes.
    Since the Nikkei is encoded in two-byte Japanese character sets, the latter is equivalent to about 60M bytes of data in English.
    The English Wall Street Journal non-parallel corpus gives us an easier test set on which to start.
    The output of this corpus should consist of words matching to themselves as translations.
    It is useful as a baseline evaluation test set providing an estimate on performance.
    The WSJ/Nikkei corpus is the most non-parallel type of corpus.
    In addition to being written in languages across linguistic families by different journalists, WS