lgorithm (which we call a lightweight dependency analyzer (LDA)) produces dependency linkages not necessarily spanning the entire sentence.
    The LDA can produce a number of partial linkages, since it is driven primarily by the need to satisfy local constraints without being driven to construct a single dependency linkage that spans the entire input.
    This, in fact, contributes to the robustness of LDA and promises to be a useful tool for parsing sentence fragments that are rampant in speech utterances, as exemplified by the Switchboard corpus.
    Tested on section 20 of the Wall Street Journal corpus, which contained 47,333 dependency links in the gold standard, the LDA, trained on 200,000 words, produced 38,480 dependency links correctly, resulting in a recall score of 82.3%.
    Also, a total of 41,009 dependency links were produced by the LDA, resulting in a precision score of 93.8%.
    A detailed evaluation of the LDA is presented in Srinivas (199M).
  
  
    Although we have presented supertaggi