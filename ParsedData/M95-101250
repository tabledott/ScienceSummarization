ognized from first principles .
  We decided to compare this strategy with one that uses a large lexicon of organization names .
  All of the Muc-6 NE training set was used to generate a list of i,8o8 distinct organization name strings .
  This could certainly be larger, but seemed a reasonable size .
  Nonetheless, this lexicon by itself got less than half of the organizations in the official named-entity test corpus : organization recall was 45 and precision 91 .
  Another interesting question is how much an organization lexicon might have helped had it been added to our rule-based phrasing algorithm, not simply used by itself.
  This configuration actually decreased ou r performance slightly (F-score down by 0 .5 points of P&amp;R), trading a slight increase in organization recall for a larger decrease in precision .
  The biggest problem here is due to overgeneration (up from 4% to 6%), and partial matches such as the following, Kraft &lt;ENAMEX&gt;General Foods&lt;/ENAMEX &gt; First &lt; E NA M EX&gt; Fi