
  Using a Dependency Parser to Improve SMT for Subject-Object-Verb Languages
  
    We introduce a novel precedence reordering approach based on a dependency parser to statistical machine translation systems.
    Similar to other preprocessing reordering approaches, our method can efficiently incorporate linguistic knowledge into SMT systems without increasing the complexity of decoding.
    For a set of five subject-object-verb (SOV) order languages, we show significant improvements in BLEU scores when translating from English, compared to other reordering approaches, in state-of-the-art phrase-based SMT systems.
  
  
    Over the past ten years, statistical machine translation has seen many exciting developments.
    Phrasebased systems (Och, 2002; Koehn et.al., 2003; Och and Ney, 2004) advanced the machine translation field by allowing translations of word sequences (a.k.a., phrases) instead of single words.
    This approach has since been the state-of-the-art because of its robustness in modeling local