extended in (Rosti et al., 2007) by introducing system weights for word confidences.
    However, the system weights did not influence the skeleton selection, so a hypothesis from a system with zero weight might have been chosen as the skeleton.
    In this work, confusion networks are generated by using the-best output from each system as the skeleton, and prior probabilities for each network are estimated from the average TER scores between the skeleton and other hypotheses.
    All resulting confusion networks are connected in parallel into a joint lattice where the prior probabilities are also multiplied by the system weights.
    The combination outputs from confusion network decoding may be ungrammatical due to alignment errors.
    Also the word-level decoding may break coherent phrases produced by the individual systems.
    In this work, log-posterior probabilities are estimated for each confusion network arc instead of using votes or simple word confidences.
    This allows a log-linear addition of 