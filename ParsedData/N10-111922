2007).
    Each review was sentence split and annotated by a human as being positive, negative or neutral in sentiment.
    This resulted in 3,916 sentences, with 1,525, 1,542 and 849 positive, negative and neutral sentences, respectively.
    The first six columns of Table 4 shows: 1) the positive/negative precision-recall of each lexicon-based system where sentence classes were determined using the vote-flip algorithm, and 2) the average precision for each lexicon-based system where purity (or negative purity) was used to rank sentences.
    Both the Wilson et al. and WordNet LP lexicons perform at a similar level, with the former slightly better, especially in terms of precision.
    The web-derived lexicon, Web GP, outperforms the other two lexicons across the board, in particular when looking at average precision, where the gains are near 10% absolute.
    If we plot the precision-recall graphs using purity to classify sentences &#8211; as opposed to the voteflip algorithm, which only provides an unweigh