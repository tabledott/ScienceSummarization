 a word x (or y) may link to NULL with nonzero probability, then that potential link is added as an additional edge in the graph between x (or y) and a NULL vertex added to V2 (or V1).
    Each such x (or y) gets its own NULL vertex, so that multiple words may ultimately link to NULL.
    A sum of weights of links in a matching will be the log-probability of the (unordered) link sequence, and maximizing that sum maximizes the probability.
    The similarity score should be high when many of the link tokens in the best sequence do not involve NULL tokens.
    Further, it should normalize for text length.
    Specifically, the score is This score is an application of Lin&#8217;s (1998) information-theoretic definition of similarity.
    Starting with a set of axioms relating intuitions about similarity to the mathematical notion of mutual information (Shannon 1948), Lin derives the measure where X and Y are any objects generated by a probabilistic model.
    This technique of using a translation model to define