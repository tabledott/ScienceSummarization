e of generating better translations has been around for a while (Frederking and Nirenburg, 1994).
    Recently, confusion network decoding for MT system combination has been proposed (Bangalore et al., 2001).
    To generate confusion networks, hypotheses have to be aligned against each other.
    In (Bangalore et al., 2001), Levenshtein alignment was used to generate the network.
    As opposed to speech recognition, the word order between two correct MT outputs may be different and the Levenshtein alignment may not be able to align shifted words in the hypotheses.
    In (Matusov et al., 2006), different word orderings are taken into account by training alignment models by considering all hypothesis pairs as a parallel corpus using GIZA++ (Och and Ney, 2003).
    The size of the test set may influence the quality of these alignments.
    Thus, system outputs from development sets may have to be added to improve the GIZA++ alignments.
    A modified Levenshtein alignment allowing shifts as in computation of 