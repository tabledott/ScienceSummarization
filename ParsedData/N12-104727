ew, large-margin tuning methods for SMT that can handle thousands of features.
    Batch lattice and k-best MIRA carry out their online training within approximated search spaces, reducing costs in terms of both implementation and training time.
    The Structured SVM optimizes a sum of hinge losses directly, exposing an explicit regularization term.
    We have organized the literature on tuning, and carried out an extensive comparison of linear-loss SMT tuners.
    Our experiments show Batch Lattice MIRA to be the most consistent of the tested methods.
    In the future, we intend to investigate improved sentence-BLEU approximations to help narrow the gap between MIRA and the direct optimizers.
  
  
    Thanks to Mark Hopkins, Zhifei Li and Jonathan May for their advice while implementing the methods in this review, and to Kevin Gimpel, Roland Kuhn and the anonymous reviewers for their valuable comments on an earlier draft.
  

