 can be hand-set or chosen to minimize a relevant loss function on training data using standard techniques from machine learning.
    Because we already have a complete alignment, the classifier&#8217;s decision can be conditioned on arbitrary global features of the aligned graphs, and it can detect failures of monotonicity.
  
  
    Our system has three stages: linguistic analysis, alignment, and entailment determination.
    Our goal in this stage is to compute linguistic representations of the text and hypothesis that contain as much information as possible about their semantic content.
    We use typed dependency graphs, which contain a node for each word and labeled edges representing the grammatical relations between words.
    Figure 1 gives the typed dependency graph for ID 971.
    This representation contains much of the information about words and relations between them, and is relatively easy to compute from a syntactic parse.
    However many semantic phenomena are not represented properly; part