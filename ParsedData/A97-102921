try to answer this question for the final model that was implemented.
    For English, there were 450,000 words of training data.
    By that we mean that the text of the document itself (including headlines but not including SGML tags) was 450,000 words long.
    Given this maximum size of training available to us, we successfully divided the training material in half until we were using only one eighth of the original training set size or a training set of 50,000 words for the smallest experiment.
    To give a sense of the size of 450,000 words, that is roughly half the length of one edition of the Wall Street Journal.
    The results are shown in a histogram in Figure 4.1 below.
    The positive outcome of the experiment is that half as much training data would have given almost equivalent performance.
    Had we used only one quarter of the data or approximately 100,000 words, performance would have degraded slightly, only about 1-2 percent.
    Reducing the training set size to 50,000 words would have h