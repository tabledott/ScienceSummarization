n SEMC OR, the sense-tagged subset of Brown corpus prepared by Miller et al. (Miller et al., 1994), we compare a subset of the occurrences that overlap.
    Out of 5,317 occurrences that overlap, about 57% of the sense assignments in our data set agree with those in SEMCOR.
    This should not be too surprising, as it is widely believed that sense tagging using the full set of refined senses found in a large dictionary like WORDNET involve making subtle human judgments (Wilks et al., 1990; Bruce and Wiebe, 1994), such that there are many genuine cases where two humans will not agree fully on the best sense assignments.
    We evaluated LEXAS on this larger set of noisy, sense-tagged data.
    We first set aside two subsets for testing.
    The first test set, named BC50, consists of 7,119 occurrences of the 191 content words that occur in 50 text files of the Brown corpus.
    The second test set, named WSJ6, consists of 14,139 occurrences of the 191 content words that occur in 6 text files of the WSJ corpus.