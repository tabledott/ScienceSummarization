e it to improve performance on the target task.
    One example of such auxiliary problems for chunking tasks is to &#8216;mask&#8217; a word and predict whether it is &#8220;people&#8221; or not from the context, like language modeling.
    Another example is to predict the prediction of some classifier trained for the target task.
    These auxiliary classifiers can be adequately learned since we have very large amounts of &#8216;training data&#8217; for them, which we automatically generate from a very large amount of unlabeled data.
    The contributions of this paper are two-fold.
    First, we present a novel robust semi-supervised method based on a new learning model and its application to chunking tasks.
    Second, we report higher performance than the previous best results on syntactic chunking (the CoNLL&#8217;00 corpus) and named entity chunking (the CoNLL&#8217;03 English and German corpora).
    In particular, our results are obtained by using unlabeled data as the only additional resource while