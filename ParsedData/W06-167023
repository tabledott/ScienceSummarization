oves over the baseline by 6.45%, 17.96% error reduction.
    We can put these results in context, although indirectly, by comparison with the results of the Senseval3 all words task systems.
    There, with a baseline of 62.40%, only 4 out of 26 systems performed above the baseline, with the two best systems (Mihalcea and Faruque, 2004; Decadt et al., 2004) achieving an F-score of 65.2% (2.8% improvement, 7.45% error reduction).
    The system based on the HMM tagger (Molina et al., 2004), 6Scoring was performed with a re-implementation of the &#8220;conlleval&#8221; script. achieved an F-score of 60.9%.
    The supersense tagger improves mostly on precision, while also improving on recall.
    Overall the tagger achieves F-scores between 70.5 and 77.2%.
    If we compare these figures with the accuracy of NER taggers the results are very encouraging.
    Given the considerably larger &#8211; one order of magnitude &#8211; class space some loss has to be expected.
    Experiments with augmented tagsets in the