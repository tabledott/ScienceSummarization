s extraction systems report on the size and quality of the training data or, if semi-supervised, the size and quality of entity or pattern seed sets.
    Narrowing the focus to closely related work, Pa&#351;ca (2007a; 2007b) and Pa&#351;ca and Durme (2008) show the impact of varying the number of instances representative of a given class and the size of the attribute seed set on the precision of class attribute extraction.
    An example observation is that good quality class attributes can still be extracted using 20 or even 10 instances to represent an entity class.
    Among others, Etzioni et al. (2005) shows that a small pattern set can help bootstrap useful entity seed sets and reports on the impact of seed set noise on final performance.
    Unlike previous work, empirically quantifying the influence of seed set size and quality on extraction performance of random entity types is a key objective of this paper.
  
  
    Term semantic models normally invoke the distributional hypothesis (Harris 1985), w