ented by re-ranking an N-best list of translations produced by a first-pass decoder; this list typically contains between 100 and 10, 000 hypotheses.
    Kumar and Byrne (2004) show that MBR decoding gives optimal performance when the loss function is matched to the evaluation criterion; in particular, MBR under the sentence-level BLEU loss function (Papineni et al., 2001) gives gains on BLEU.
    This is despite the fact that the sentence-level BLEU loss function is an approximation to the exact corpus-level BLEU.
    A different MBR inspired decoding approach is pursued in Zhang and Gildea (2008) for machine translation using Synchronous Context Free Grammars.
    A forest generated by an initial decoding pass is rescored using dynamic programming to maximize the expected count of synchronous constituents in the tree that corresponds to the translation.
    Since each constituent adds a new 4-gram to the existing translation, this approach approximately maximizes the expected BLEU.
    In this paper we expl