and decoding with the normal-form model involves finding the most probable derivation, as described in Section 6.
    The &#946; value refers to the setting of the supertagger used for training and is the first in the sequence of &#946;s from Table 5.
    The &#946; values used during the testing are those in Table 4 and the new, efficient supertagging strategy of taking the highest &#946; value first was used.
    With the same &#946; values used for training (&#946; = 0.1), the results for the dependency model are slightly higher than for the normal-form model.
    However, the coverage of the normal-form model is higher (because the use of the normal-form constraints mean that there are less sentences which exceed the chart-size threshold).
    One clear result from the table is that increasing the chart size used for training, by using smaller &#946; values, can significantly improve the results, in this case around 1.5% F-score for the normal-form model.
    The training of the dependency model already u