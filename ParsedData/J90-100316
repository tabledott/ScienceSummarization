10-6, and P(set, off) 70/(7.3 x 106), we would estimate the mutual information to be I(set; off) = log2 P(set, off )1 (P(set) P(off )) 6.1.
    In the 1988 AP corpus (N = 44,344,077), we estimate P(set) 13,046/N, P(off) 20,693/N, and P(set, off) 463/N.
    Given these estimates, we would compute the mutual information to be I(set; off) 6.2.
    In this example, at least, the values seem to be fairly comparable across corpora.
    In other examples, we will see some differences due to sampling.
    Sinclair's corpus is a fairly balanced sample of (mainly British) text; the AP corpus is an unbalanced sample of American journalese.
    This association between set and off is relatively strong; the joint probability is more than 26 = 64 times larger than chance.
    The other particles that Sinclair mentions have association ratios that can be seen in Table 4.
    The first three, set up, set off and set out, are clearly associated; the last three are not so clear.
    As Sinclair suggests, the approach is well s