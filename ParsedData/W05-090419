   We speculate this is why the kernel dependency subtree metric achieves the best performance among all the metrics.
    We can also see that HWCM and DSTM beat BLEU in most cases and exhibit more stable performance.
    An example hypothesis which was assigned a high score by HWCM but a low score by BLEU is shown in Table 7.
    In this particular sentence, the common head-modifier relations &#8220;aboard +&#8211; plane&#8221; and &#8220;plane +&#8211; the&#8221; caused a high headword chain overlap, but did not appear as common n-grams counted by BLEU.
    The hypothesis is missing the word &#8220;fifth&#8221;, but was nonetheless assigned a high score by human judges.
    This is probably due to its fluency, which HWCM seems to capture better than BLEU.
  
  
    This paper introduces several syntax-based metrics for the evaluation of MT, which we find to be particularly useful for predicting a hypothesis&#8217;s fluency.
    The syntactic metrics, except the kernel based ones, all outperform BLEU in sent