ate contexts (did, began).
    Other interesting phenomena also emerge.
    For example, intermediate symbols, which in previous work were very heavily, manually split using a Markov process, end up encoding processes which are largely Markov, but more complex.
    For example, some classes of adverb phrases (those with RB-4 as their head) are &#8216;forgotten&#8217; by the VP intermediate grammar.
    The relevant rule is the very probable VP-2 &#8594; VP-2 ADVP-6; adding this ADVP to a growing VP does not change the VP subsymbol.
    In essense, at least a partial distinction between verbal arguments and verbal adjucts has been learned (as exploited in Collins (1999), for example).
  
  
    By using a split-and-merge strategy and beginning with the barest possible initial structure, our method reliably learns a PCFG that is remarkably good at parsing.
    Hierarchical split/merge training enables us to learn compact but accurate grammars, ranging from extremely compact (an Fl of 78% with only 147 symbols) 