    These statistics suggest that without accounting for paraphrases, automatic evaluation measures may never reach the accuracy of human evaluation.
    As a solution to this problem, researchers use multiple references to refine automatic evaluation.
    Papineni et al. (2002) shows that expanding the number of references reduces the gap between automatic and human evaluation.
    However, very few human annotated sets are augmented with multiple references and those that are available are relatively 'Each pair included different translations of the same sentence, produced by two human translators. small in size.
    Moreover, access to several references does not guarantee that the references will include the same words that appear in machine-generated sentences.
    In this paper, we explore the use of paraphrasing methods for refinement of automatic evaluation techniques.
    Given a reference sentence and a machine-generated sentence, we seek to find a paraphrase of the reference sentence that is closer