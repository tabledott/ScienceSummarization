ar to those de- scribed in Section 7.
  
  Seed words for this algorithm were those French words that were both POS-tagged as proper nouns and had an above-threshold entity-class confidence from the lexical projec- tion models.
  Performance was measured in terms of per-word entity-type clas- sification accuracy on the French Hansard test data, using the 4- class inventory listed above.
  Classification accuracy of raw tag projections was only 64% (based on automatic word alignment).
  In contrast, the stand-alone co-training-based tagger trained on the projections achieved 85% classification accuracy, illustrating its ef- fectivess at generalization in the face of projection noise.
  Notably, most of its observed errors can be traced to entity classification er- rors from the original English tagger.
  In fact, when evaluated on the English translation of the French test data set, the English tagger only achieved 86% classification accuracy on this directly compa- rable data set.
  It appears that the projec