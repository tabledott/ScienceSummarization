iment.
			3.1.2 Human?Machine Agreement Table 5 shows results, using Equation (2) of Section 2.1.1, compared against a baseline that randomly assigns a sentiment category to each word (averaged over 10 iterations).
			The system achieves lower agreement than humans but higher than the random process.
			Of the test data, the algorithm classified 93.07% of adjectives and 83.27% of verbs as either positive and negative.
			The remainder of adjectives and verbs failed to be classified, since they did not overlap with the synonym set of adjectives and verbs.
			In Table 5, the seed list included just a few manually selected seed words (23 positive and 21 negative verbs and 15 and 19 adjectives, repectively).
			We decided to investigate the effect of more seed words.
			After collecting the annotated data, we added half of it (231 adjectives and 251 verbs) to the training set, retaining the other half for the test.
			As Table 6 shows, agreement of both adjectives and verbs with humans improves.
			Recall is also