previous section, we gave statistics about the distribution of evaluation metrics across a large number of experimental samples (Table 1).
    Because of the large number of trials we carried out, we can be extremely confident in concluding that for both pairs of systems, the experimental manipulation accounts for the observed metric improvements, and furthermore, that we have a good estimate of the magnitude of that improvement.
    However, it is not generally feasible to perform as many replications as we did, so here we turn to the question of how to compare two systems, accounting for optimizer noise, but without running 300 replications.
    We begin with a visual illustration how optimizer instability affects test set scores when comparing two systems.
    Figure 1 plots the histogram of the 300 optimizer samples each from the two BTEC Chinese-English systems.
    The phrase-based system&#8217;s distribution is centered at the sample mean 48.4, and the hierarchical system is centered at 49.9, a differe