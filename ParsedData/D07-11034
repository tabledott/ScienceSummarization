 , t?K , jK); t?k are tar get phrases such that t = t?1...t?K ; s?k are sourcephrases such that s = s?j1 ...s?jK ; and s?k is the trans lation of the kth target phrase t?k. To model p(t,a|s), we use a standard loglinear approach: p(t,a|s) ? exp [ ? i ?ifi(s, t,a) ] where each fi(s, t,a) is a feature function, and weights ?i are set using Och?s algorithm (Och,2003) to maximize the system?s BLEU score (Pa pineni et al , 2001) on a development corpus.
			The features used are: the length of t; a single-parameterdistortion penalty on phrase reordering in a, as de scribed in (Koehn et al, 2003); phrase translation model probabilities; and 4-gram language modelprobabilities log p(t), using Kneser-Ney smooth ing as implemented in the SRILM toolkit (Stolcke, 2002).
			Phrase translation model probabilities are features of the form: log p(s|t,a) ? K? k=1 log p(s?k|t?k) i.e., we assume that the phrases s?k specified by a are conditionally independent, and depend only on their aligned phrases t?k. The ?forward?
			phras