omparison with Table 2.
    Table 10 shows the results in terms of three overall measures: kappa, percentage accuracy, and macro-F (following Lewis [1991]).
    Macro-F is the mean of the F-measures of all seven categories.
    One reason for using macro-F and kappa is that we want to measure success particularly on the rare categories that are needed for our final task (i.e., AIM, BASIS, and CONTRAST).
    Microaveraging techniques like traditional accuracy tend to overestimate the contribution of frequent categories in skewed distributions like ours; this is undesirable, as OWN is the least interesting category for our purposes.
    This situation has parallels in information retrieval, where precision and recall are used because accuracy overestimates the performance on irrelevant items.
    In the case of macro-F, each category is treated as one unit, independent of the number of items contained in it.
    Therefore, the classification success of the individual items in rare categories is given more impor