a tion and can be applied to projective languages with 526the Eisner parsing algorithm and non-projective languages with the Chu-Liu-Edmonds maximum span ning tree algorithm.
			The only remaining problem is how to learn the weight vector w. A major advantage of our approach over other dependency parsing models is its uniformity and simplicity.
			By viewing dependency structures asspanning trees, we have provided a general framework for parsing trees for both projective and non projective languages.
			Furthermore, the resultingparsing algorithms are more efficient than lexi calized phrase structure approaches to dependencyparsing, allowing us to search the entire space with out any pruning.
			In particular the non-projective parsing algorithm based on the Chu-Liu-EdmondsMST algorithm provides true non-projective parsing.
			This is in contrast to other non-projective meth ods, such as that of Nivre and Nilsson (2005), who implement non-projectivity in a pseudo-projective parser with edge transformations.
	