mising.
    The average accuracy across all folds is 72.17%, more than 20 percentage points higher than the baseline accuracy.
    Interestingly, the system performs better on the sentences for which the judges are certain.
    In a post hoc analysis, we consider the sentences from the second data set for which judges M, J, and D rate their certainty as 2 or 3.
    There are 299/500 such sentences.
    For each fold, we calculate the system's accuracy on the subset of the test set consisting of such sentences.
    The average accuracy of the subsets across folds is 81.5%.
    Taking human performance as an upper bound, the system has room for improvement.
    The average pairwise percentage agreement between D, J, and M and the bias-corrected tags in the entire data set is 89.5%, while the system's percentage agreement with the bias-corrected tags (i.e., its accuracy) is 72.17%.
  
  
    This paper demonstrates a procedure for automatically formulating a single best tag when there are multiple judges who dis