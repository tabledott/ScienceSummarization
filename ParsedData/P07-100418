 dev1.
    In the first experiment presented in Table 4, all of the generated 1-best translations were kept and used for training the adapted phrase tables.
    This method yields slightly higher translation quality than the baseline system.
    The second approach we studied is the use of importance sampling (IS) over 20-best lists, based either on lengthnormalized sentence scores (norm.) or confidence scores (conf.).
    As the results in Table 4 show, both variants outperform the first method, with a consistent improvement over the baseline across all test corpora and evaluation metrics.
    The third method uses a threshold-based selection method.
    Combined with confidence estimation as scoring method, this yields the best results.
    All improvements over the baseline are significant at the 95%-level.
    Table 5 shows the translation quality achieved on the NIST test sets when additional source language data from the Chinese Gigaword corpus comprising newswire text is used for transductive learning.