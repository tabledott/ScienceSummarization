e them other than torun the training procedure with a particular combination of values and evaluate the accuracy of the resulting alignments.
			Since evaluating each combina tion of parameter values in this way can take hours to days on a large training corpus, it seems safe to say that these parameters are rarely if ever truly jointly optimized for a particular alignment task.
			The second problem we address is the difficulty of adding features to the standard generative models.
			Generative models require a generative ?story?
			as to how the observed data is generated by an interrelatedset of stochastic processes.
			For example, the gener ative story for IBM Models 1 and 2 and the HMM alignment model is that a target language translation of a given source language sentence is generated byfirst choosing a length for the target language sentence, then for each target sentence position choos ing a source sentence word, and then choosing the corresponding target language word.
			When Brown et al (1993) wa