ds are nearby (Honkela et al., 1995; Honkela, 1997).
    LSA (Dumais et al., 1988; Landauer et al., 1998), LSI, and LDA (Blei et al., 2003) induce distributional representations over F in which each column is a document context.
    In most of the other approaches discussed, the columns represent word contexts.
    In LSA, g computes the SVD of F. Hyperspace Analogue to Language (HAL) is another early distributional approach (Lund et al., 1995; Lund &amp; Burgess, 1996) to inducing word representations.
    They compute F over a corpus of 160 million word tokens with a vocabulary size W of 70K word types.
    There are 2&#183;W types of context (columns): The first or second W are counted if the word c occurs within a window of 10 to the left or right of the word w, respectively. f is chosen by taking the 200 columns (out of 140K in F) with the highest variances.
    ICA is another technique to transform F into f. (V&#168;ayrynen &amp; Honkela, 2004; V&#168;ayrynen &amp; Honkela, 2005; V&#168;ayrynen et al., 