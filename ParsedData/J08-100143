w text without employing syntactic or other annotations.
    In this framework, a word&#8217;s meaning is captured in a multi-dimensional space by a vector representing its co-occurrence with neighboring words.
    Co-occurrence information is collected in a frequency matrix, where each row corresponds to a unique word, and each column represents a given linguistic context (e.g., sentence, document, or paragraph).
    Foltz, Kintsch, and Landauer&#8217;s model use singular value decomposition (SVD; Berry, Dumais, and O&#8217;Brien 1994) to reduce the dimensionality of the space.
    The transformation renders sparse matrices more informative and can be thought of as a means of uncovering latent structure in distributional data.
    The meaning of a sentence is next represented as a vector by taking the mean of the vectors of its words.
    The similarity between two sentences is determined by measuring the cosine of their means: where &#181;(Si) = |Si |Eu&#8712;Si u, and u is the vector for word u.
    An ove