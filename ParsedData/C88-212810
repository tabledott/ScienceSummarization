will lead to the same lemmas, and com- binatorial havoc may result.
  The traditional solution to this problem is to store lemmas in a table, i.e., the well-formed-substring table or chart in tabular parsing algorithms.
  In extending tabular parsing to non-context-free formalisms, the use of subsumption rather than iden- tity in testing for redundancy of lemmas becomes necessary, and has been described elsewhere [Pereira nd Shieber, 1987].
  Second, deduction is a nondeterministic process and the order of searching the various paths in the proof space is critical and differs among processing tasks.
  We therefore parameterize the theorem- proving process by a priority function that assigns to each lemma a priority.
  Lemmas are then added to the table in order of their pri- ority.
  As they are added, furtlmr lemmas that are consequences of the 2Pereira nd Warren use the terms insfantiation and reduction for their analogs to these rules.
  3As Jted previously [Shieber, 1985], this rule of inference can lead 