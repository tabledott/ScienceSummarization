gure 2 gives the raw results for the merged entries and corpus analysis on each verb.
    It shows the of positives correct classes proby our system, positives incorrect proposed by our system, and negatives classes not proposed by our system, as judged against the merged entry, and, for seven of the verbs, against the corpus analysis.
    It also shows, in the final column, the number of sentences from which classes were extracted.
    Dictionary (14 verbs) Corpus (7 verbs) Precision Recall 65.7% 76.6% 35.5% 43.4% Figure 3: Type precision and recall Ranking Accuracy ask 75.0% begin 100.0% believe 66.7% cause 100.0% give 70.0% seem 75.0% swing 83.3% Mean 81.4% Figure 4: Ranking accuracy of classes Figure 3 gives the type precision and recall of our system's recognition of subcategorization classes as evaluated against the merged dictionary entries (14 verbs) and against the manually analysed corpus data (7 verbs).
    The frequency distribution of classes is highly skewed: for example for there are 107 instan