re also referred to as maximum entropy models and random fields in the NLP literature.
    They are popular because of the ease with which complex discriminating features can be included in the model, and have been shown to give good performance across a range of NLP tasks.
    Log-linear models have previously been applied to statistical parsing (Johnson et al. 1999; Toutanova et al.
    2002; Riezler et al. 2002; Malouf and van Noord 2004), but typically under the assumption that all possible parses for a sentence can be enumerated.
    For manually constructed grammars, this assumption is usually sufficient for efficient estimation and decoding.
    However, for wide-coverage grammars extracted from a treebank, enumerating all parses is infeasible.
    In this article we apply the dynamic programming method of Miyao and Tsujii (2002) to a packed chart; however, because the grammar is automatically extracted, the packed charts require a considerable amount of memory: up to 25 GB.
    We solve this massive e