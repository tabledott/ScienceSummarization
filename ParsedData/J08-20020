
  A Global Joint Model for Semantic Role Labeling
  
    We present a model for semantic role labeling that effectively captures the linguistic intuition that a semantic argument frame is a joint structure, with strong dependencies among the arguments.
    We show how to incorporate these strong dependencies in a statistical joint model with a rich set of features over multiple argument phrases.
    The proposed model substantially outperforms a similar state-of-the-art local model that does not include dependencies among different arguments.
    We evaluate the gains from incorporating this joint information on the Propbank corpus, when using correct syntactic parse trees as input, and when using automatically derived parse The gains amount to reduction on all arguments and core arguments for gold-standard parse trees on Propbank.
    For automatic parse trees, the error reductions are all and core arguments, respectively.
    We also present results on the CoNLL 2005 shared task data set.
    Additionally,