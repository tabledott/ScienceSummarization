ining corpus.
    Two types of training scheme are explored in this study, both unsupervised.
    The first employs a pattern that follows Pustejovsky (1993) in counting the occurrences of subcomponents.
    A training instance is any sequence of four words w1w2w3w4 where tv1,1v4 Ar and w2, w3 E Ar.
    Let countp(ni, n2) be the number of times a sequence w1n1n2w4 occurs in the training corpus with wi, tv4 H. The second type uses a window to collect training instances by observing how often a pair of nouns cooccur within some fixed number of words.
    In this study, a variety of window sizes are used.
    For n &gt; 2, let countn(ni , n2) be the number of times a sequence niwi win2 occurs in the training corpus where i &lt; n &#8212; 2.
    Note that windowed counts are asymmetric.
    In the case of a window two words wide, this yields the mutual information metric proposed by Liberman and Sproat (1992).
    Using each of these different training schemes to arrive at appropriate counts it is then possible t