omplete data D = (Y, 8), where Y is the observed data and S is the missing sense value: Here, C is the current value of the maximum likelihood estimates of the model parameters and 02 is the improved estimate that we are seeking; p(Y, 510i) is the likelihood of observing the complete data given the improved estimate of the model parameters.
    When approximating the maximum of the likelihood function, the EM algorithm starts from a randomly generated initial estimate of C and then replaces 0 by the 0i which maximizes Q(0110).
    This process is broken down into two steps: expectation (the E-step), and maximization (the M-step).
    The E-step finds the expected values of the sufficient statistics of the complete model using the current estimates of the model parameters.
    The M-step makes maximum likelihood estimates of the model parameters using the sufficient statistics from the E-step.
    These, steps iterate until the parameter estimates 0 and 0i converge.
    The M-step is usually easy, assuming it 