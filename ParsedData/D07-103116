 of the EM and VB estimators, while 5 runs were performed for the GSestimators.
			Each EM and VB run consisted of 1,000 iterations, while each GS run consisted of 50,000 it erations.
			For the estimators with 10 runs, a 3-standard error 95% confidence interval is approximately the same as the standard deviation.
			states are being mapped onto a single POS tag.
			This is also consistent with the fact that the cross-entropy H(T |Y ) of tags given hidden states is relatively low(i.e., given a hidden state, the tag is relatively predictable), while the cross-entropy H(Y |T ) is rela tively high.
	
	
			and Variational Bayes A Bayesian estimator combines a likelihood termP(x|?, ?) and a prior P(?, ?) to estimate the poste rior probability of a model or hidden state sequence.
			We can use a Bayesian prior to bias our estimatortowards models that generate more skewed distributions.
			Because HMMs (and PCFGs) are prod ucts of multinomials, Dirichlet distributions are a particularly natural choice for the priors