s by controlling for randomness across test sets.
    However, there is no consistently used strategy that controls for the effects of unstable estimates of model parameters.1 While the existence of optimizer instability is an acknowledged problem, it is only infrequently discussed in relation to the reliability of experimental results, and, to our knowledge, there has yet to be a systematic study of its effects on hypothesis testing.
    In this paper, we present a series of experiments demonstrating that optimizer instability can account for substantial amount of variation in translation quality,2 which, if not controlled for, could lead to incorrect conclusions.
    We then show that it is possible to control for this variable with a high degree of confidence with only a few replications of the experiment and conclude by suggesting new best practices for significance testing for machine translation.
  
  
    Statistical machine translation systems consist of a model whose parameters are estimated to maxim