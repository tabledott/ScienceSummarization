s case.
			It isgenerally accepted that to solve the attachment deci sion it is necessary to look at the head noun withinthe prepositional phrase (i.e., ?U.S.?
			in the exam ple), which has a grand-parental relation with the two candidate tokens that the phrase may attach?see e.g.
			(Ratnaparkhi et al, 1994).
			Other ambigu ities in language may also require consideration of grand-parental relations in the dependency structure.
			We present experiments with higher-order models trained with averaged perceptron.
			The second-orderrelations that we incorporate in the model yield significant improvements in accuracy.
			However, the inference algorithms for our factorization are very ex pensive in terms of time and memory consumption,and become impractical when dealing with many la bels or long sentences.
	
	
			A dependency parser receives a sentence x of n to kens, and outputs a labeled dependency tree y. In the tree, a labeled dependency is a triple ?h, m, l?, where h ? [0 . . .
			n] is the index of the 