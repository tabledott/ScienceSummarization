ross multiple product classes, we used two sets of reviews downloaded from tripadvisor.com for Hotels and amazon.com for Scanners.
			Two annotators la beled a set of unique 450 OPINE extractions as correct or incorrect.
			The inter-annotator agreement was 86%.
			The extractions on which the annotators agreed were usedto compute OPINE?s precision, which was 89%.
			Fur Data Explicit Feature Extraction: Precision Hu Hu+A/R Hu+A/R+W OP/R OPINE D1 0.75 +0.05 +0.17 +0.07 +0.19 D2 0.71 +0.03 +0.19 +0.08 +0.22 D3 0.72 +0.03 +0.25 +0.09 +0.23 D4 0.69 +0.06 +0.22 +0.08 +0.25 D5 0.74 +0.08 +0.19 +0.04 +0.21 Avg 0.72 +0.06 + 0.20 +0.07 +0.22Table 2: Precision Comparison on the Explicit Feature Extraction Task.
			OPINE?s precision is 22% better than Hu?sprecision; Web PMI statistics are responsible for 2/3 of the pre cision increase.
			All results are reported with respect to Hu?s. Data Explicit Feature Extraction: Recall Hu Hu+A/R Hu+A/R+W OP/R OPINE D1 0.82 -0.16 -0.08 -0.14 -0.02 D2 0.79 -0.17 -0.09 -0.13 -0.06 D