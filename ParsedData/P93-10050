
  Towards History-Based Grammars: Using Richer Models For Probabilistic Parsing
  
    While a different order for these predictions is possible, we only experimented with this one.
    Parameter Estimation We only have built a decision tree to the rule probability component (3) of the model.
    For the mowe are using with the usual interpolation smoothing for the other four components of the model.
    We have assigned bit strings to the syntactic and semantic categories and to the rules manually.
    Our intention is that bit strings differing in the least significant bit positions correspond to categories of non-terminals or rules that are similar.
    We also have assigned bitstrings for the words in the vocabulary (the lexical heads) using automatic clustering algorithms using the bigram mutual information clustering algorithm (see (5)).
    Given the bitsting of a history, we then designed a decision tree for modeling the probability that a rule will be used for rewriting a node in the parse tree.
   