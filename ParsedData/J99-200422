he disuse of the dependency model for supertagging is that the objective of supertagging is to see how far local techniques can be used to disambiguate supertags even before parsing begins.
    The dependency model, in contrast, is too much like full parsing and is contrary to the spirit of supertagging.
    We have improved the performance of the trigram model by incorporating smoothing techniques into the model and training the model on a larger training corpus.
    We have also proposed some new models for supertag disambiguation.
    In this section, we discuss these developments in detail.
    Two sets of data are used for training and testing the models for supertag disambiguation.
    The first set has been collected by parsing the Wall Street Journal', IBM Manual, and ATIS corpora using the wide-coverage English grammar being developed as part of the XTAG system (Doran et al. 1994).
    The correct derivation from all the derivations produced by the XTAG system was picked for each sentence from these 