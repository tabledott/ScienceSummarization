
    An example is given in Figure 4.
    Head transducers and dependency transduction models are thus related as follows: Each pair of local trees produced by a dependency transduction derivation is the result of a head transducer derivation.
    Specifically, the input to such a head transducer is the string corresponding to the flattened local source dependency tree.
    Similarly, the output of the head transducer derivation is the string corresponding to the flattened local target dependency tree.
    In other words, the head transducer is used to convert a sequence consisting of a headword w and its left and right dependent words to a sequence consisting of a target word v and its left and right dependent words (Figure 5).
    Since the empty string may appear in a transition in place of a source or target symbol, the number of source and target dependents can be different.
    The cost of a derivation produced by a dependency transduction model is the sum of all the weights of the head transducer deriv