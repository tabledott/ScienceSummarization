l in Section 6.
    Despite being the only approach that is general enough to run on all of the data sets, our algorithm achieves similar performance to the others, even outperforming them in several cases.
  
  
    The goal of our algorithm is to find a function f : x &#8212;* z that maps sentences x to logical expressions z.
    We learn this function by inducing a probabilistic CCG (PCCG) grammar from a training set {(xZ, zz)|i = 1... n} containing example (sentence, logical-form) pairs such as (&#8220;New York borders Vermont&#8221;, next to(ny, vt)).
    The induced grammar consists of two components which the algorithm must learn: tion over the possible parses y, conditioned on the sentence x.
    We will present the approach in two parts.
    The lexical induction process (Section 4) uses a restricted form of higher order unification along with the CCG combinatory rules to propose new entries for A.
    The complete learning algorithm (Section 5) integrates this lexical induction with a parameter esti