ands for the -score.
    Experiments show that the MEMM models achieve the best results after 500 and 400 rounds (iterations) of training on the AS data and the PKU data respectively.
    However, the results on the CityU data is not very clear.
    From Round 100 through 200, the F-score on the development set almost stays unchanged.
    We think this is because the CityU data is from three different sources, which differ in the optimal number of iterations.
    We decided to train the MEMM taggers for 160 iterations the HK City University data.
    We implemented two MEMM taggers, one scans the input from left to right and one from right to left.
    We then used these two MEMM taggers to tag both the training and the development data.
    We use the LMR tagging output to train a TransformationBased learner, using fast TBL (Ngai and Florian, 2001).
    The middle in Table 2 shows the F-score on the development set achieved by the MEMM tagger that scans the input from left to right and the last column is the