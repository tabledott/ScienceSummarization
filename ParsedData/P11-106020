ns of SEMRESP by a significant margin (87.2% over 73.2% and 80.4%).
    Next, we compared our systems (DCS and DCS+) with the state-of-the-art semantic parsers on the full dataset for both GEO and JOBS (see Table 3).
    All other systems require logical forms as training data, whereas ours does not.
    Table 3 shows that even DCS, which does not use prototypes, is comparable to the best previous system (Kwiatkowski et al., 2010), and by adding a few prototypes, DCS+ offers a decisive edge (91.1% over 88.9% on GEO).
    Rather than using lexical triggers, several of the other systems use IBM word alignment models to produce an initial word-predicate mapping.
    This option is not available to us since we do not have annotated logical forms, so we must instead rely on lexical triggers to define the search space.
    Note that having lexical triggers is a much weaker requirement than having a CCG lexicon, and far easier to obtain than logical forms.
    Intuitions How is our system learning?
    Initially, th