 majority classifier, the decision stump, and the Naive Bayesian classifier.
    The majority classifier assigns the most common sense in the training data to every instance in the test data.
    A decision stump is a one node decision tree(Holte, 1993) that is created by stopping the decision tree learner after the single most informative feature is added to the tree.
    The Naive Bayesian classifier (Duda and Hart, 1973) is based on certain blanket assumptions about the interactions among features in a corpus.
    There is no search of the feature space performed to build a representative model as is the case with decision trees.
    Instead, all features are included in the classifier and assumed to be relevant to the task at hand.
    There is a further assumption that each feature is conditionally independent of all other features, given the sense of the ambiguous word.
    It is most often used with a bag of words feature set, where every word in the training sample is represented by a binary feature t