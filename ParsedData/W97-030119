ser must use information that has been carefully selected for its value, whereas the maximum entropy framework ro
  
  
    bustly integrates any kind of information, obviating the need to screen it first.
    The SPATTER parser is a history-based parser that uses decision tree models to guide the operations of a few tree building procedures.
    It differs from the maximum entropy parser in how it builds trees and more critically, in how its decision trees use information.
    The SPATTER decision trees use predicates on word classes created with a statistical clustering technique, whereas the maximum entropy parser uses predicates that contain merely the words themselves, and thus lacks the need for a (typically expensive) word clustering procedure.
    Furthermore, the top K BFS search heuristic appears to be much simpler than the stack decoder algorithm outlined in (Magerman, 1995).
  
  
    The maximum entropy parser presented here achieves a parsing accuracy which exceeds the best previously published 