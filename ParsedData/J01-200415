ot dominate B; and (ii) the lowest branching node (i.e., non-unary node) that dominates A also dominates B.'
    Thus in Figure 1(a), the subject NP and the VP each c-command the other, because neither dominates the other and the lowest branching node above both (the S) dominates the other.
    Notice that the subject NP c-commands the object NP, but not vice versa, since the lowest branching node that dominates the object NP is the VP, which does not dominate the subject NP.
    This section will briefly introduce language modeling for statistical speech recognition.'
    In language modeling, we assign probabilities to strings of words.
    To assign a probability, the chain rule is generally invoked.
    The chain rule states, for a string of k+1 words: A Markov language model of order n truncates the conditioning information in the chain rule to include only the previous n words.
    These models are commonly called n-gram models.'
    The standard language model used in many speech recognition systems is