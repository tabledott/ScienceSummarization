 In the balance, the reliability metric seemed to give higher performance.
    This metric is therefore the one that will be used from here on.
    It was also used for all experiments involving the method of collocations.
    Table 6 shows the performance of decision lists with each metric for the usual confusion sets.
    As with the practice confusion sets, we see sometimes dramatic performance differences between the two metrics, and no clear winner.
    For instance, for {I, me}, the reliability metric did better than U(xly) (0.980 versus 0.808); whereas for {between, among}, it did worse (0.659 versus 0.800).
    Further research is needed to understand the circumstances under which each metric performs best.
    Focusing for now on the reliability metric, Table 6 shows that the method of decision lists does, by and large, accomplish what it set out to do &#8212; namely, outperform either component method alone.
    There are, however, a few cases where it falls short; for instance, for {between, among}