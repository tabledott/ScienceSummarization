cs, although their proportion varies from 0.1% to 5.4%.
    Participants took the following approaches to non-projectivity: (Bick, 2006) or if the classifier chooses a special action (Attardi, 2006) or the parser predicts a trace (Schiehlen and Spranger, 2006). training trees to projective ones but encode the information necessary to make the inverse transformation in the DEPREL, so that this inverse transformation can also be carried out on the test trees (Nivre et al., 2006).
    Table 3 shows which column values have been used by participants.
    Nobody used the PHEAD/PDEPREL column in any way.
    It is likely that those who did not use any of the other columns did so mainly for practical reasons, such as the limited time and/or the difficulty to integrate it into an existing parser.
  
  
    Lemma or stem information has often been ignored in previous dependency parsers.
    In the shared task data, it was available in just over half the data sets.
    Both LEMMA and FORM encode lexical information.
  