sch and Canisius, 2006).
    The results in Table 3 (1-1+CSInf vs. 1-1+HMM) show that the HMM approach consistently improves performance over the baseline system (1-1 align), while the CSInf degrades performance on the Brulex data set.
    For the CSInf method, most errors are caused by trigram confusion in the prediction phase.
    The results of our best system, which combines the HMM method with the many-to-many alignments (M-M+HMM), are better than the results reported in (Black et al., 1998) on both the CMUDict and German Celex data sets.
    This is true even though Black et al. (1998) use explicit lists of letterphoneme mappings during the alignment process, while our approach is a fully automatic system that does not require any handcrafted list.
  
  
    We presented a novel technique of applying manyto-many alignments to the letter-to-phoneme conversion problem.
    The many-to-many alignments relax the constraint assumptions of the traditional one-toone alignments.
    Letter chunking bigram predi