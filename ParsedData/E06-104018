 SUMTIME-Hybrid/pCRUroulette, and the difference in BLEU scores for SUMTIME-Hybrid/pCRU-2gram.
    In both Tables 2 and 4, there are two major differences between the rankings assigned by human and automatic evaluation: (i) Human evaluators prefer SUMTIME-Hybrid over pCRU-greedy, whereas all the automatic metrics have it the other way around; and (ii) human evaluators score pCRU-roulette highly (second and third respectively), whereas the automatic metrics score it very low, second worst to random generation (except for NIST which puts it second).
    There are two clear tendencies in scores going from left (humans) to right (SE) across Tables 2 and 4: SUMTIME-Hybrid goes down in rank, and pCRU-2gram comes up.
    In addition to the BLEU-4 scores shown in the tables, we also calculated BLEU-1, BLEU-2, BLEU3 scores.
    These give similar results, except that BLEU-1 and BLEU-2 rank pCRU-roulette as highly as the human judges.
    It is striking how low the experts rank the corpus texts, and to what extent they