tion technique, employing instead an objective function which includes a Gaussian prior on the parameter values, thereby penalizing parameter values which become too large: Closed-form updates under iterative scaling are not possible with this objective function; instead, optimization algorithms such as gradient descent or conjugate gradient methods are used to estimate parameter values.
    In more recent work, Lafferty, McCallum, and Pereira (2001) describe the use of conditional Markov random fields (CRFs) for tagging tasks such as named entity recognition or part-of-speech tagging (hidden Markov models are a common method applied to these tasks).
    CRFs employ the objective function in equation (28).
    A key insight of Lafferty, McCallum, and Pereira (2001) is that when features are of a significantly local nature, the gradient of the function in equation (28) can be calculated efficiently using dynamic programming, even in cases in which the set of candidates involves all possible tagged sequences an