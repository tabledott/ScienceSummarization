us Fig.
    1a defines a weighted relation f where f(aabb, xz) = .0005292.
    This particular relation does happen to be probabilistic (see &#167;1).
    It represents a joint distribution (since Ex,y f(x, y) = 1).
    Meanwhile, Fig.
    1c defines a conditional one (bx Ey f(x, y) = 1).
    This paper explains how to adjust probability distributions like that of Fig.
    1a so as to model training data better.
    The algorithm improves an FST&#8217;s numeric weights while leaving its topology fixed.
    How many parameters are there to adjust in Fig.
    1a?
    That is up to the user who built it!
    An FST model with few parameters is more constrained, making optimization easier.
    Some possibilities: generate E if heads, F if tails.&#8221; E*&#955; = (AE)&#8727;(1&#8722;A) means &#8220;repeatedly flip an A-weighted coin and keep repeating E as long as it comes up heads.&#8221; These 4 parameters have global effects on Fig.
    1a, thanks to complex parameter tying: arcs &#174; b:p &#8722;) @, &#174; 