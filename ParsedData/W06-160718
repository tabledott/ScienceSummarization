positions not encountered in training data (Garcia-Varea et al., 1998).
    Moore (2004) has found that smoothing to correct overestimated IBM1 lexical probabilities for rare words can improve word-alignment performance.
    Langlais (2005) reports negative results for synonym-based smoothing of IBM2 lexical probabilities prior to extracting phrases for phrasebased SMT.
    For phrase-based SMT, the use of smoothing to avoid zero probabilities during phrase induction is reported in (Marcu and Wong, 2002), but no details are given.
    As described above, (Zens and Ney, 2004) and (Koehn et al., 2005) use two different variants of glass-box smoothing (which they call &#8220;lexical smoothing&#8221;) over the phrasetable, and combine the resulting estimates with pure relativefrequency ones in a loglinear model.
    Finally, (Cettollo et al., 2005) describes the use of Witten-Bell smoothing (a black-box technique) for phrasetable counts, but does not give a comparison to other methods.
    As Witten-Bell is repor