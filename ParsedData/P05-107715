ature f occurring in word e. Here, cef is the number of times word e occurred in context f. We then construct a mutual information vector MI(e) = (mie1, mie2, ..., miek) for each word e, where mief is the pointwise mutual information between word e and feature f, which is defined as: where n is the number of words and N = En Em j=1 cij is the total frequency count of all i=1 features of all words.
    Having thus obtained the feature representation of each noun we can apply the algorithm described in Section 3 to discover similarity lists.
    We report results in the next section for both corpora.
  
  
    Evaluating clustering systems is generally considered to be quite difficult.
    However, we are mainly concerned with evaluating the quality and speed of our high speed randomized algorithm.
    The web corpus is used to show that our framework is webscalable, while the newspaper corpus is used to compare the output of our system with the similarity lists output by an existing system, which are calculate