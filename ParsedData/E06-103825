d deviation of the two systems.
    Though these results are promising, more large scale experiments are required to really ascertain the significance of the performance increase.
    Ideally we could sample multiple training/testing splits and use all sentences in the data set to evaluate the systems.
    However, since these systems require human evaluation we did not have the time or the resources to conduct these experiments.
    Here we aim to give the reader a flavor of some common outputs from the different models.
    Three examples are given in Table 4.1.
    The first shows two properties.
    First of all, the decision tree model completely breaks and just returns a single noun-phrase.
    Our system performs well, however it leaves out the complementizer of the relative clause.
    This actually occurred in a few examples and appears to be the most common problem of our model.
    A post-processing rule should eliminate this.
    The second example displays a case in which our system and the human