 generated from the sentence in Figure 1.
    Note that in generating the examples from the sentence in Figure 1 we did not create three negative examples (there are six potential ordered relations between three entities), thereby implicitly under-sampling the data set.
    This allows us to make the classification task simpler without loosing information.
    As a matter of fact, generating examples for each ordered pair of entities would produce two subsets of the same size containing similar examples (differing only for the attributes CANDIDATE and OTHER), but with different classification labels.
    Furthermore, under-sampling allows us to halve the data set size and reduce the data skewness.
    For the protein-protein interaction task (AImed) we use the correct entities provided by the manual annotation.
    As said at the beginning of this section, this task is simpler than the LLL challenge because there is no distinction between types (all entities are proteins) and roles (the relation is symmetric)