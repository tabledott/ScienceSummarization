us, since some questions are not treated as positive examples for possible classes as they should be.
			In training, we divide the 5,500 questions from the first three sources randomly into 5 training sets of 1,000, 2,000, 3,000, 4,000 and 5,500 questions.
			All 500 TREC 10 questions are used as the test set.
			4.2 Evaluation.
			In this paper, we count the number of correctly clas sified questions by two different precision standards P 1 and P 5 . Suppose k. ilabels are output for the i th question (k i  5) and are ranked in a decreasing order according to their density values.
			We define I ij = f 1; if the correct label of the ith question is output in rank j; 0; otherwise: (2) Then, P 1 = P m i=1 I i1 =m and P 5 = P m i=1 P k i j=1 I ij =m where m is the total number of test examples.
			P 1corresponds to the usual defini tion of precision which allows only one label for each question, while P 5 allows multiple labels.
			P 5reflects the accuracy of our classifier with respect to later stages in a que