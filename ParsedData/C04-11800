
	Wide-Coverage Semantic Representations From A CCG Parser
		This paper shows how to construct semantic representations from the derivations producedby a wide-coverage CCG parser.
		Unlike the dependency structures returned by the parser itself, these can be used directly for semantic in terpretation.
		We demonstrate that well-formed semantic representations can be produced for over 97% of the sentences in unseen WSJ text.We believe this is a major step towards wide coverage semantic interpretation, one of the key objectives of the field of NLP.
	
	
			The levels of accuracy and robustness recently achieved by statistical parsers (e.g. Collins (1999),Charniak (2000)) have led to their use in a num ber of NLP applications, such as question-answering(Pasca and Harabagiu, 2001), machine translation (Charniak et al, 2003), sentence simplifica tion (Carroll et al, 1999), and a linguist?s search engine (Resnik and Elkiss, 2003).
			Such parsers typically return phrase-structure trees in the styleof the Penn Treeba