(LSA) which showed that valid semantic relationships between words and documents in a corpus can be induced with virtually no human intervention.
    To do this, one typically begins by applying singular value decomposition (SVD) to a matrix, M, whose entries M(i,j) contains the frequency of word i as seen in document j of the corpus.
    The SVD decomposes M into the product of three matrices, U, D, and V such diagonal matrix whose entries are the singular values of M. The LSA approach then zeros out all but the top k singular values of the SVD, which has the effect of projecting vectors into an optimal kdimensional subspace.
    This methodology is well-described in the literature (Landauer, et al., 1998; Manning and Sch&#252;tze, 1999).
    In order to obtain semantic representations of each word, we apply our previous strategy (Schone and Jurafsky (2000)).
    Rather than using a termdocument matrix, we had followed an approach akin to that of Sch&#252;tze (1993), who performed SVD on a Nx2N term-term mat