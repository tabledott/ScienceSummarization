 using only high-precision projected annotations and far outperforms, by more than 35% absolute dependency accuracy, unsupervised EM.
    When a small number of target-language parse trees is available, projection gives a boost equivalent to doubling the number of target trees.
    The loss in performance from conditioning only on noisy 1-best source parses points to some natural avenues for improvement.
    We are exploring methods that incorporate a packed parse forest on the source side and similar representations of uncertainty about alignments.
    Building on our recent belief propagation work (Smith and Eisner, 2008), we can jointly infer two dependency trees and their alignment, under a joint distribution p(t, a, t'  |w, w') that evaluates the full graph of dependency and alignment edges.
  

