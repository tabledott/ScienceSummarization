agged Brown Corpus [Francis and Kucera], a corpus of approximately 1,000,000 words with part of speech tags assigned laboriously by hand over many years.
    Program performance is encouraging (95-99% &amp;quot;correct&amp;quot;, depending on the definition of &amp;quot;correct&amp;quot;).
    A small 400 word sample is presented in the Appendix, and is judged to be 99.5% correct.
    It is surprising that a local &amp;quot;bottom-up&amp;quot; approach can perform so well.
    Most errors are attributable to defects in the lexicon; remarkably few errors are related to the inadequacies of the extremely over-simplified grammar (a trigram model).
    Apparently, &amp;quot;long distance&amp;quot; dependences are not very important, at least most of the time.
    One might have thought that ngram models weren't adequate for the task since it is wellknown that they are inadequate for determining grammaticality: &amp;quot;We find that no finite-state Markov process that produces symbols with transition from state to