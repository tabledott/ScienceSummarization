s of training and test data.
    In each case, the corpus used was the Penn Treebank's hand-annotated parses of Wall Street Journal articles.
    Relatively few quantitative parsing results have been reported on other corpora (though see Stolcke et al. (1996) for results on Switchboard, as well as Collins et al.
    (1999) for results on Czech and Hwa (1999) for bootstrapping from WSJ to ATIS).
    The inclusion of parses for the Brown corpus in the Penn Treebank allows us to compare parser performance across corpora.
    In this paper we examine the following questions: Our investigation of these questions leads us to a surprising result about parsing the WSJ corpus: over a third of the model's parameters can be eliminated with little impact on performance.
    Aside from cross-corpus considerations, this is an important finding if a lightweight parser is desired or memory usage is a consideration.
  
  
    A great deal of work has been done outside of the parsing community analyzing the variations between 