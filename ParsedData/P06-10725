f a posterior distribution over hypotheses, pp(y  |x) (where y is any tree with yield x), and computing a new parameter estimate O.3 with a locality bias at varying S. Each curve corresponds to a different language and shows performance of supervised model selection within a given S, across A and O1&#176;) values.
    (See Table 3 for performance of models selected across Ss.)
    We decode with S = 0, though we found that keeping the training-time value of S would have had almost no effect.
    The EM baseline corresponds to S = 0.
    One way to bias a learner toward local explanations is to penalize longer attachments.
    This was done for supervised parsing in different ways by Collins (1997), Klein and Manning (2003), and McDonald et al. (2005), all of whom considered intervening material or coarse distance classes when predicting children in a tree.
    Eisner and Smith (2005) achieved speed and accuracy improvements by modeling distance directly in a ML-estimated (deficient) generative model.
    Here