one of them clearly outperforms the others across several datasets.
    However, as we show, these contributions are, to a large extent, independent and, as we show, the approaches can be used together to yield better results.
    Our experiments corroborate recently published results indicating that word class models learned on unlabeled text can significantly improve the performance of the system and can be an alternative to the traditional semi-supervised learning paradigm.
    Combining recent advances, we develop a publicly available NER system that achieves 90.8 F1 score on the CoNLL-2003 NER shared task, the best reported result for this dataset.
    Our system is robust &#8211; it consistently outperforms all publicly available NER systems (e.g., the Stanford NER system) on all three datasets.
  
  
    NER system should be robust across multiple domains, as it is expected to be applied on a diverse set of documents: historical texts, news articles, patent applications, webpages etc.
    Therefore, we