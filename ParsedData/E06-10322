ufficient to reflect a genuine improvement in translation quality, and in other circumstances that it is not necessary to improve Bleu in order to achieve a noticeable improvement in translation quality.
    We argue that Bleu is insufficient by showing that Bleu admits a huge amount of variation for identically scored hypotheses.
    Typically there are millions of variations on a hypothesis translation that receive the same Bleu score.
    Because not all these variations are equally grammatically or semantically plausible there are translations which have the same Bleu score but a worse human evaluation.
    We further illustrate that in practice a higher Bleu score is not necessarily indicative of better translation quality by giving two substantial examples of Bleu vastly underestimating the translation quality of systems.
    Finally, we discuss appropriate uses for Bleu and suggest that for some research projects it may be preferable to use a focused, manual evaluation instead.
  
  
    The rationale 