est F1measure on the development set according to different cost-factor values6.
    We applied such model to the Google ranks and to the ranks of our Web-based QA system, i.e.
    YourQA.
    The latter uses Web documents corresponding to the top 20 Google results for the question.
    Then, each sentence in each document is compared to the question via a blend of similarity metrics used in the answer extraction phase to select the most relevant sentence.
    A passage of up to 750 bytes is then created around the sentence and returned as an answer.
    Table 2 illustrates the results of the answer classifiers derived by exploiting Google (Gg) and YourQA (QA) ranks: the top N ranked results are considered as correct definitions and the remaining ones as in6However, by observing the curves in Fig.
    5, the selected parameters appear as pessimistic estimates for the best model improvement: the one for BOW is the absolute maximum, but an average one is selected for the best model. correct for different values