 addition to the two estimators described above we also present results from a baseline estimator in which all parses are treated as equally likely (this corresponds to setting all the parameters 01 to zero).
    We evaluated our estimators using held-out test corpus (7)test .
    We used two evaluation measures.
    In an actual parsing application a SUBG might be used to identify the correct parse from the set of grammatical parses, so ouorfitrestevaluation measure counts the number c(.5st) of sentences in the test corpus CA-hest whose maximum likelihood parse under the estimated model 0 is actually the correct parse.
    If a sentence has 1 most likely parses (i.e., all 1 parses have the same conditional probability) and one of these parses is the correct parse, then we score 1// for this sentence.
    The second evaluation measure is the pseudolikelihood of the test corpus is the likelihood of the correct parses given their yields, so pseudolikelihood measures how much of the probability mass the model pu