ntities can be In order to account for how strongly the words in a mentioned in the same sentence for reasons other sequence are correlated with either of the individual than the target relation R, and these noisy training arguments of the relation, we modify the formula for sentences are likely to contain words that are corre- the sequence weight T(s) by factoring in a weight lated with the two entities, without any relationship T(w) for each word in the sequence, as illustrated in to R. A learning model where the features are based Equation 1. on words, or word sequences, is going to give too 11 T(s) &#65533; A&#65533;&#65533;&#65533;s) &#183; T(w) (1) much weight to words or combinations of words that wEs are correlated with either of individual arguments.
    Given a predefined set of weights T(w), it is straightThis overweighting will adversely affect extraction forward to update the recursive computation of performance through an increased number of errors. the subsequence kernel so that it reflects the