 require O(m) time or space to be feasible).
    More generally, however, boosting can be applied in more complex settings.
    For example, a common use of boosting is to form a linear combination of decision trees.
    In this case each example x is represented as a number of attribute-value pairs, and each &#8220;feature&#8221;hk(x) is a complete decision tree built on predicates over the attribute values in x.
    In this case the number of features m is huge: There are as many features as there are decision trees over the given set of attributes, thus m grows exponentially quickly with the number of attributes that are used to represent an example x.
    Boosting may even be applied in situations in which the number of features is infinite.
    For example, it may be used to form a linear combination of neural networks.
    In this case each feature hk(x) corresponds to a different parameter setting within the (infinite) set of possible parameter settings for the neural network.
    In more complex setti