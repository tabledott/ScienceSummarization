mple of the tuples extracted from the corpus text (row 1), and a SUMTIME-Hybrid text produced from the tuples (row 5).
    Statistical NLG has focused on generate-and-select models: a set of alternatives is generated and one is selected with a language model.
    This technique is computationally very expensive.
    Moreover, the only type of language model used in NLG are ngram models which have the additional disadvantage of a general preference for shorter realisations, which can be harmful in NLG (Belz, 2005). pCRU1 language generation (Belz, 2006) is a language generation framework that was designed to facilitate statistical generation techniques that are more efficient and less biased.
    In pCRU generation, a base generator is encoded as a set of generation rules made up of relations with zero or more atomic arguments.
    The base generator is then trained on raw text corpora to provide a probability distribution over generation rules.
    The resulting PCRU generator can be run in several modes, inc