spective test sets, and compared the precision and recall of all tuples output by each system.
    Table 3 shows that from the start, O-CRF achieves a high level of precision &#8211; 75.0% &#8211; without any relation-specific data.
    Using labeled training data, the R1-CRF system achieves a slightly lower precision of 73.9%.
    Exactly how many training examples per relation does it take R1-CRF to achieve a comparable level of precision?
    We varied the number of training examples given to R1-CRF, and found that in 3 out of 4 cases it takes hundreds, if not thousands of labeled examples for R1-CRF to achieve acceptable levels of precision.
    In two cases &#8211; acquisitions and inventions &#8211; R1-CRF is unable to match the precision of O-CRF, even with many labeled examples.
    Table 4 summarizes these findings.
    Using labeled data, R1-CRF obtains a recall of 58.4%, compared to O-CRF, whose recall is 18.4%.
    A large number of false negatives on the part of OCRF can be attributed to its lack