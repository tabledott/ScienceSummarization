LABORATION classifier on these examples, we can label correctly 60 of the 61 cue-phrase marked relations and, in addition, we can also label 123 of the 177 relations that are not marked explicitly with cue phrases.
    This means that our classifier contributes to an increase in accuracy from to !!!
    Similarly, out of the 307 CAUSE-EXPLANATION-EVIDENCE relations that hold between two discourse units in Carlson et al.&#8217;s corpus, only 79 are explicitly marked.
    A program trained only on Carlson et al.&#8217;s corpus, would, therefore, identify at most 79 of the 307 relations correctly.
    When we run our CAUSEEXPLANATION-EVIDENCE vs. ELABORATION classifier on these examples, we labeled correctly 73 of the 79 cue-phrase-marked relations and 102 of the 228 unmarked relations.
    This corresponds to an increase in accuracy from to .
    In a seminal paper, Banko and Brill (2001) have recently shown that massive amounts of data can be used to significantly increase the performance of confusion set disa