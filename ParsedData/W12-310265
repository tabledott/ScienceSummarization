en considering the quality estimation task as a ranking problem versus a scoring problem.
    The rankingbased approach appears to be somewhat simpler and more easily amenable to automatic solutions, and at the same time provides immediate benefits when integrated into larger applications (see, for instance, the post-editing application described in Specia (2011)).
    The scoring-based approach is more difficult, as the high error rate even of oracle-based solutions indicates.
    It is also well-known from human evaluations of MT outputs that human judges also have a difficult time agreeing on absolute-number judgements to translations.
    Our experience in creating the current datasets confirms that, even with highly-trained professionals, it is difficult to arrive at consistent judgements.
    We plan to have future investigations on how to achieve more consistent ways of generating absolute-number scores that reflect the quality of automated translations.
  
  
    As in previous incarnations of this wo