 going in the opposite direction and simply putting all mentions in one cluster produces a MUC score which is higher than any in the table, even though this clustering is clearly not useful in applications.
    Hence, we are skeptical of this measure&#8217;s utility and provide it primarily for comparison with previous work.
    The improvements from the ILP system are most clearly shown on the ACE NWIRE corpus, where the V f-score improved 3.6%, and the cluster f-score improved 16.5%.
  
  
    We showed how to use integer linear programming to encode transitivity constraints in a coreference classifier which models pairwise decisions over mentions.
    We also demonstrated that enforcing such constraints at test time can significantly improve performance, using a variety of evaluation metrics.
  
  
    Thanks to the following members of the Stanford NLP reading group for helpful discussion: Sharon Goldwater, Michel Galley, Anna Rafferty.
    This paper is based on work funded by the Disruptive Technology O