antly larger, and has a more even mix of left and right-branching noun phrases.
    We also measured the amount of lexical overlap between the two corpora, shown in Table 5.
    This displays the percentage of n-grams in Lauer&#8217;s corpus that are also in our corpus.
    We can clearly see that the two corpora are quite dissimilar, as even on unigrams barely half are shared.
    With our new data set, we began running experiments similar to those carried out in the literature (Nakov and Hearst, 2005).
    We implemented both an adjacency and dependency model, and three different association measures: raw counts, bigram probability, and .
    We draw our counts from a corpus of n-gram counts calculated over 1 trillion words from the web (Brants and Franz, 2006).
    The results from the experiments, on both our and Lauer&#8217;s data set, are shown in Table 6.
    Our results on Lauer&#8217;s corpus are similar to those reported previously, with the dependency model outperforming the adjacency model on all 