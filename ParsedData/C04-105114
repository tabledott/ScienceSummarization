endencies, and a variety of distributed paraphrases, with alignments spanning widely separated elements.
			3.2 Word Error Alignment Rate.
			An objective scoring function was needed to compare the relative success of the two data collection strategies sketched in 2.1.1 and 2.1.2.
			Which technique produces more data?
			Are the types of data significantly different in character or utility?
			In order to address such questions, we used word Alignment Error Rate (AER), a metric borrowed from the field of statistical machine translation (Och &amp; Ney 2003).
			AER measures how accurately an automatic algorithm can align words in corpus of parallel sentence pairs, with a human 4 This contrasts with 16.7% pairs assessed as unrelated in a 10,000 pair sampling of the L12 data.
			tagged corpus of alignments serving as the gold standard.
			Paraphrase data is of course monolingual, but otherwise the task is very similar to the MT alignment problem, posing the same issues with one-to-many, many-to-many, and one/ma