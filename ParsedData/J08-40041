 the aspects of language interpretation of concern in the creation of early resources such as the Brown corpus (Francis and Kucera 1982), the British National Corpus (Leech, Garside, and Bryant 1994), or the Penn Treebank (Marcus, Marcinkiewicz, and Santorini 1993).
    Problems with early proposals for assessing coders&#8217; agreement on discourse segmentation tasks (such as Passonneau and Litman 1993) led Carletta (1996) to suggest the adoption of the K coefficient of agreement, a variant of Cohen&#8217;s x (Cohen 1960), as this had already been used for similar purposes in content analysis for a long time.1 Carletta&#8217;s proposals were enormously influential, and K quickly became the de facto standard for measuring agreement in computational linguistics not only in work on discourse (Carletta et al. 1997; Core and Allen 1997; Hearst 1997; Poesio and Vieira 1998; Di Eugenio 2000; Stolcke et al.
    2000; Carlson, Marcu, and Okurowski 2003) but also for other annotation tasks (e.g., V&#180;eronis 1998; B