n Transduction Grammars (Wu, 97), or ITGs, treat translation as a process of parallel parsing of the source and target language via a synchronized grammar.
    To make this process computationally efficient, however, some severe simplifying assumptions are made, such as using a single non-terminal label.
    This results in the model simply learning a very high level preference regarding how often nodes should switch order without any contextual information.
    Also these translation models are intrinsically word-based; phrasal combinations are not modeled directly, and results have not been competitive with the top phrasal SMT systems.
    Along similar lines, Alshawi et al. (2000) treat translation as a process of simultaneous induction of source and target dependency trees using headtransduction; again, no separate parser is used.
    Yamada and Knight (01) employ a parser in the target language to train probabilities on a set of operations that convert a target language tree to a source language string.
