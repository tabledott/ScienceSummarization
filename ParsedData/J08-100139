erence course coherence (see Section 3.3 for details).
    An additional motivation for our study was to explore the trade-off between robustness and richness of linguistic annotations.
    NLP tools are typically trained on human-authored texts, and may deteriorate in performance when applied to automatically generated texts with coherence violations.
    We thus compared a linguistically rich model against models that use more impoverished representations.
    More concretely, our full model (Coreference+Syntax+ Salience+) uses coreference resolution, denotes entity transition sequences via grammatical roles, and differentiates between salient and non-salient entities.
    Our lessexpressive models (seven in total) use only a subset of these linguistic features during the grid construction process.
    We evaluated the effect of syntactic knowledge by eliminating the identification of grammatical relations and recording solely whether an entity is present or absent in a sentence.
    This process created a 