ensemble are constructed (Dietterich 1997).
    In this paper we take a multistrategy approach, in which an ensemble is constructed by classifiers resulting from training different learning methods on the same data (see also Alpaydin [19981).
    Methods to combine the outputs of component classifiers in an ensemble include simple voting where each component classifier gets an equal vote, and weighted voting, in which each component classifier's vote is weighted by its accuracy (see, for example, Golding and Roth [1999]).
    More sophisticated weighting methods have been designed as well.
    Ali and Pazzani (1996) apply the Naive Bayes' algorithm to learn weights for classifiers.
    Voting methods lead to the gang effect discussed earlier.
    The Let T, be the component taggers, Si(tok) the most probable tag for a token tok as suggested by T,, and let the quality of tagger T be measured by Simple algorithms for voting between component taggers. most interesting approach to combination is stacking in which