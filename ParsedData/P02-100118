52; o yi directly, just as in the joint model.
    Finally, note that EM is not all-purpose.
    It only maximizes probabilistic objective functions, and even there it is not necessarily as fast as (say) conjugate gradient.
    For this reason, we will also show below how to compute the gradient of f&#952;(xi, yi) with respect to 0, for an arbitrary parameterized FST f&#952;.
    We remark without elaboration that this can help optimize task-related objective functions, such as E Ey(P(xi, y)&#945;/ Ey' P(xi, y&#65533;)&#945;) &#183; error(y, yi). i
  
  
    It remains to devise appropriate E steps, which looks rather daunting.
    Each path in Fig.
    2 weaves together parameters from other machines, which we must untangle and tally.
    In the 4-coin parameterization, path observed heads and tails of the 4 coins.
    This nontrivially works out to (4, 1, 0,1,1,1,1, 2).
    For other parameterizations, the path must instead yield a vector of arc traversal counts or feature counts.
    Computing a count vect