 a final sample of about 9,500 users and 380,000 messages, totaling 4.7 million word tokens.
    We have made this dataset available online.4 Informal text from mobile phones is challenging to tokenize; we adapt a publicly available tokenizer5 originally developed for Twitter (O&#8217;Connor et al., 2010), which preserves emoticons and blocks of punctuation and other symbols as tokens.
    For each user&#8217;s Twitter feed, we combine all messages into a single &#8220;document.&#8221; We remove word types that appear in fewer than 40 feeds, yielding a vocabulary of 5,216 words.
    Of these, 1,332 do not appear in the English, French, or Spanish dictionaries of the spell-checking program aspell.
    Every message is tagged with a location, but most messages from a single individual tend to come from nearby locations (as they go about their day); for modeling purposes we use only a single geographic location for each author, simply taking the location of the first message in the sample.
    The authors in our