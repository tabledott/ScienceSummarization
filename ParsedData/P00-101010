 the performance of a frozen version of the machine tagger, which was trained and engineered on a separate body of NYT, ABC News, and CNN data.
    Only the body of the text was included in the tagging and evaluation.
    The system performance is shown in Table 12.
    Note that if the human said the TIMEX had no value, and the system decided it had a value, this is treated as an error.
    A baseline of just tagging values of absolute, fully specified TIMEXs (e.g., &#8220;January 31st, 1999&#8221;) is shown for comparison in parentheses.
    Obviously, we would prefer a larger data sample; we are currently engaged in an effort within the information extraction community to annotate a large sample of the TDT2 collection and to conduct an interannotator reliability study.
    Table 2 shows the number of errors made by the program classified by the type of error.
    Only 2 of these 138 errors (5 on TIME, 133 on DATE) were due to errors in the source.
    14 of the 138 errors (9 NYT vs. 5 VOA) were due to the 