ine.
    To speed up training, in combined experiments (C&amp;W plus another word representation), we used the 50-dimensional C&amp;W embeddings, not the 200-dimensional ones.
    In the last section, we show how many unlabeled words were used.
    Table 2 shows the final chunking results and Table 3 shows the final NER F1 results.
    We compare to the state-of-the-art methods of Ando and Zhang (2005), Suzuki and Isozaki (2008), and&#8212;for NER&#8212;Lin and Wu (2009).
    Tables 2 and 3 show that accuracy can be increased further by combining the features from different types of word representations.
    But, if only one word representation is to be used, Brown clusters have the highest accuracy.
    Given the improvements to the C&amp;W embeddings since Turian et al. (2009), C&amp;W embeddings outperform the HLBL embeddings.
    On chunking, there is only a minute difference between Brown clusters and the embeddings.
    Combining representations leads to small increases in the test F1.
    In comparison