rams, which have lower correlation values by our metric, include verb/subject and preposition/object relations and seem more broadly applicable as a model of English.
    However, the pairs are not strongly related semantically, no doubt because the first term of the pruning criterion favors the most frequent words, such as forms of the verbs &amp;quot;be&amp;quot; and &amp;quot;have&amp;quot;.
  
  
    Our results show strong corpus effects for statistical parsing models: a small amount of matched training data appears to be more useful than a large amount of unmatched data.
    The standard WSJ task seems to be simplified by its homogenous style.
    Adding training data from from an unmatched corpus doesn't hurt, but doesn't help a great deal either.
    In particular, lexical bigram statistics appear to be corpus-specific, and our results show that they are of no use when attempting to generalize to new training data.
    In fact, they are of surprisingly little benefit even for matched training and test