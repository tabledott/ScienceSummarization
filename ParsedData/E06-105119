 using the training set without coreferences and the whole training set are similar.
    We also report in Table 4 an analysis of the kernel combination.
    Given that we are interested here in the contribution of each kernel, we evaluated the experiments by 10-fold cross-validation on the whole training set avoiding the submission process.
    The experimental results show that the combined kernel KSL outperforms the basic kernels KGC and KLC on both data sets.
    In particular, precision significantly increases at the expense of a lower recall.
    High precision is particularly advantageous when extracting knowledge from large corpora, because it avoids overloading end users with too many false positives.
    Although the basic kernels were designed to model complementary aspects of the task (i.e.
    9After the challenge deadline, Reidel and Klein (2005) achieved a significant improvement, Fl = 68.4% (without coreferences) and Fl = 64.7% (with and without coreferences). presence of the relation and role