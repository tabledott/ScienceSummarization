 process that improves the model by generating feedback through labeling unlabeled examples.
    Our algorithm pushes this intuition further, in that the use of constraints allows us to better exploit domain information as a way to label, along with the current learned model, unlabeled examples.
    Given a small amount of labeled data and a large unlabeled pool, our framework initializes the model with the labeled data and then repeatedly: This way, we can generate better &#8220;training&#8221; examples during the semi-supervised learning process.
    The core of our approach, (1), is described in Section 5.
    The task is described in Section 3 and the Experimental study in Section 6.
    It is shown there that the improvement on the training examples via the constraints indeed boosts the learned model and the proposed method significantly outperforms the traditional semi-supervised framework.
  
  
    In the semi-supervised domain there are two main approaches for injecting domain specific knowledge.
   