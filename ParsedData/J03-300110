that need quantitative information about the behavior of words as input (most notably parsers [Briscoe and Carroll 1997; Korhonen 2000]).
    However, for some purposes, it is not large enough.
    This is an outcome of the Zipfian nature of word frequencies.
    Although 100 million is a huge number, and the BNC contains ample information on the dominant meanings and usage patterns for the 10,000 words that make up the core of English, the bulk of the lexical stock occurs less than 50 times in the BNC, which is not enough to draw statistically stable conclusions about the word.
    For rarer words, rare meanings of common words, and combinations of words, we frequently find no evidence at all.
    Researchers are obliged to look to larger data sources (Keller and Lapata, this issue; also Section 3.3).
    They find that probabilistic models of language based on very large quantities of data, even if those data are noisy, are better than ones based on estimates (using sophisticated smoothing techniques) from 