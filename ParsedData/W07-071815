relation of a range of automatic metrics in addition to Bleu.
    In total we used eleven different automatic evaluation measures to rank the shared task submissions.
    They are: against a reference.
    It flexibly matches words using stemming and WordNet synonyms.
    Its flexible matching was extended to French, Spanish, German and Czech for this workshop (Lavie and Agarwal, 2007).
    4The GTM scores presented here are an F-measure with a weight of 0.1, which counts recall at 10x the level of precision.
    The exponent is set at 1.2, which puts a mild preference towards items with words in the correct order.
    These parameters could be optimized empirically for better results.
    TER calculates the number of edits required to change a hypothesis translation into a reference translation.
    The possible edits in TER include insertion, deletion, and substitution of single words, and an edit which moves sequences of contiguous words.
    The scores produced by these are given in the tables at the end 