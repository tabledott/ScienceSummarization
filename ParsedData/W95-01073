re tags were assigned to each word based on its part-of-speech tag.
    Rules were then automatically learned that updated these chunk structure tags based on neighboring words and their part-of-speech and chunk tags.
    Applying transformation-based learning to text chunking turns out to be different in interesting ways from its use for part-of-speech tagging.
    The much smaller tagset calls for a different organization of the computation, and the fact that part-of-speech assignments as well as word identities are fixed suggests different optimizations.
  
  
    Abney (1991) has proposed text chunking as a useful preliminary step to parsing.
    His chunks are inspired in part by psychological studies of Gee and Grosjean (1983) that link pause durations in reading and naive sentence diagraming to text groupings that they called 0-phrases, which very roughly correspond to breaking the string after each syntactic head that is a content word.
    Abney's other motivation for chunking is procedural, based on