l (1993), sometimes augmented by an HMM-based model or Och and Ney?s ?Model 6?
			(Och and Ney, 2003).
			The best combinations of these models can produce high accuracy alignments,at least when trained on a large corpus of fairly di rect translations in related languages.These standard models are less than ideal, how ever, in a number of ways, two of which we address in this paper.
			First, although the standard models cantheoretically be trained without supervision, in prac tice various parameters are introduced that should be optimized using annotated data.
			For, example,Och and Ney (2003) suggest supervised optimization of a number of parameters, including the prob ablity of jumping to the empty word in the HMMmodel, as well as smoothing parameters for the dis tortion probabilities and fertility probabilities of themore complex models.
			Since the values of these parameters affect the values of the translation, align ment, and fertility probabilities trained by EM, there is no effective way to optimiz