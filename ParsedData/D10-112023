dependency model with valence (DMV) (Klein and Manning, 2004) and the phylogenetic grammar induction (PGI) model (Berg-Kirkpatrick and Klein, 2010).
    HDP-DEP outperforms both DMV and PGI across all six languages.
    Against DMV we achieve an average absolute improvement of 24.1%.
    This improvement is expected given that DMV does not have access to the additional information provided through the universal rules.
    PGI is more relevant as a point of comparison, since it is able to leverage multilingual data to learn information similar to what we have declaratively specified using universal rules.
    Specifically, PGI reduces induction ambiguity by connecting language-specific parameters via phylogenetic priors.
    We find, however, that we outperform PGI by an average margin of 7.2%, demonstrating the benefits of explicit rule specification.
    An additional point of comparison is the lexicalized unsupervised parser of Headden III et al. (2009), which yields the current state-of-the-art unsupervise