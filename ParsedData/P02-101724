e 11 shows recall for various categories by iteration.
    NP recall exhibits the more typical pattern of a sharp rise followed by a slow fall, but the other categories, after some initial drops, all increase until convergence.
    These graphs stop at 40 iterations.
    The system actually converged in both likelihood and F1 by iteration 38, to within a tolerance of 10&#8722;10.
    The time to convergence varied according to smoothing amount, number of classes, and tags used, but the system almost always converged within 80 iterations, usually within 40.
  
  
    We have presented a simple generative model for the unsupervised distributional induction of hierarchical linguistic structure.
    The system achieves the best published unsupervised parsing scores on the WSJ-10 and ATIS data sets.
    The induction algorithm combines the benefits of EM-based parameter search and distributional clustering methods.
    We have shown that this method acquires a substantial amount of correct structure, to the point 