ng and labeling tasks, consider figure 3.
    In both plots, each point is a frequent tag sequence, assigned to the (normalized) vector of its context frequencies.
    Each plot has been projected onto the first two principal components of its respective data set.
    The left plot shows the most frequent sequences of three constituent types.
    Even in just two dimensions, the clusters seem coherent, and it is easy to believe that they would be found by a clustering algorithm in the full space.
    On the right, sequences have been labeled according to whether their occurrences are constituents more or less of the time than a cutoff (of 0.2).
    The distinction between constituent and distituent seems much less easily discernible.
    We can turn what at first seems to be distributional clustering into tree induction by confining P(B) to put mass only on tree-equivalent bracketings.
    In particular, consider Pbin(B) which is uniform over binary bracketings and zero elsewhere.
    If we take this bracketi