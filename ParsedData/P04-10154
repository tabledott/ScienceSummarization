igures of 86.7% and 86.6% for the separate generative and perceptron models).
    The approach is an extremely simple method for integrating new features into the generative model: essentially all that is needed is a definition of feature-vector representations of entire parse trees, and then the existing parsing algorithms can be used for both training and decoding with the models.
  
  
    In this section we describe a general framework &#8211; linear models for NLP &#8211; that could be applied to a diverse range of tasks, including parsing and tagging.
    We then describe a particular method for parameter estimation, which is a generalization of the perceptron algorithm.
    Finally, we give an abstract description of an incremental parser, and describe how it can be used with the perceptron algorithm.
    We follow the framework outlined in Collins (2002; 2004).
    The task is to learn a mapping from inputs x &#8712; X to outputs y &#8712; Y.
    For example, X might be a set of sentences, with Y bein