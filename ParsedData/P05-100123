ctuation symbols.
    As shown in Figure 7, ASO-semi improves both precision and recall over the supervised baseline.
    It achieves 94.39% in F-measure, which outperforms the supervised baseline by 0.79%.
    Co- and selftraining again slightly improve recall but slightly degrade precision at their oracle performance, which demonstrates that it is not easy to benefit from unlabeled data on this task.
    Comparison with the previous best systems As shown in Figure 8, ASO-semi achieves performance higher than the previous best systems.
    Though the space constraint precludes providing the detail, we note that ASO-semi outperforms all of the previous top systems in both precision and recall.
    Unlike named entity chunking, the use of external resources on this task is rare.
    An exception is the use of output from a grammar-based full parser as features in ZDJ02+, which our system does not use.
    KM01 and CM03 boost performance by classifier combinations.
    SP03 trains conditional random fields for 