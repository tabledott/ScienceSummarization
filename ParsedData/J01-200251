ervations about the overall accuracies, although the most important, are not the only interesting ones.
    We can also examine the results of the experiments above in more detail, evaluating the results of combination for specific words and tags, and Error rates for the most confusing words.
    For each word, we list the total number of instances in the test set (n), the number of tags associated with the word (tags), and then, for each base tagger and WPDV(Tags+Context), the rank in the error list (rank), the absolute number of errors (err), and the percentage of instances that is mistagged (/o). trying to discover why such disappointing results are found for WSJ.
    Furthermore, we can run additional experiments, to determine the effects of the size of the training set, the number of base tagger components involved, and the granularity of the tagset.
    The overall accuracy of the various tagging systems gives a good impression of relative performance, but it is also useful to have a more detailed look 