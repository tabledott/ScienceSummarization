ceefficient manner.
    We then propose a mechanism, sub-sequence filtering, for reducing the error rates of these models by using the fact that an n-gram&#8217;s frequency is bound from above by the frequency of its least frequent sub-sequence.
    We present machine translation experiments using these models to represent information regarding higher-order n-grams and additional larger monolingual corpora in combination with conventional smoothed trigram models.
    We also run experiments with these models in isolation to highlight the impact of different order n-grams on the translation process.
    Finally we provide some empirical analysis of the effectiveness of both the log frequency Bloom filter and sub-sequence filtering.
  
  
    In this section, we give a brief overview of the Bloom filter (BF); refer to Broder and Mitzenmacher (2005) for a more in detailed presentation.
    A BF represents a set S = {x1, x2, ..., xn} with n elements drawn from a universe U of size N. The structure is attractive w