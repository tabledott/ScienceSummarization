s or trees can be selected by each word in the training data.
    We use a count cutoff for trees in the labeled data and combine observed counts into an unobserved tree count.
    This is similar to the usual technique of assigning the token unknown to infrequent word tokens.
    In this way, trees unseen in the labeled data but in the tag dictionary are assigned a probability in the parser.
    The problem of lexical coverage is a severe one for unsupervised approaches.
    The use of tag dictionaries is a way around this problem.
    Such an approach has already been used for unsupervised part-of-speech tagging in (Brill, 1997) where seed data of which POS tags can be selected by each word is given as input to the unsupervised tagger.
    In future work, it would be interesting to extend models for unknown-word handling or other machine learning techniques in clustering or the learning of subcategorization frames to the creation of such tag dictionaries.
  
  
    As described before, we treat parsing as a