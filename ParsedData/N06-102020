t the probabilities of the 50-best parses are becoming more skewed.
    In essence the model is learning, in general, what VPs and Ss look like so it is becoming easier to pull them out of the stew surrounding the conjunct.
    Conversely, language modeling has comparatively less reason to help PP attachment.
    As long as the parser is doing it consistently, attaching the PP either way will work almost as well.
  
  
    Contrary to received wisdom, self-training can improve parsing.
    In particular we have achieved an absolute improvement of 0.8% over the baseline performance.
    Together with a 0.3% improvement due to superior reranking features, this is a 1.1% improvement over the previous best parser results for section 23 of the Penn Treebank (from 91.0% to 92.1%).
    This corresponds to a 12% error reduction assuming that a 100% performance is possible, which it is not.
    The preponderance of evidence suggests that it is somehow the reranking aspect of the parser that makes this possible, but gi