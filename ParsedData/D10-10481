her modules.
    In spite of its simplicity, our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora.
    This suggests that sievebased approaches could be applied to other NLP tasks.
  
  
    Recent work on coreference resolution has shown that a rich feature space that models lexical, syntactic, semantic, and discourse phenomena is crucial to successfully address the task (Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010).
    When such a rich representation is available, even a simple deterministic model can achieve state-of-the-art performance (Haghighi and Klein, 2009).
    By and large most approaches decide if two mentions are coreferent using a single function over all these features and information local to the two mentions.1 This is problematic for two reasons: (1) lower precision features may overwhelm the smaller number of high precision ones, and (2) local information is often insufficient to make an informed decisi