 or reject a hypothesis, but to generalize the patterns using machine-learning algorithms.
    Through a series of simulations, Reidsma and Carletta demonstrate that agreement coefficients are poor predictors of machine-learning success: Even highly reproducible annotations are difficult to generalize when the disagreements contain patterns that can be learned, whereas highly noisy and unreliable data can be generalized successfully when the disagreements do not contain learnable patterns.
    These results show that agreement coefficients should not be used as indicators of the suitability of annotated data for machine learning.
    However, the purpose of reliability studies is not to find out whether annotations can be generalized, but whether they capture some kind of observable reality.
    Even if the pattern of disagreement allows generalization, we need evidence that this generalization would be meaningful.
    The decision whether a set of annotation guidelines are appropriate or meaningful is ultima