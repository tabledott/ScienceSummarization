xts tend to have twice as many entities as easy ones.
    Consequently, easy and difficult texts are represented by entity transition sequences with different probabilities (e.g., the sequences [S S] and [S O] are more probable in difficult texts).
    Interestingly, when coherence is quantified using LSA, we observe no improvement to the classification task.
    The LSA scores capture lexical or semantic text properties similar to those expressed by the Flesch Kincaid index and the perplexity scores (e.g., word repetition).
    It is therefore not surprising that their inclusion in the feature set does not increase performance.
    We also evaluated the training requirements for the readability system described herein.
    Figure 3 shows the learning curve for Schwarm and Ostendorf&#8217;s (2005) model enhanced with the Coreference+Syntax+Salience+ feature space and on its own.
    As can be seen, both models perform relatively well when trained on small data sets (e.g., 20&#8211;40 documents) and reach peak