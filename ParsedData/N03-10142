arse history (Ratnaparkhi, 1999; Collins, 1999; Charniak, 2000).
    In the work presented here, we automatically induce a finite set of real valued features to represent the parse history.
    We perform the induction of a history representation using an artificial neural network architecture, called Simple Synchrony Networks (SSNs) (Lane and Henderson, 2001; Henderson, 2000).
    This machine learning method is specifically designed for processing unbounded structures.
    It allows us to avoid making a priori independence assumptions, unlike with hand-crafted history features.
    But it also allows us to make use of our a priori knowledge by imposing structurally specified and linguistically appropriate biases on the search for a good history representation.
    The combination of automatic feature induction and linguistically appropriate biases results in a history-based parser with state-of-the-art performance.
    When trained on just part-of-speech tags, the resulting parser achieves the best current 