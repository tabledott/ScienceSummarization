ng discourse and dialogue phenomena, and especially coding segment boundaries, may be inherently more difficult than many previous types of content analysis (for instance, 1 There are several variants of the kappa coefficient in the literature, including one, Scott's pi, which actually has been used at least once in our field, to assess agreement on move boundaries in monologues using action assembly theory (Grosz and Sidner 1986).
    Krippendorff's a is more general than Siegel and Castellan's K in that Krippendorff extends the argument from category data to interval and ratio scales; this extension might be useful for, for instance, judging the reliability of TOBI break index coding, since some researchers treat these codes as inherently scalar (Silverman et al. 1992).
    Krippendorff's a and Siegel and Castellan's K differ slightly when used on category judgments in the assumptions under which expected agreement is calculated.
    Here we use Siegel and Castellan's K because they explain their statistic 