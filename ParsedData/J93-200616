hus, in applications such as tagging, where a significant number of the theoretically possible events do not occur in practice, we can use supervised training of probabilistic models without needing prohibitively large corpora.
    Of course, performance of POST is also affected by the estimates of p(w, I ti) for known words and unknown words.
    How to estimate p(w, I t,) for unknown words is covered in the next section.
    For an observed word, a small training set of 64,000 words may still be adequate for estimates of p(w, I t1).
    We found that by treating words observed only once as if they had not been observed at all (and are thus handled by the probabilistic models for unknown words) that performance actually increased slightly.
    This suggests that adequate performance can be obtained from a relatively small training set.
    We are not aware of any other published studies documenting empirically the impact of training set size on performance.
    Sources of open-ended text, such as a newswire,