xt as where n is the number of times that context has appeared and d is the number of different symbols that have directly followed it (Howard 1993).
    The probability of a character that has occurred c times in that context is Since there are d such characters, and their counts sum to n, it is easy to confirm that the probabilities in the distribution (including the escape probability) sum to 1.
    To illustrate the PPM modeling technique, Table 1 shows the model after the string tobeornottobe has been processed.
    In this illustration the maximum model order is 2 (not 5 as stated above), and each prediction has a count c and a prediction probability p. The probability is determined from the counts associated with the prediction using the formula that we discuss above.
    IA l is the size of the alphabet, and it is this that determines the probability for each unseen character.
    The model in Table 1 is used as follows: Suppose the character following tobeornottobe is o.
    Since the order 2 context