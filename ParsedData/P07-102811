 assigned some level of preference by a model (&#8220;full coverage&amp;quot;).
    We contrast this with another condition, where we count a pair as covered if at least one of the two words w, w' is assigned a level of preference by a model (&#8220;half coverage&#8221;).
    If only one is assigned a preference, that word is counted as chosen.
    To test the performance difference between models for significance, we use Dietterich's Under the null hypothesis, the t statistic has approximately a t distribution with 5 degrees of freedom.5
  
  
    Error rates.
    Table 2 shows error rates and coverage for the different selectional preference induction methods.
    The first five models are similarity-based, computed with uniform weights.
    The name in the first column is the name of the similarity metric used.
    Next come EM-based clustering models, using 30 (40) clusters and 20 re-estimation steps6, and the last row lists the results for Resnik's WordNet-based method.
    Results are micro-averaged.
  