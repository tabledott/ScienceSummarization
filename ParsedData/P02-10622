ximum-entropy) tagger is used to generate 20 possible segmentations for each input sentence, along with their probabilities.
    We describe a number of additional global features of these candidate segmentations.
    These additional features are used as evidence in reranking the hypotheses from the max-ent tagger.
    We describe two learning algorithms: the boosting method of (Collins 2000), and a variant of the voted perceptron algorithm, which was initially described in (Freund &amp; Schapire 1999).
    We applied the methods to a corpus of over one million words of tagged web data.
    The methods give significant improvements over the maximum-entropy tagger (a 17.7% relative reduction in error-rate for the voted perceptron, and a 15.6% relative improvement for the boosting method).
    One contribution of this paper is to show that existing reranking methods are useful for a new domain, named-entity tagging, and to suggest global features which give improvements on this task.
    We should stress that 