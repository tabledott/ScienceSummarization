le Adjacent method is also competent when the training set is small.
    A further inspection into the result of first 3 domains, we can also conclude that: 1) Tree kernels(SVM-WTree and SVM-PTree) are better than Adjacent, SVM-1 and SVM-2 in all domains.
    It proofs that the dependency tree is important in the opinion relation extraction.
    The reason for that is a connection between an opinion and its target can be discovered with various syntactic structures.
    2) The kernel defined on phrase dependency tree (SVM-PTree) outperforms kernel defined on word level dependency tree(SVMWTree) by 4.8% in average.
    We believe the main reason is that phrase dependency tree provides a more succinct tree structure, and the separative treatment of local dependencies and global dependencies in kernel computation can indeed improve the performance of relation extraction.
    To analysis the results of preprocessing steps&#8217; influences on the following relation extraction, we provide 2 additional experiments 