ssible feature value; as detailed in Quinlan (1993), this approach might not be appropriate when there are many values for a feature, which is true for features such as wordi and word2.
    In &amp;quot;Learning 2&amp;quot; C4.5 allows feature values to be grouped into one branch of the decision tree.
    While the &amp;quot;Learning 2&amp;quot; tree is more complex than the tree of Figure 15, it does have slightly better performance.
    The &amp;quot;Learning 2&amp;quot; decision tree predicts the class of a potential boundary site based on the features before, duration, cuei, wordi, word2, coref, infer, and cue-prosody.
    At T = 3, &amp;quot;Learning 1&amp;quot; performance is comparable to human performance (Table 3), and &amp;quot;Learning 2&amp;quot; is slightly better than humans; at T = 4, both learning conditions are superior to human performance.
    The results obtained via machine learning are also better than the results obtained using error analysis (EA in Table 6), primarily due to better pre