this section, we report the results of machine learning experiments, in which we develop probablistic classifiers to automatically perform the subjective and objective classification.
    In the method we use for developing classifiers (Bruce and Wiebe, 1999), a search is performed to find a probability model that captures important interdependencies among features.
    Because features can be dropped and added during search, the method also performs feature selection.
    In these experiments, the system considers naive Bayes, full independence, full interdependence, and models generated from those using forward and backward search.
    The model selected is the one with the highest accuracy on a held-out portion of the training data. sets.
    On each fold, one set is used for testing, and the other nine are used for training.
    Feature selection, model selection, and parameter estimation are performed anew on each fold.
    The following are the potential features considered on each fold.
    A binary fe