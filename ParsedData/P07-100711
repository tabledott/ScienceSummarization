xamples, as compared to the out-of-domain BC examples, will improve the adaptation process.
    Hence, we just use a &#946; value of 3 in our experiments involving count-merging.
  
  
    In this section, we describe an EM-based algorithm that was introduced by Saerens et al. (2002), which can be used to estimate the sense priors, or a priori probabilities of the different senses in a new dataset.
    We have recently shown that this algorithm is effective in estimating the sense priors of a set of nouns (Chan and Ng, 2005).
    Most of this section is based on (Saerens et al., 2002).
    Assume we have a set of labeled data DL with n classes and a set of N independent instances (x1, ... , xN) from a new data set.
    The likelihood of these N instances can be defined as: Assuming the within-class densities p(xk|&#969;i), i.e., the probabilities of observing xk given the class &#969;i, do not change from the training set DL to the new data set, we can define: p(xk|&#969;i) = pL(xk|&#969;i).
    To determine 