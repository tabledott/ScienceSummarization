llel corpus and the LDC news cor pora released for 2005 (LDC, 2005).
			Note that these algorithms are unsupervised by design but we utilizethem to have a baseline for comparing the perfor mance of this supervised approach.
			7.3.1 HMM Max Posterior AlignerThe maximum-posterior word alignments are obtained by finding the link configuration that maxi 93 System # of Add Subtract feats Feature Feature Word pairs 50070 85.03 76.3 Spelling 4 85.11 87.7 Segmentation 70 87.39 87.5(*) WordNet 13789 87.54 87.5 Dynamic-Words 1952 87.80 87.1 Dynamic-Segmentation 42 87.84 87.8 Table 3: Alignment performance in terms of the feature types utilized.
			F-Measure GIZA++ 79.5 HMM 76.3 MaxEnt 87.8 Table 4: Alignment performance mizes the posterior state probability.
			In contrast, in performing a Viterbi alignment, we compute the best state sequence given the observation.
			The maximum posterior computes the best state one at a time and iterates over all possible combinations.
			Once we find the maximum in the posterior pr