			The participants all performed relatively well onthe frame-recognition task, with precision scores av eraging 63% and topping 85%.
	
	
			The testing data for this task turned out to be espe cially challenging with regard to new frames, since, in an effort to annotate especially thoroughly, almost 10340 new frames were created in the process of an notating these three specific passages.
			One result of this was that the test passages had more unseenframes than a random unseen passage, which prob ably lowered the recall on frames.
			It appears that this was not entirely compensated by giving partial credit for related frames.
			This task is a more advanced and realistic version of the Automatic Semantic Role Labeling task of Senseval-3 (Litkowski, 2004).
			Unlike that task, the testing data was previously unseen, participants had to determine the correct frames as a first step, and participants also had to determine FE boundaries, which were given in the Senseval-3.
			A crucial difference from similar 