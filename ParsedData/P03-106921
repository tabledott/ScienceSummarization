lizes inverse rankings.
    Comparison between Model 1 and Model 3 would give a i of 0.244 even though the orders between the two models are identical modulo the beginning and the end.
    This seems appropriate given that flipping the introduction in a document with the conclusions seriously disrupts coherence.
    The model from Section 2.1 was trained on the BLLIP corpus and tested on 20 held-out randomly selected unseen texts (average length 15.3).
    We also used 20 randomly chosen texts (disjoint from the test data) for development purposes (average length 16.2).
    All our results are reported on the test set.
    The input to the the greedy algorithm (see Section 2.2) was a text with a randomized sentence ordering.
    The ordered output was compared against the original authored text using i.
    Table 3 gives the average i (T) for all 20 test texts when the following features are used: lemmatized verbs (VL), tensed verbs (VT), lemmatized nouns (NL), lemmatized verbs and nouns (VLNL), tensed verbs 