
  Investigating GIS And Smoothing For Maximum Entropy Taggers
  
    This paper investigates two elements of Maximum Entropy tagging: the use of a correction feature in the Generalised Iterative Scaling (Gis) estimation algorithm, and techniques for model smoothing.
    We show analytically and empirically that the correction feature, assumed to be required for the correctof unnecessary.
    We also explore the use of a Gaussian prior and a simple cutoff for smoothing.
    The experiments are performed with two tagsets: standard Penn Treebank and the larger set of lexical types from
  
  
    The use of maximum entropy (ME) models has become popular in Statistical NLP; some example applications include part-of-speech (Pos) tagging (Ratnaparkhi, 1996), parsing (Ratnaparkhi, 1999; Johnson et al., 1999) and language modelling (Rosenfeld, 1996).
    Many tagging problems have been successfully modelled in the ME framework, including POS tagging, with state of the art performance (van Halteren et al., 2001), &amp