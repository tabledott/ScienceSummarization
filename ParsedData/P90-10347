object of drink than with wine.
    To capture this intuition, we turn, following Church and Hanks (1989), to &amp;quot;mutual information&amp;quot; (see Fano 1961).
    The mutual information of two events /(x y) is defined as follows: where P(x y) is the joint probability of events x and y, and P(x) and P(y) are the respective independent probabilities.
    When the joint probability P(x y) is high relative to the product of the independent probabilities, f is positive; when the joint probability is relatively low, f is negative.
    We use the observed frequencies to derive a cooccurrence score Cab; (an estimate of mutual information) defined as follows. where fin v) is the frequency of noun n occurring as object of verb v, fin) is the frequency of the noun n occurring as argument of any verb, f(v) is the frequency of the verb v, and N is the count of clauses in the sample.
    (C&#8222;,hi(n v) is defined analogously.)
    Calculating the cooccurrence weight for drink, shown in the third column of Table 2