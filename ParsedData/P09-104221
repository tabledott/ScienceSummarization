ometimes errenously attached to a the following verb rather than being the root of the sentence.
    The rightmost panel of Table 3 shows similar analysis when we also use the rules for the five other closed-class words.
    We see an improvement in attachments in all categories, but no qualitative change is visible.
    The reason for this is probably that these words are relatively rare, but by encouraging the model to add an edge, it also rules out incorrect edges that would cross it.
    Consequently we are seeing improvements not only directly from the constraints we enforce but also indirectly as types of edges that tend to get ruled out.
    The generative model we use is a state of the art model for unsupervised parsing and is our only fully unsupervised baseline.
    As smoothing we add a very small backoff probability of 4.5 x 10&#8722;5 to each learned paramter.
    Unfortunately, we found generative model performance was disappointing overall.
    The maximum unsupervised accuracy it achieved on t