
	
			As one more way to assess the potential benefit from using left and right context in an HMM tagger, we tested our tagging model in the supervised framework, using the same sections of the Treebank previously allocated for unsupervised training, development and testing.
			In addition to comparing against a baseline tagger, which always chooses a word?s most frequent tag, we implemented and trained a version of a standard HMM trigram tagger.
			For further comparison, we evaluated these part of speech taggers against Toutanova et als supervised dependency-network based tagger, which currently achieves the highest accuracy on this dataset to date.
			The best result for this tagger, at 97.24%, makes use of both lexical and tag features coming from the left and right sides of the target.
			We also chose to examine this tagger?s results when using only &lt;ti, t i-1, t i+1&gt; as feature templates, which represents the same amount of context built into our contextualized tagger.
			As shown in Table 3, inc