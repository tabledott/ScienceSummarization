 NIST MT05 and the newsgroup portion of the GALE 2006 dryrun sets.
    The outputs were evaluated on both TER and BLEU.
    As the target evaluation metric in the GALE program was human-mediated TER (HTER) (Snover et al., 2006), it was found important to improve both of these automatic metrics.
    This paper is organized as follows.
    Section 2 describes the evaluation metrics and a generic discriminative optimization technique used in tuning of the various system combination weights.
    Sentence, phrase and word-level system combination methods are presented in Sections 3, 4 and 5.
    Experimental results on Arabic and Chinese to English newswire and newsgroup test data are presented in Section 6.
  
  
    The official metric of the 2006 DARPA GALE evaluation was human-mediated translation edit rate (HTER).
    HTER is computed as the minimum translation edit rate (TER) between a system output and a targeted reference which preserves the meaning and fluency of the sentence (Snover et al., 2006).
    Th