old, but, as we show in this paper, goes a long way toward filtering out erroneous applications of rules.
    In this paper, we propose ISP, a collection of methods for learning inferential selectional preferences and filtering out incorrect inferences.
    The presented algorithms apply to any collection of inference rules between binary semantic relations, such as example (1).
    ISP derives inferential selectional preferences by aggregating statistics of inference rule instantiations over a large corpus of text.
    Within ISP, we explore different probabilistic models of selectional preference to accept or reject specific inferences.
    We present empirical evidence to support the following main contribution: Claim: Inferential selectional preferences can be automatically learned and used for effectively filtering out incorrect inferences.
  
  
    Selectional preference (SP) as a foundation for computational semantics is one of the earliest topics in AI and NLP, and has its roots in (Katz and Fodor 19