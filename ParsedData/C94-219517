lso used training and test datt~ drawn from the Penn Treebank's Wall Street Jour- nal corpus.
			Instead of' using mammlly coustructed lexical classes, they nse word classes arrived at via mutmd information clustering in a training corpus (BDd+92), resulting in a representation i which each word is represented by a sequence of bits.
			As in the experiments here, their statistical model also makes use of a 4-tuple context (v, c&lt;l, p, n2), and can use the identit.ies of the words, class inl'or- marion (tbr them, wdues of any of the class bits), rThe difference between these results ~nd tile result they quoted is likely due to a much bLrger training set used in their origimd experiments.
			1202 or both Mnds of i ld'ormation as eotll;extual fea- tlll?eS riley {lescril)e a search process use(\[ to {letePn6\]m what, sul)set of the available ill\['or,~Ht- l ion will Im used in the model.
			(\]iv{;\]\] a eh{}ice of features, they train ;t prol}abi/islie model For I)r(Sitclcoutext), and in {.esl.ing choose Site 