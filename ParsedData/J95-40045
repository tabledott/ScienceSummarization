ave to realize that, usually, a word one or two words to the right of a modal is a verb and not a noun.
    An exception to this generalization arises when the word is also one word to the right of a determiner.
    It is an exciting discovery that simple stochastic n-gram taggers can obtain very high rates of tagging accuracy simply by observing fixed-length word sequences, without recourse to the underlying linguistic structure.
    However, in order to make progress in corpus-based natural language processing, we must become better aware of just what cues to linguistic structure are being captured and where these approximations to the true underlying phenomena fail.
    With many of the current corpus-based approaches to natural language processing, this is a nearly impossible task.
    Consider the part-of-speech tagging example above.
    In a stochastic n-gram tagger, the information about words that follow modals would be hidden deeply in the thousands or tens of thousands of contextual probabilities (