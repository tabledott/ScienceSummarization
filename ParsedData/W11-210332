 judgments collected during the manual evaluation for the translation task and the system combination task to calculate how well metrics correlate at system-level and at the segment-level.
    This year the strongest metric was a new metric developed by Columbia and ETS called MTeRaterPlus.
    MTeRater-Plus is a machine-learning-based metric that use features from ETS&#8217;s e-rater, an automated essay scoring engine designed to assess writing proficiency (Attali and Burstein, 2006).
    The features include sentence-level and document-level information.
    Some examples of the e-rater features include: MTeRater uses only the e-rater features, and measures fluency without any need for reference translations.
    MTeRater-Plus is a meta-metric that incorporates adequacy by combining MTeRater with other MT evaluation metrics and heuristics that take the reference translations into account.
    Please refer to the proceedings for papers providing detailed descriptions of all of the metrics. for translation ou