the regular TBL has an almost quadratic dependency.
    The explanation for this behavior has been given in Section 3.3.
    Figure 2(b) shows the time spent at each iteration versus the iteration number, for the original TBL and fast TBL systems.
    It can be observed that the time taken per iteration increases dramatically with the iteration number for the regular TBL, while for the FastTBL, the situation is reversed.
    The consequence is that, once a certain threshold has been reached, the incremental time needed to train the FastTBL system to completion is negligible.
  
  
    We have presented in this paper a new and improved method of computing the objective function for transformation-based learning.
    This method allows a transformation-based algorithm to train an observed 13 to 139 times faster than the original one, while preserving the final performance of the algorithm.
    The method was tested in three different domains, each one having different characteristics: part-of-speech tagging, pr