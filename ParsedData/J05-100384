er of rounds of feature selection goes to infinity, the LogLoss approaches its minimum value.
    The algorithms in Figures 3 and 4 could be modified to take the alternative definitions of W&#254;k and Wk into account, thereby being modified to optimize LogLoss instead of ExpLoss.
    The denominator terms in the qi,j definitions in equation (B.1) may complicate the algorithms somewhat, but it should still be possible to derive relatively efficient algorithms using the technique.
    For a full derivation of the modified updates and for quite technical convergence proofs, see Collins, Schapire and Singer (2002).
    We give a sketch of the argument here.
    First, we show that LogLoss&#240;Upd&#240;&#175;a, k, d&#222;&#222; &lt; LogLoss&#240;&#175;a &#8212; W&#254;k &#8212; Wk &#254; W&#254;k e~d &#254; Wk ed&#222; &#240;B.4&#222; Equation (B.6) can be derived from equation (B.5) through the bound log&#240;1 + x&#222; &lt; x for all x.
    The second step is to minimize the right-hand side of the bound in eq