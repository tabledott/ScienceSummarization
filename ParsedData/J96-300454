he axis labels represent the amount of variation in the data explained by the dimension in question. cases.
    Nonetheless, the results of the comparison with human judges demonstrates that there is mileage being gained by incorporating models of these types of words.
    It may seem surprising to some readers that the interhuman agreement scores reported here are so low.
    However, this result is consistent with the results of experiments discussed in Wu and Fung (1994).
    Wu and Fung introduce an evaluation method they call nk-blind.
    Under this scheme, n human judges are asked independently to segment a text.
    Their results are then compared with the results of an automatic segmenter.
    For a given &amp;quot;word&amp;quot; in the automatic segmentation, if at least k of the human judges agree that this is a word, then that word is considered to be correct.
    For eight judges, ranging k between 1 and 8 corresponded to a precision score range of 90% to 30%, meaning that there were relatively f