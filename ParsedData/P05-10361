sion problems, such as text-to-abstract conversion, by eliminating the need for coherency between sentences.
    The model is further simplified by being constrained to word deletion: no rearranging of words takes place.
    Others have performed the sentence compression task using syntactic approaches to this problem (Mani et al., 1999) (Zajic et al., 2004), but we focus exclusively on the K&amp;M formulation.
    Though the problem is simpler, it is still pertinent to current needs; generation of captions for television and audio scanning services for the blind (Grefenstette, 1998), as well as compressing chosen sentences for headline generation (Angheluta et al., 2004) are examples of uses for sentence compression.
    In addition to simplifying the task, K&amp;M&#8217;s noisy-channel formulation is also appealing.
    In the following sections, we discuss the K&amp;M noisy-channel model.
    We then present our cleaned up, and slightly improved noisy-channel model.
    We also develop unsupervised and sem