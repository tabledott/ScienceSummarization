.
    If the original rich feature representation of Malt is sufficient to separate the training data, regularization may force the weights of the guided features to be small (since they are not needed at training time).
    On the other hand, an online learning algorithm will recognize the guided features as strong indicators early in training and give them a high weight as a result.
    Features with high weight early in training tend to have the most impact on the final classifier due to both weight regularization and averaging.
    This is in fact observed when inspecting the weights of MSTMalt.
  
  
    Combinations of graph-based and transition-based models for data-driven dependency parsing have previously been explored by Sagae and Lavie (2006), who report improvements of up to 1.7 percentage points over the best single parser when combining three transition-based models and one graph-based model for unlabeled dependency parsing, evaluated on data from the Penn Treebank.
    The combined parsing mode