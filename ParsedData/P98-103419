of NPs in the annotated text Table 1 summarizes the performance of the treebank approach to base NP identification on the R&amp;M and Empire corpora using the initial and pruned rule sets.
    The first column of results shows the performance of the initial, unpruned base NP grammar.
    The next two columns show the performance of the automatically pruned rule sets.
    The final column indicates the performance of rule sets that had been pruned using the handcrafted pruning heuristics.
    As expected, the initial rule set performs quite poorly.
    Both automated approaches provide significant increases in both recall and precision.
    In addition, they outperform the rule set pruned using handcrafted pruning heuristics.
    Many errors appear to stem from four underlying causes.
    First, close to 20% can be attributed to errors in the Treebank and in the Base NP corpus, bringing the effective performance of the algorithm to 94.2P/95.9R and 91.5P/92.7R for the Empire and R&amp;M corpora, respectively.
 