ed answers from consideration (Method 1), the overall accuracy of the Q/A system increased by 12% over the baseline (when an EAT could be identified) and by nearly 9% (when no EAT could be identified).
    In contrast, when entailment information was used to rank passages and candidate answers, performance increased by 22% and 10% respectively.
    Somewhat smaller performance gains were achieved when TE was used to select amongst AGQs generated by our Q/A system&#8217;s AutoQUAB module (Method 3).
    We expect that by adding features to TE system specifically designed to account for the semantic contributions of a question&#8217;s EAT, we may be able to boost the performance of this method.
  
  
    In this paper, we discussed three different ways that a state-of-the-art textual entailment system could be used to enhance the performance of an open-domain Q/A system.
    We have shown that when textual entailment information is used to either filter or rank candidate answers returned by a Q/A system, Q/A ac