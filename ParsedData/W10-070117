tic things like doing human-in-the-loop min imum error rate training for machine translation (Zaidan and Callison-Burch, 2009).Some projects have demonstrated the super scalability of crowdsourced efforts.
			Deng et al(2009) used MTurk to construct ImageNet, an anno tated image database containing 3.2 million that arehierarchically categorized using the WordNet ontol ogy (Fellbaum, 1998).
			Because Mechanical Turkallows researchers to experiment with crowdsourc ing by providing small incentives to Turkers, other successful crowdsourcing efforts like Wikipedia or Games with a Purpose (von Ahn and Dabbish, 2008) also share something in common with MTurk.
	
	
			The workshop included a shared task in which participants were provided with $100 to spend on Me chanical Turk experiments.
			Participants submitted a 1 page proposal in advance describing their intended use of the funds.
			Selected proposals were provided $100 seed money, to which many participants added their own funds.
			As part of their particip