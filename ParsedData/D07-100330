 development and test setsof our model in comparison with the baseline algo rithms are shown in Table 2.
			Both our model and the model in Cui et al (2005) are trained on the manually-judged training set (questions 1-100 fromTREC 8?12).
			The approximate tree matching algorithm in Punyakanok et al (2004) uses fixed edit distance functions and therefore does not require training.
			From the table we can see that our model signif icantly outperforms the two baseline algorithms?
			even when they are given the benefit of WordNet?
			on both development and test set, and on both MRR and MAP.
			5.4 Experiments with Noisy Training Data.
			Although manual annotation of the remaining 2,293 training sentences?
			answers in TREC 8?12 was too labor-intensive, we did experiment with a simple, noisy automatic labeling technique.
			Any answer that had at least three non-stop word types seen in the question and contains the answer pattern defined in the dataset was labeled as ?correct?
			and used intraining.
			The 