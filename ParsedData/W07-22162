with no two edges crossing.
    Conversely, a non-projective dependency graph does not satisfy this property.
    Figure 2 gives an example of a nonprojective graph for a sentence that has also been extracted from the Penn Treebank.
    Non-projectivity arises due to long distance dependencies or in languages with flexible word order.
    For many languages, a significant portion of sentences require a non-projective dependency analysis (Buchholz et al., 2006).
    Thus, the ability to learn and infer nonprojective dependency graphs is an important problem in multilingual language processing.
    Syntactic dependency parsing has seen a number of new learning and inference algorithms which have raised state-of-the-art parsing accuracies for many languages.
    In this work we focus on datadriven models of dependency parsing.
    These models are not driven by any underlying grammar, but instead learn to predict dependency graphs based on a set of parameters learned solely from a labeled corpus.
    The advanta