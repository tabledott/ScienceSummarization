s is that every tree in G projects under &#960; to a tree in G' with the same or higher probability, which is true because every rule in G does.
    Therefore, we know that &#945;G(e, s) &lt; &#945;G1(e, s).
    If G' is much more compact than G, for each new sentence s, we can first rapidly calculate a&#960; = &#945;G1 for all edges, then parse with G. The identity projection t returns G and therefore a&#953; is TRUE.
    On the other extreme, a constant projection gives NULL (if any rewrite has probability 1).
    In between, we tried three other grammar projection estimates (examples in figure 3).
    First, consider mapping all terminal states to a single terminal token, but not altering the grammar in any other way.
    If we do this projection, then we get the SX estimate from the last section (collapsing the terminals together effectively hides which terminals are in the context, but not their number).
    However, the resulting grammar is nearly as large as G, and therefore it is much more efficient t