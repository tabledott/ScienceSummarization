1000 and 11100000, considering only one of those can negatively bias the model.
  
  
    In this section, we present empirical results of our algorithms on two domains: citations and advertisements.
    Both problems are modeled with a simple token-based HMM.
    We stress that token-based HMM cannot represent many of our constraints.
    The function d(y, 1C(x)) used is an approximation of a Hamming distance function, discussed in Section 7.
    For both domains, and all the experiments, -y was set to 0.1.
    The constraints violation penalty p is set to &#8722; log 10&#8722;4 and &#8722; log 10&#8722;1 for citations and advertisements, resp.2 Note that all constraints share the same penalty.
    The number of semi-supervised training cycles (line 3 of Figure 2) was set to 5.
    The constraints for the two domains are listed in Table 1.
    We trained models on training sets of size varying from 5 to 300 for the citations and from 5 to 100 for the advertisements.
    Additionally, in all the semi-supervis