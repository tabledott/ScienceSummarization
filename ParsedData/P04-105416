he bagof-words kernel.
    Joachims et al. (2001) have shown that given two kernels K1, K2, the composite kernel K12(xi, xj) = K1(xi, xj)+K2(xi, xj) is also a kernel.
    We find that this composite kernel improves performance when the Gram matrix G is sparse (i.e. our instances are far apart in the kernel space).
    The features used to represent each node are shown in Table 3.
    After initial experimentation, the set of features we use in the matching function is &#966;m(ti) = {general-pos, entity-type, relationargument}, and the similarity function examines the remaining features.
    In our experiments we tested the following five kernels: We also experimented with the function C(vq, vr), the compatibility function between two feature values.
    For example, we can increase the importance of two nodes having the same Wordnet hypernym2.
    If vq, vr are hypernym features, then we can define When &gt; 1, we increase the similarity of nodes that share a hypernym.
    We tested a number of weighting sche