c objects: that is, both the s&#732; and the t&#732; in the expression p(&#732;s|&#732;t) are treated as units about which nothing is known except their counts.
    In contrast, glass-box methods break phrases down into their component words.
    The black-box approach, which is the simpler of the two, has received little attention in the SMT literature.
    An interesting aspect of this approach is that it allows one to implement phrasetable smoothing techniques that are analogous to LM smoothing techniques, by treating the problem of estimating p(&#732;s|&#732;t) as if it were the problem of estimating a bigram conditional probability.
    In this paper, we give experimental results for phrasetable smoothing techniques analogous to Good-Turing, Fixed-Discount, Kneser-Ney, and Modified Kneser-Ney LM smoothing.
    Glass-box methods for phrasetable smoothing have been described by other authors: see section 3.3.
    These authors decompose p(&#732;s|&#732;t) into a set of lexical distributions p(s|&#732;t) by