s seen in test data will frequently be seen only once or twice in training data.
    An experiment was made with all counts less than 5 being put to zero,6 effectively making the algorithm ignore low count events.
    In [RRR94] a cut-off 'between 3 and 5' is used for all events.
    The training and test data were both the unprocessed, original data sets.
    The results were as follows: We have excluded tuples which do not contain a preposition from the model.
    This section gives results which justify this.
    The table below gives accuracies for the sub-tuples at each stage of backing-off.
    The accuracy figure for a particular tuple is obtained by modifying the algorithm in section 4.1 to use only information from that tuple at the appropriate stage.
    For example for (v, nl, n2), stage 2 would be modified to read If f(v, nl, n2) &gt; 0, All other stages in the algorithm would be unchanged.
    The accuracy figure is then the percentage accuracy on the test cases where the (v, nl, n2) counts were 