come broken into appropriately matching chunks, so it is up to the parser to decide when to break up potential collocations into individual words.
    The problem is particularly acute for English and Chinese because word boundaries are not orthographically marked in Chinese text, so not even a default chunking exists upon which word matchings could be postulated.
    (Sentences (2) and (5) demonstrate why the obvious trick of taking single characters as words is not a workable strategy.)
    The usual Chinese NLP architecture first preprocesses input text through a word segmentation module (Chiang et al. 1992; Lin, Chiang, and Su 1992, 1993; Chang and Chen 1993; Wu and Tseng 1993; Sproat et al.
    1994; Wu and Fung 1994), but, clearly, bilingual parsing will be hampered by any errors arising from segmentation ambiguities that could not be resolved in the isolated monolingual context because even if the Chinese segmentation is acceptable monolingually, it may not agree with the words present in the English s