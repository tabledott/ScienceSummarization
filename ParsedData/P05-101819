ral humans.
    To ensure that we do not tune a model to a particular system, we used the output summaries of distinct systems for training and testing.
    Our set of training materials contained 4 &#183; 16 summaries (average length 4.8), yielding (4)&#183;16 = 96 pairwise rankings.
    2 In a similar fashion, we obtained 32 pairwise rankings for the test set.
    Six documents from the training data were used as a development set.
    Coherence ratings were obtained during an elicitation study by 177 unpaid volunteers, all native speakers of English.
    The study was conducted remotely over the Internet.
    Participants first saw a set of instructions that explained the task, and defined the notion of coherence using multiple examples.
    The summaries were randomized in lists following a Latin square design ensuring that no two summaries in a given list were generated from the same document cluster.
    Participants were asked to use a seven point scale to rate how coherent the summaries were without h