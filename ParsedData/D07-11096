ble.
			Given a word assumed to be generated by a WORDNET-WALK, we can use posterior inference to predict which synset produced the word.
			These properties allow us to develop LDAWN, which is a fusion of these WORDNET-WALKs and latent Dirichlet alocation (LDA) (Blei et al, 2003),a probabilistic model of documents that is an im provement to pLSI (Hofmann, 1999).
			LDA assumes that there are K ?topics,?
			multinomial distributionsover words, which describe a collection.
			Each docu ment exhibits multiple topics, and each word in each document is associated with one of them.
			Although the term ?topic?
			evokes a collection of ideas that share a common theme and although the topics derived by LDA seem to possess semantic coherence, there is no reason to believe this would 1025 be true of the most likely multinomial distributions that could have created the corpus given the assumed generative model.
			That semantically similar words are likely to occur together is a byproduct of how language is actually u