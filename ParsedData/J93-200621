rds.
    Adding a model of capitalization to the other two models further increased the accuracy to 85%.
    The total effect of BBN's model has been a reduction of a factor of five in the error rate of the best previously reported performance.
    Decreasing error rate with use of word features.
    An alternative mode of running POST is to return the set of most likely tags for each word, rather than a single tag for each.
    In our first test, the system returned the sequence of most likely tags for the sentence.
    This has the advantage of eliminating ambiguity; however, even with a rather low error rate of 3.7%, there are cases in which the system returns the wrong tag, which can be fatal for a parsing system trying to deal with sentences averaging more than 20 words in length.
    De Marcken (1990) developed an approximate method for finding multiple tags for each word given the preceding words and one following word.
    We addressed this problem by adding the ability of the tagger to return for eac