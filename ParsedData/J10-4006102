
    For SEMEVAL, the table reports the results of those models that took part in the shared task and, like ours, did not use the organizer-provided WordNet sense labels nor information about the query used to retrieve the examples.
    All these models are outperformed by TypeDM, despite the fact that they exploit the training contexts and/or specific additional resources: an annotated compound database (UCD-FC), more sophisticated machine learning algorithms to train the relation classifiers (ILK, UCD-FC), Web counts (UCB), and so on.
    For the NS data set, none of the DM models do well, although TypeDM is once more the best among them.
    The DM models are outperformed by other models from the literature, all trained on much larger corpora, and also by our implementation of LRA.
    The difference in global accuracy between LRA and TypeDM is significant (Fisher test, p = 0.00002).
    TypeDM&#8217;s accuracy is nevertheless well above the best (Majority) baseline accuracy (p = 0.0001).
    The OC result