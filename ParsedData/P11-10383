even more complex, e.g. with word lengthening such as goooood being commonplace for emphasis.
    In addition, the detection of ill-formed words is difficult due to noisy context.
    Our objective is to restore ill-formed words to their canonical lexical forms in standard English.
    Through a pilot study, we compared OOV words in Twitter and SMS data with other domain corpora, revealing their characteristics in OOV word distribution.
    We found Twitter data to have an unsurprisingly long tail of OOV words, suggesting that conventional supervised learning will not perform well due to data sparsity.
    Additionally, many illformed words are ambiguous, and require context to disambiguate.
    For example, Gooood may refer to Good or God depending on context.
    This provides the motivation to develop a method which does not require annotated training data, but is able to leverage context for lexical normalisation.
    Our approach first generates a list of candidate canonical lexical forms, based on morph