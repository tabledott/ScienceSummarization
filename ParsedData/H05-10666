sed Factorization.
			In what follows, x = x1 ? ?
			xn represents a genericinput sentence, and y represents a generic depen dency tree for sentence x. Seeing y as the set of tree edges, we write (i, j) ? y if there is a dependency in y from word xi to word xj .In this paper we follow a common method of fac toring the score of a dependency tree as the sum of the scores of all edges in the tree.
			In particular, wedefine the score of an edge to be the dot product be 524 tween a high dimensional feature representation of the edge and a weight vector, s(i, j) = w ? f(i, j) Thus the score of a dependency tree y for sentence x is, s(x,y) = ?
			(i,j)?y s(i, j) = ?
			(i,j)?y w ? f(i, j) Assuming an appropriate feature representation as well as a weight vector w, dependency parsing is the task of finding the dependency tree y with highest score for a given sentence x. For the rest of this section we assume that the weight vector w is known and thus we know the score s(i, j) of each possible edge.
			In Section 3 w