 the assumption that &#8220;The closer a machine translation is to a professional human translation, the better it is&#8221; (Papineni et al., 2002).
    For every hypothesis, BLEU computes the fraction of n-grams which also appear in the reference sentences, as well as a brevity penalty.
    NIST uses a similar strategy to BLEU but further considers that n-grams with different frequency should be treated differently in the evaluation.
    It introduces the notion of information weights, which indicate that rarely occurring n-grams count more than those frequently occurring ones in the evaluation (Doddington, 2002).
    BLEU and NIST have been shown to correlate closely with human judgments in ranking MT systems with different qualities (Papineni et al., 2002; Doddington, 2002).
    In the 2003 Johns Hopkins Workshop on Speech and Language Engineering, experiments on MT evaluation showed that BLEU and NIST do not correlate well with human judgments at the sentence level, even when they correlate well over lar