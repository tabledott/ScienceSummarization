ries.
    We leave the recovery of the categories of entities to a separate stage of processing.1 We evaluate different methods on the task through precision and recall.
    If a method proposes entities on the test set, and of these are correct (i.e., an entity is marked by the annotator with exactly the same span as that proposed) then the precision of a method is .
    Similarly, if is the total number of entities in the human annotated version of the test set, then the recall is .
    The problem can be framed as a tagging task &#8211; to tag each word as being either the start of an entity, a continuation of an entity, or not to be part of an entity at all (we will use the tags S, C and N respectively for these three cases).
    As a baseline model we used a maximum entropy tagger, very similar to the ones described in (Ratnaparkhi 1996; Borthwick et.
    al 1998; McCallum et al. 2000).
    Max-ent taggers have been shown to be highly competitive on a number of tagging tasks, such as part-of-speech taggi