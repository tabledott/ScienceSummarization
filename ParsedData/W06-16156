ll of type &lt;the token on the right&gt;.
    Note that &#8220;signal&#8221; is unambiguously a noun in these contexts.
    Adjectives rarely precede past tense verbs such as &#8220;required&#8221; or prepositions such as &#8220;from&#8221; and &#8220;for&#8221;.
    We now search for occurrences of the pivot features in the WSJ.
    Figure 2(c) shows some words that occur together with the pivot features in the WSJ unlabeled data.
    Note that &#8220;investment&#8221;, &#8220;buy-outs&#8221;, and &#8220;jail&#8221; are all common nouns in the financial domain.
    Furthermore, since we have labeled WSJ data, we expect to be able to label at least some of these nouns correctly.
    This example captures the intuition behind structural correspondence learning.
    We want to use pivot features from our unlabeled data to put domain-specific words in correspondence.
    That is, we want the pivot features to model the fact that in the biomedical domain, the word signal behaves similarly to the words investment