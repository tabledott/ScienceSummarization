lish and Spanish, starting from the top 1000 hits yielded up by Altavista in the candidate generation stage, leading to a set of 913 candidate pairs.
    A test set of 179 items was generated for annotation by human judges, containing: It was impractical to manually evaluate all pairs filtered out structurally, owing to the time required for judgments and the desire for two independent judgments per pair in order to assess inter-judge reliability.
    The two judges were both native speakers of Spanish with high proficiency in English, neither previously familiar with the project.
    They worked independently, using a Web browser to access test pairs in a fashion that allowed them to view pairs side by side.
    The judges were told they were helping to evaluate a system that identifies pages on the Web that are translations of each other, and were instructed to make decisions according to the following criterion: Is this pair of pages intended to show the same material to two different users, one a reader o