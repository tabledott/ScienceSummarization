s moderate to substantial for most tasks. annotators rank five outputs at once, P(A = B) = 3, not &#65533;, since there are only five (out of 25) label pairs that satisfy 1 A = B.
    Working this back into P(E)&#8217;s definition, we have P(A &gt; B) = P(A &lt; B) = 5, and therefore P(E) = 0.36 rather than 0.333. and 50 below for a detailed breakdown by language pair.
    However, one result that is of concern is that agreement rates are noticeably lower for European language pairs, in particular for the individual systems track.
    When excluding reference comparisons, the inter- and intra-annotator agreement levels are 0.320 and 0.512, respectively.
    Not only are those numbers lower than for the other tasks, but they are also lower than last year&#8217;s numbers, which were 0.409 and 0.580.
    We investigated this result a bit deeper.
    Tables 49 and 50 in the Appendix break down the results further, by reporting agreement levels for each language pair.
    One observation is that the agreement leve