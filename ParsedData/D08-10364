e to use Bayesian inference to find a single model, such as the Maximum A Posteriori or MAP value of 0 which maximizes the posterior P(0  |d), this is not necessarily the best approach (Bishop, 2006; MacKay, 2003).
    Instead, rather than commiting to a single value for the parameters 0 many Bayesians often prefer to work with the full posterior distribution P(0  |d), as this naturally reflects the uncertainty in 0&#8217;s value.
    In all but the simplest models there is no known closed form for the posterior distribution.
    However, the Bayesian literature describes a number of methods for approximating the posterior P(0  |d).
    Monte Carlo sampling methods and Variational Bayes are two kinds of approximate inference methods that have been applied to Bayesian inference of unsupervised HMM POS taggers (Goldwater and Griffiths, 2007; Johnson, 2007).
    These methods can also be used to approximate other distributions that are important to us, such as the conditional distribution P(t  |w) of POS tags (i