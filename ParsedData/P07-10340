
  Instance Weighting for Domain Adaptation in NLP
  
    Domain adaptation is an important problem in natural language processing (NLP) due to the lack of labeled data in novel domains.
    In this paper, we study the domain adaptation problem from the instance weighting perspective.
    We formally analyze and characterize the domain adaptation problem from a distributional view, and show that there are two distinct needs for adaptation, corresponding to the different distributions of instances and classification functions in the source and the target domains.
    We then propose a general instance weighting framework for domain adaptation.
    Our empirical results on three NLP tasks show that incorporating and exploiting more information from the target domain through instance weighting is effective.
  
  
    Many natural language processing (NLP) problems such as part-of-speech (POS) tagging, named entity (NE) recognition, relation extraction, and semantic role labeling, are currently solved by supervis