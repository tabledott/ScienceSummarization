   As we can see, the ranker achieves F-scores of 57.8&#8211;71.2 and 54.1&#8211;65.4 for true mentions and system mentions, respectively, yielding a significant improvement over the entity-mention baseline in all but one case (MUC/true mentions).
    In the second method, we perform discoursenew detection jointly with coreference resolution using the method described in Section 4.2.
    While we discussed this joint learning method in the context of cluster ranking, it should be easy to see that the method is equally applicable to a mention ranker.
    Results of the mention ranker using this joint architecture are shown in row 4 of Tables 3 and 4.
    As we can see, the ranker achieves F-scores of 61.6&#8211;73.4 and 55.6&#8211;67.1 for true mentions and system mentions, respectively.
    For both types of mentions, the improvements over the corresponding results for the entity-mention baseline are significant, and suggest that mention ranking is a precision-enhancing device.
    Moreover, in comparison to 