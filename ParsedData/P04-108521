a discussion of the problem in (McCallum et al., 2000)).
    Conditional models address these concerns.
    Conditional Markov models (CMM) (Ratnaparkhi, 1996; Klein and Manning, 2002) have been successfully used in sequence labeling tasks incorporating rich feature sets.
    In a left-to-right CMM as shown in Figure 1(a), the probability of a sequence of L tags is decomposed as: is the vector of observations and each is the index of a spurt.
    The probability distribution associated with each state of the Markov chain only depends on the preceding tag and the local observation .
    However, in order to incorporate more than one label dependency and, in particular, to take into account the four pragmatic and , there is then a direct dependency between and , and the probability model becomes .
    This is a simplifying example; in practice, each label is dependent on a fixed number of other labels. contextual dependencies discussed in the previous subsection, we must augment the structure of our model to ob