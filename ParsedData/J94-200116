built by RF training over the whole training data and all the successive models created by the iterations of ML training.
    For each of these models we performed Viterbi tagging and ML tagging on the same test data, then evaluated and compared the number of tagging errors produced by these two methods.
    The results are shown in Table 3.
    The models obtained at different iterations are related, so one should not draw strong conclusions about the definite superiority of one tagging procedure.
    However, the difference in error rate is very small, and shows that the choice of the tagging procedure is not as critical as the kind of training material.
    Following a suggestion made by F. Jelinek, we investigated the effect of constraining the ML training by imposing constraints on the probabilities.
    This idea comes from the observation that the amount of training data needed to properly estimate the model increases with the number of free parameters of the model.
    In the case of little training d