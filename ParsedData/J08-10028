ova et al. 2002; Toutanova and Manning 2002; Baldridge and Osborne 2003; Malouf and van Noord 2004) have also adopted log-linear models.
    This is because these grammar formalisms exploit feature structures to represent linguistic constraints.
    Such constraints are known to introduce inconsistencies in probabilistic models estimated using simple relative frequency, as discussed in Abney (1997).
    The maximum entropy model is a reasonable choice for credible probabilistic models.
    It also allows various overlapping features to be incorporated, and we can expect higher accuracy in disambiguation.
    A maximum entropy model gives a probabilistic distribution that maximizes the likelihood of training data under given feature functions.
    Given training data E = {(x, y)}, a maximum entropy model gives conditional probability p(y|x) as follows.
    Definition 1(Maximum entropy model) A maximum entropy model is defined as the solution of the following optimization problem.
    In this definition, &#732;