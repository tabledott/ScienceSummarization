   The estimation method in model 2 effectively estimates the probability of a rule as The left and right subcategorization frames, LC and RC, are chosen first.
    The entire rule is then generated by Markov processes.
    Once armed with the Pl, and Pr, parameters, the model has the ability to learn the generalization that told appears with a quite limited, sharp distribution over subcategorization frames.
    Say that these parameters are again estimated through interpolation, for example In this case &#955; can be quite high.
    Only five subcategorization frames (as opposed to 26 rule types) have been seen in the 147 cases.
    The lexically specific distribution Pml(LC I VP, told) can therefore be quite highly trusted.
    Relatively little probability mass is left to the backed-off estimate.
    In summary, from the distributions in Table 13, the model should be quite uncertain about what rules told can appear with.
    It should be relatively certain, however, about the subcategorization frame.
    I