 NETWORKS Artificial neural networks consist of a large number of simple processing units.
  These units are highly inter- connected by directed weighted links.
  Associated with each unit is an activation value.
  Through tile connec- tions, this activation is propagated to other units.
  In mnltilayer perceptron etworks (MLP-networks), tile most popular network type, the processing units are arranged vertically in several ayers (fig.
  Con- nections exist only between units in adjacent layers.
  The bottom layer is called input layer, because the activations of the units in this layer represent the in- put of tile network.
  Correspondingly, the top layer is called output layer.
  Any layers between input layer 772 Figure 1: A 3-layer perceptron etwork ( output units hidden units b input units and outlmt layer are called hidden layers.
  Their acti- wttions are not visible externally.
  During the processing in a MLP-network, actiwt- tions are propagated from inlmt units through hidden units to output units