(produced by the WSJ-trained reranker) achieves a labeled precision-recall f-measure of 87.8% on Brown data, nearly equal to the performance one achieves by using a purely Brown trained parser-reranker.
    The 87.8% f-score on Brown represents a 24% error reduction on the corpus.
    Of course, as corpora differences go, Brown is relatively close to WSJ.
    While we also find that our the difference in parentheses as estimated by a randomization test with 106 samples.
    &#8220;x/y&#8221; indicates that the first-stage parser was trained on data set x and the second-stage reranker was trained on data set y.
    &#8220;best&#8221; WSJ-parser-reranker improves performance on the Switchboard corpus, it starts from a much lower base (74.0%), and achieves a much less significant improvement (3% absolute, 11% error reduction).
    Bridging these larger gaps is still for the future.
    One intriguing idea is what we call &#8220;self-trained bridging-corpora.&#8221; We have not yet experimented with medical text 