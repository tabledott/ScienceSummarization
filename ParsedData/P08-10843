individual words.
    For this reason, English should provide a strong source of disambiguation for highly inflected languages, such as Arabic and Hebrew.
    In general, we pose the following question.
    In which scenario will multilingual learning be most effective?
    Will it be for related languages, which share a common core of linguistic features, or for distant languages, whose linguistic divergence can provide strong sources of disambiguation?
    As a first step towards answering this question, we propose a model which can take advantage of both similarities and differences across languages.
    This joint bilingual model identifies optimal morphemes for two languages and at the same time finds compact multilingual representations.
    For each language in the pair, the model favors segmentations which yield high frequency morphemes.
    Moreover, bilingual morpheme pairs which consistently share a common semantic or syntactic function are treated as abstract morphemes, generated by a single langu