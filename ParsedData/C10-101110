ures ya and the reference structure yi.
			It updates ??v as well, whereby the algorithm additionally weights the updates by ?.
			Since the algorithm decreases ? in each round, the algorithm adapts the weights more aggressively at the beginning (Crammer etal., 2006).
			After all iterations, the algorithm com putes the average of ??v , which reduces the effect of overfitting (Collins, 2002).
			We have inserted into the training algorithm functions to measure the start times ts and the end times te for the procedures to compute andstore the features, to read the features, to predict the projective parse, and to calculate the nonprojective approximation.
			We calculate the aver age elapsed time per instance, as the average over all training examples and epochs: tx = ?E?I k=1 t e x,k?tsx,k E?I . We use the training set and the test set of theCoNLL shared task 2009 for our experiments.
			Ta ble 1 shows the elapsed times in 11000 seconds (milliseconds) of the selected languages for the procedure calls in the l