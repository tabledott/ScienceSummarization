ing words as column labels, the 50,000 most frequent terms in the corpus were assigned row vectors by counting the number of times they oc'A &#8220;stoplist&#8221; is a list of frequent words which have little independent semantic content, such as prepositions and determiners (Baeza-Yates and Ribiero-Neto, 1999, p167). curred within the same sentence as a content-bearing word.
    Singular-value decomposition (Deerwester et al., 1990) was then used to reduce the number of dimensions from 1000 to 100.
    Similarity between two vectors (points) was measured using the cosine of the angle between them, in the same way as the similarity between a query and a document is often measured in information retrieval (Baeza-Yates and Ribiero-Neto, 1999, p28).
    Effectively, we could use LSA to measure the extent to which two words or MWEs x and y usually occur in similar contexts.
    Since the corpora had been tagged with parts-ofspeech, we could build syntactic distinctions into the LSA models &#8212; instead of just