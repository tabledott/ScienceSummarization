eatures to a preliminary release of the Propbank data.
    The dataset used contained annotations for 26,138 predicate-argument structures containing 65,364 individual arguments and containing examples from 1,527 lexical predicates (types).
    In order to provide results comparable with the statistical parsing literature, annotations from Section 23 of the Treebank were used as the test set; all other sections were included in the training set.
    The system was tested under two conditions, one in which it is given the constituents which are arguments to the predicate and merely has to predict the correct role, and one in which it has to both find the arguments in the sentence and label them correctly.
    Results are shown in Tables 1 and 2.
    Although results for Propbank are lower than for FrameNet, this appears to be primarily due to the smaller number of training examples for each predicate, rather than the difference in annotation style between the two corpora.
    The FrameNet data contained at lea