1.
  The training examples include 90,352 propositions with a total of 332,381 arguments.
  The test data contain 5,246 propositions and 19,511 arguments.
  As shown in the table, although the full-parsing features are more helpful than the shallow-parsing features, the perfor- mance gap is quite small (0.75% on gold-standard data and 0.61% with the automatic parsers).
  The rather small difference in the performance between argument classifiers using full parsing and shallow parsing information almost disappears when their output is processed by the inference stage.
  Table 3 shows the final results in recall, precision, and F1, when the argument boundaries are known.
  In all cases, the differences in F1 between the full parsing?based and the shallow parsing?based systems are not statistically significant.
  When the argument boundaries are known, the performance of the full parsing?based SRL system is about the same as the shallow parsing?based SRL system.
  4.3 Argument Identification Argument identificat