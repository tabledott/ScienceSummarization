d tested that model using the other topics.
    Figure 1 shows the results of this experiment.
    The tendency seems to be that performance in a given topic is best if the training data is from the same topic.
    For example, the Finance-trained SVM classifier achieved an accuracy of 78.8% against articles from Finance, but only 72.7% when predicting the sentiment of articles from M&amp;A.
    However, statistical testing showed that the results are not significantly different when training on one topic and testing on another.
    It is interesting to note, though, that providing a dataset of mixed topics (the sub-corpus MIX) does not necessarily reduce topic dependency.
    Indeed, the performance of the classifiers suffers a great deal when training on mixed data (confidence interval 95%).
    We conducted an experiment to compare the accuracy when training a classifier on one domain (newswire articles or movie reviews from the Polarity 1.0 dataset used by Pang et al. (2002)) and testing on the other doma