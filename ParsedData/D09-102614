cument under Labeled LDA is equal to the probability of the document under the Multinomial Naive Bayes event model trained on those same document instances.
    Unlike the Multinomial Naive Bayes classifier, Labeled LDA does not encode a decision boundary for unlabeled documents by comparing P(w(d)|ld) to P(w(d)|&#172;ld), although we discuss using Labeled LDA for multilabel classification in Section 7.
    Labeled LDA&#8217;s similarity to Naive Bayes ends with the introduction of a second label to any document.
    In a traditional one-versus-rest Multinomial Naive Bayes model, a separate classifier for each label would be trained on all documents with that label, so each word can contribute a count of 1 to every observed label&#8217;s word distribution.
    By contrast, Labeled LDA assumes that each document is a mixture of underlying topics, so the count mass of single word instance must instead be distributed over the document&#8217;s observed labels.
  
  
    Social bookmarking websites contain million