costly to obtain for building large-scale, broadcoverage language understanding systems.
    A more flexible direction is grounded language acquisition: learning the meaning of sentences in the context of an observed world state.
    The grounded approach has gained interest in various disciplines (Siskind, 1996; Yu and Ballard, 2004; Feldman and Narayanan, 2004; Gorniak and Roy, 2007).
    Some recent work in the NLP community has also moved in this direction by relaxing the amount of supervision to the setting where each sentence is paired with a small set of candidate meanings (Kate and Mooney, 2007; Chen and Mooney, 2008).
    The goal of this paper is to reduce the amount of supervision even further.
    We assume that we are given a world state represented by a set of records along with a text, an unsegmented sequence of words.
    For example, in the weather forecast domain (Section 2.2), the text is the weather report, and the records provide a structured representation of the temperature, sky conditi