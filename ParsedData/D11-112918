
    2) Retrieve the vector &#8594;&#8722;wl of each argument wl.
    3) Suppose w1 has weight c1i on basis vector &#8594;&#8722;n i, w2 has weight c2j on basis vector &#8594;&#8722;n j, &#183; &#183; &#183; , and wm has weight cm&#950; on basis vector &#8594;&#8722;n &#950;.
    Multiply these weights 4) Repeat the above steps for all the k &#8216;P&#8217;relations, and suma the corresponding weights aWe also experimented with multiplication, but the sparsity of noun vectors resulted in most verb matrices being empty.
    The weight cij corresponding to basis vector ten i&#174; te n j, is the extent according to which words that have co-occurred with ten i have been the subject of the &#8216;verb&#8217; and words that have co-occurred with ten j have been the object of the &#8216;verb&#8217;.
    This example computation is demonstrated in Figure 5.
    As an example, consider the verb &#8216;show&#8217; and suppose there are two &#8216;show&#8217;-relations in the corpus: s1 = table show result s2 = map sho