inference in Section 4.3.
    Finally, we report on the quality of a large database of Wordnet-based preferences obtained after manually associating our topics with Wordnet classes (Section 4.4).
    For all experiments we make use of a corpus of r(a1, a2) tuples, which was automatically extracted by TEXTRUNNER (Banko and Etzioni, 2008) from 500 million Web pages.
    To create a generalization corpus from this large dataset.
    We first selected 3,000 relations from the middle of the tail (we used the 2,0005,000 most frequent ones)3 and collected all instances.
    To reduce sparsity, we discarded all tuples containing an NP that occurred fewer than 50 times in the data.
    This resulted in a vocabulary of about 32,000 noun phrases, and a set of about 2.4 million tuples in our generalization corpus.
    We inferred topic-argument and relation-topic multinomials (Q, 'y, and 0) on the generalization corpus by taking 5 samples at a lag of 50 after a burn in of 750 iterations.
    Using multiple samples introd