ng supervised methods, even though the lack of gold-standard data makes this difficult.
    Girju et al. (2005) draw a training set from raw WSJ text and use it to train a decision tree classifier achieving 73.1% accuracy.
    When they shuffled their data with Lauer&#8217;s to create a new test and training split, their accuracy increased to 83.1% which may be a result of the 10% duplication in Lauer&#8217;s test set.
    We have created a new NP bracketing data set from our extended Treebank by extracting all rightmost three noun sequences from base-NPs.
    Our initial experiments are presented in Section 6.1.
  
  
    According to Marcus et al. (1993), asking annotators to markup base-NP structure significantly reduced annotation speed, and for this reason baseNPs were left flat.
    The bracketing guidelines (Bies et al., 1995) also mention the considerable difficulty of identifying the correct scope for nominal modifiers.
    We found however, that while there are certainly difficult cases, the vast ma