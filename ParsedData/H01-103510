re given in Yarowsky and Ngai (2001).
  
  The contribution of each candidate training sentence is weighted proportionally with both its EGYPT/GIZA sentence- level alignment score and an agreement measure between the pro- jected tags and the 1st iteration lexical priors, a rough measure of alignment reasonableness.
  Given the observed bursty distri- bution of alignment errors in the corpus, this downweighting of low-confidence alignment regions substantially improves sequence model quality with tolerable reduction in training volume.
  4.3 Evaluation of POS Tagger Induction As shown in Table 1, performance is evaluated on two evalua- tion data sets, including an independent 200K-word hand-tagged French dataset provided by Universite?
  de Montre?al, which is used to gauge stand-alone tagger performance.
  Signal amplification and noise reduction techniques yield a 71% error reduction, achieving a core tagset accuracy of 96%, closely approaching the upper-bound 97% performance of an equivalent bigram model tr