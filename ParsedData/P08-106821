 Table 4 are statistically significant.16 Table 5 compares accuracy results on the PDT 1.0 test set for our parsers and several other recent papers.
    As in our English experiments, we performed additional experiments on reduced sections of the PDT; the results are shown in Table 6.
    For simplicity, we did not retrain a tagger for each reduced dataset, so we always use the (automatically-assigned) part of speech tags provided in the corpus.
    Note that the cluster-based features obtain improvements at all training set sizes, with data-reduction factors similar to those observed in English.
    For example, the dep1c model trained on 4k sentences is roughly as good as the dep1 model trained on 8k sentences.
    Here, we present two additional results which further explore the behavior of the cluster-based feature sets.
    In Table 7, we show the development-set performance of second-order parsers as the threshold for lexical feature elimination (see Section 3.2) is varied.
    Note that the performance