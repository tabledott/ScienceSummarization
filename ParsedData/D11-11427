Markov Logic Network (Zhu et al., 2009) can lead to improved extraction.
    The WOE systems introduced by Wu and Weld make use of Wikipedia as a source of training data for their extractors, which leads to further improvements over TEXTRUNNER (Wu and Weld, 2010).
    Wu and Weld also show that dependency parse features result in a dramatic increase in precision and recall over shallow linguistic features, but at the cost of extraction speed.
    Other approaches to large-scale IE have included Preemptive IE (Shinyama and Sekine, 2006), OnDemand IE (Sekine, 2006), and weak supervision for IE (Mintz et al., 2009; Hoffmann et al., 2010).
    Preemptive IE and On-Demand IE avoid relationspecific extractors, but rely on document and entity clustering, which is too costly for Web-scale IE.
    Weakly supervised methods use an existing ontology to generate training data for learning relationspecific extractors.
    While this allows for learning relation-specific extractors at a larger scale than what was previousl