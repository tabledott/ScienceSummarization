
  Joint Learning Improves Semantic Role Labeling
  
    Despite much recent progress on accurate semantic role labeling, previous work has largely used independent classifiers, possibly combined with separate label sequence models via Viterbi decoding.
    This stands in stark contrast to the linguistic observation that a core argument frame is with strong dependencies between arguments.
    We show how to build a joint model of argument frames, incorporating novel features that model these interactions into discriminative loglinear models.
    This system achieves an reduction of all arguments core arguments over a stateof-the art independent classifier for goldstandard parse trees on PropBank.
  
  
    The release of semantically annotated corpora such as FrameNet (Baker et al., 1998) and PropBank (Palmer et al., 2003) has made it possible to develop high-accuracy statistical models for automated semantic role labeling (Gildea and Jurafsky, 2002; Pradhan et al., 2004; Xue and Palmer, 2004).
    Such syste