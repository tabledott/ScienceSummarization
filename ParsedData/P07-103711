titution and adjunction in LTAG or function application and combination in CCG).
    Akin to POS tagging, the process of supertagging an input utterance proceeds with statistics that are based on the probability of a word-supertag pair given their Markovian or local context (Bangalore &amp; Joshi, 1999; Clark &amp; Curran, 2004).
    This is the main difference with full parsing: supertagging the input utterance need not result in a fully connected graph.
    The LTAG-based supertagger of (Bangalore &amp; Joshi, 1999) is a standard HMM tagger and consists of a (second-order) Markov language model over supertags and a lexical model conditioning the probability of every word on its own supertag (just like standard HMM-based POS taggers).
    The CCG supertagger (Clark &amp; Curran, 2004) is based on log-linear probabilities that condition a supertag on features representing its context.
    The CCG supertagger does not constitute a language model nor are the Maximum Entropy estimates directly interpretable as s