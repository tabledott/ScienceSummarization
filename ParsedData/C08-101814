, 2005; Tsochantaridis et al, 2005).
			This training method allows the use of a configurable loss function, ?(y ? ,y), whichmeasures the extent to which the model?s predic tion, y, differs from the reference, y ? .
			Central.
			to training is the search for a derivation which is both high scoring and has high loss compared to the gold standard.
			5 This requires finding the maximiser of H(y) in one of: H s = (1?
			??(y ? )??(y), ??)?(y ? ,y) H m = ?(y ? ,y)?
			??(y ? )??(y), ??
			(3) where the subscripts s and m denote slack and margin rescaling, which are different formulations of the training problem (see Tsochantaridis et al (2005) and Taskar et al (2003) for details).
			The search for the maximiser of H(y) in (3) requires the tracking of the loss value.
			This can be achieved by extending the decoding algorithmsuch that the chart cells also store the loss param eters (e.g., for precision, the number of true and false positives (Joachims, 2005)).
			Consequently, this extension leads to a consider