f r &lt; 1, then y is underrepresented relative to xn, and we accept y with probability one.
    If r&gt; 1, then we accept y with a probability that diminishes as r increases: specifically, with probability 1/r.
    In brief, the acceptance probability of y is A(y I xn) = min(1, 1/r).
    It can be shown that proposing items with probability pH and accepting them with probability A( I xn) yields a sampler for q(.).
    (See, for example, Winkler [1995]).2 The acceptance probability A(y I xn) reduces in our case to a particularly simple form.
    If r &lt; 1 then A(y I x) = 1.
    Otherwise, writing 0(x) for the &amp;quot;field weight&amp;quot; ni 0{,(x), we have:
  
  
    In summary, we cannot simply transplant CF methods to the AV grammar case.
    In particular, the ERF method yields correct weights only for SCFGs, not for AV grammars.
    We can define a probabilistic version of AV grammars with a correct weight-selection method by going to random fields.
    Feature selection and weight adjustment can b