; &#22530;), or the institution sense (&#25945;&#20250;).
    In manual sense tagging done in SENSEVAL-2, it is possible to assign two sense tags to church in this case, but in the parallel text setting, a particular translator will translate it in one of the two ways (&#25945;&#22530; or &#25945; &#20250;), and hence the sense tag found by parallel text alignment is only one of the two sense tags.
    By manually examining a subset of about 1,000 examples, we estimate that the sense-tag error rate of training examples (tagged with lumped senses) obtained by our parallel text alignment approach is less than 1%, which compares favorably with the quality of manually sense tagged corpus prepared in SENSEVAL-2 (Kilgarriff, 2001).
    While it is encouraging to find out that the parallel text sense tags are of high quality, we are still left with the task of explaining the difference between M1 and P1 for the set of difficult nouns.
    Our further investigation reveals that the accuracy difference between M1 and 