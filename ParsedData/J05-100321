rwise.
    Thus we see that the logistic regression model implements a hyperplane classifier.
    In boosting, a different loss function is used, namely, ExpLoss(&#175;a), which is defined as This loss function is minimized using a feature selection method, which we describe in the next section.
    There are strong similarities between LogLoss (equation (4)) and ExpLoss (equation (6)).
    In making connections between the two functions, it is useful to consider a third function of the parameters and training examples, where gp&#196; is one if p is true, zero otherwise.
    Error(&#175;a) is the number of incorrectly classified training examples under parameter values &#175;a.
    Finally, it will be useful to define the margin on the ith training example, given parameter values &#175;a, as The three loss functions differ only in their choice of an underlying &#8220;potential function&#8221;of the margins, f(z).
    This function is f(z) = log (1 + e&#8212;z), f(z) = e&#8212;z, or f (z) = Qz &lt; 01 for LogL