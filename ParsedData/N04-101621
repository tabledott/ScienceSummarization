wi are members of these categories.
    The estimation ofprobabilities over concepts (rather than words) reduces the number of model parameters and effectively decreases the amount of training data required.
    The probability P(t1 -&gt; t2) denotes the modification of a category t2 by a category t1.
    Lauer (1995) tested both the adjacency and dependency models on 244 compounds extracted from Grolier&#8217;s encyclopedia, a corpus of 8 million words.
    Frequencies for the two models were obtained from the same corpus and from Roget&#8217;s thesaurus (version 1911) by counting pairs of nouns that are either strictly adjacent or co-occur within a window of a fixed size (e.g., two, three, fifty, or hundred words).
    The majority of the bracketings in our test set were left-branching, yielding a baseline of 63.93% (see Table 9).
    Lauer&#8217;s best results (77.50%) were obtained with the dependency model and a training scheme which takes strictly adjacent nouns into account.
    Performance increased f