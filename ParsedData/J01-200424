 search heuristics of this sort without DP.
    Our approach is found to yield very accurate parses efficiently, and, in addition, to lend itself straightforwardly to estimating word probabilities on-line, that is, in a single pass from left to right.
    This on-line characteristic allows our language model to be interpolated on a word-by-word basis with other models, such as the trigram, yielding further improvements.
    Next we will outline our conditional probability model over rules in the PCFG, followed by a presentation of the top-down parsing algorithm.
    We will then present empirical results in two domains: one to compare with previous work in the parsing literature, and the other to compare with previous work using parsing for language modeling for speech recognition, in particular with the Chelba and Jelinek results mentioned above.
    A simple PCFG conditions rule probabilities on the left-hand side of the rule.
    It has been shown repeatedly&#8212;e.g., Briscoe and Carroll (1993), Charniak