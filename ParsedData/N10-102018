cts that we found intuitive, while the other 2 are used only with low probability.
    Conversely, the Conversation model, whether trained by EM or Gibbs sampling, suffered from the inclusion of general terms and from the conflation of topic and dialogue.
    For example, the EMtrained conversation model discovered an &#8220;act&#8221; that was clearly a collection of posts about food, with no underlying dialogue theme (see Table 2).
    In the remainder of this section, we reproduce our visualization for the 10-act Conversation+Topic model.
    Word lists summarizing the discovered dialogue acts are shown in Table 3.
    For each act, the top 40 words are listed in order of decreasing emission probability.
    An example post, drawn from the set of highest-confidence posts for that act, is also included.
    Figure 4 provides a visualization of the matrix of transition probabilities between dialogue acts.
    An arrow is drawn from one act to the next if the probability of transition is above 0.15.7 Note tha