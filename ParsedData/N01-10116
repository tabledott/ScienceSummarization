one test should not always be preferred over the other.
    In light of this, (Pedersen, 1996) presents Fisher's exact test as an alternative since it does not rely on the distributional assumptions that underly both Pearson's test and the likelihood ratio.
    Unfortunately it is usually not clear which test is most appropriate for a particular sample of data.
    We take the following approach, based on the observation that all tests should assign approximately the same measure of statistical significance when the bigram counts in the contingency table do not violate any of the distributional assumptions that underly the goodness of fit statistics.
    We perform tests using X2, G2, and Fisher's exact test for each bigram.
    If the resulting measures of statistical significance differ, then the distribution of the bigram counts is causing at least one of the tests to become unreliable.
    When this occurs we rely upon the value from Fisher's exact test since it makes fewer assumptions about the underlyin