de a description of these features.
    Details can be found in Soon et al. (2001).
    Ng and Cardie expand Soon et al.&#8217;s feature set from 12 features to a deeper set of 53 to allow more complex NP string matching operations as well as finer-grained syntactic and semantic compatibility tests.
    See Ng and Cardie (2002b) for details.
    Learning algorithms.
    We consider three learning algorithms, namely, the C4.5 decision tree induction system (Quinlan, 1993), the RIPPER rule learning algorithm (Cohen, 1995), and maximum entropy classification (Berger et al., 1996).
    The classification model induced by each of these learners returns a number between 0 and 1 that indicates the likelihood that the two NPs under consideration are coreferent.
    In this work, NP pairs with class values above 0.5 are considered COREFERENT; otherwise the pair is considered NOT COREFERENT.
    Clustering algorithms.
    We employ three clustering algorithms, as described below.
    The closest-first clustering algori