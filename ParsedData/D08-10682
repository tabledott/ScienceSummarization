ming joint inference, which leverages the &#8220;easy&#8221; decisions to help make related &#8220;hard&#8221; ones.
    Relations that have been exploited in supervised coreference resolution include transitivity (McCallum &amp; Wellner, 2005) and anaphoricity (Denis &amp; Baldridge, 2007).
    However, there is little work to date on joint inference for unsupervised resolution.
    We address this problem using Markov logic, a powerful and flexible language that combines probabilistic graphical models and first-order logic (Richardson &amp; Domingos, 2006).
    Markov logic allows us to easily build models involving relations among mentions, like apposition and predicate nominals.
    By extending the state-of-the-art algorithms for inference and learning, we developed the first general-purpose unsupervised learning algorithm for Markov logic, and applied it to unsupervised coreference resolution.
    We test our approach on standard MUC and ACE datasets.
    Our basic model, trained on a minimum of data, s