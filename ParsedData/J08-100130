arge number of salience classes would unavoidably increase the number of features.
    Parameter estimation in such a space requires a large sample of training examples that is unavailable for most domains and applications.
    Different classes of models can be defined along the linguistic dimensions just discussed.
    Our experiments will consider several models with varying degrees of linguistic complexity, while attempting to strike a balance between expressivity of representation and ease of computation.
    In the following sections we evaluate their performance on three tasks: sentence ordering, summary coherence rating, and readability assessment.
    Equipped with the feature vector representation introduced herein, we can view coherence assessment as a machine learning problem.
    When considering text generation applications, it is desirable to rank rather than classify instances: There is often no single coherent rendering of a given text but many different possibilities that can be partially or