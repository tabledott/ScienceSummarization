ised training.
    We show that semi-supervised training leads to better word alignments than running unsupervised training followed by discriminative training.
    Another important difference with previous work is that we are concerned with generating many-to-many word alignments.
    Cherry and Lin (2003) and Taskar et al. (2005) compared their results with Model 4 using &#8220;intersection&#8221; by looking at AER (with the &#8220;Sure&#8221; versus &#8220;Possible&#8221; link distinction), and restricted themselves to considering 1-to-1 alignments.
    However, &#8220;union&#8221; and &#8220;refined&#8221; alignments, which are many-to-many, are what are used to build competitive phrasal SMT systems, because &#8220;intersection&#8221; performs poorly, despite having been shown to have the best AER scores for the French/English corpus we are using (Och and Ney, 2003).
    (Fraser and Marcu, 2006) recently found serious problems with AER both empirically and analytically, which explains why optimizing AER 