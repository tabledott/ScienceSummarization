ere (e.g., 17,232 rows and 8,000 columns; see Section 6.1).
    In step 4 of LRA, we simply select the top num patterns most frequent patterns and discard the remaining patterns.
    Perhaps a more sophisticated selection algorithm would improve the performance of LRA.
    We have tried a variety of ways of selecting patterns, but it seems that the method of selection has little impact on performance.
    We hypothesize that the distributed vector representation is not sensitive to the selection method, but it is possible that future work will find a method that yields significant improvement in performance.
  
  
    This article has introduced a new method for calculating relational similarity, Latent Relational Analysis.
    The experiments demonstrate that LRA performs better than the VSM approach, when evaluated with SAT word analogy questions and with the task of classifying noun-modifier expressions.
    The VSM approach represents the relation between a pair of words with a vector, in which the elemen