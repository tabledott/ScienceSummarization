for adjectives, and 0.73 for nouns, corresponding to &#954;w values of 0.41, 0.41, and 0.46, but with a wide variety of values when measured per word&#8212;ranging from 0.007 for the adjective correct to 0.92 for the noun d&#180;etention.
    Similarly mediocre results for intercoder agreement between naive coders were reported in the subsequent editions of SENSEVAL.
    Agreement studies for SENSEVAL-2, where WordNet senses were used as tags, reported a percentage agreement for verb senses of around 70%, whereas for SENSEVAL-3 (English Lexical Sample Task), Mihalcea, Chklovski, and Kilgarriff (2004) report a percentage agreement of 67.3% and average K of 0.58.
    Two types of solutions have been proposed for the problem of low agreement on sense tagging.
    The solution proposed by Kilgarriff (1999) is to use professional lexicographers and arbitration.
    The study carried out by Kilgarriff does not therefore qualify as a true study of replicability in the sense of the terms used by Krippendorff, but it 