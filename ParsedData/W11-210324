Cohen, 1960), which is defined as where P(A) is the proportion of times that the annotators agree, and P(E) is the proportion of time that they would agree by chance.
    Note that n is basically a normalized version of P(A), one which takes into account how meaningful it is for annotators to agree with each other, by incorporating P(E).
    Note also that n has a value of at most 1 (and could possibly be negative), with higher rates of agreement resulting in higher n. The above definition of n is actually used by several definitions of agreement measures, which differ in how P(A) and P(E) are computed.
    We calculate P(A) by examining all pairs of systems which had been judged by two or more judges, and calculating the proportion of time that they agreed that A &gt; B, A = B, or A &lt; B.
    In other words, P(A) is the empirical, observed rate at which annotators agree, in the context of pairwise comparisons.
    P(A) is computed similarly for intraannotator agreement (i.e. self-consistency), but over pai