word when making its final predictions.
    So, it's understandable that the algorithm is doing better on words that it's seen during training as opposed to unknown words.
    In our memory-based approach, feature weighting (rather than feature selection) for determining the relevance of features is integrated more smoothly with the similarity metric, and our results are based on experiments with a larger corpus (3 million cases).
    Our case representation is (at this point) simpler: only the (ambiguous) tags, not the words themselves or any other information are used.
    The most important improvement is the use of IGTree to index and search the case base, solving the computational complexity problems a case-based approach would run into when using large case bases.
    An approach based on k-nn methods (such as memory-based and case-based methods) is a statistical approach, but it uses a different kind of statistics than Markov model-based approaches.
    K-nn is a non-parametric technique; it assumes no