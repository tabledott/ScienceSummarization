the log-likelihood would rise by approximately 0.019059 bits; since this value was higher than for any other constraint considered, the constraint was selected.
    After applying iterative scaling to recompute the parameters of the new model, the likelihood of the empirical sample rose to &#8212;2.8525 bits, an increase of 0.0178 bits.
    Table 6 lists the first few selected features for the model for translating the English word run.
    The &amp;quot;Hansard flavor&amp;quot;&#8212;the rather specific domain of parliamentary discourse related to Canadian affairs&#8212;is easy to detect in many of the features in this table.
    It is not hard to incorporate the maximum entropy word translation models into a translation model p(FIE) for a French sentence given an English sentence.
    We merely replace the simple context-independent models p(ye) used in the basic translation model (33) with the more general context-dependent models pe(y1x): where xa, denotes the context of the English word eaj.
    Figure 6