ialized using the same jointly trained Model 1 parameters (5 iterations), then trained independently for 5 iterations.
    Both models were then combined with an independently trained HMM model in the opposite direction: f -* e.4 Table 1 summarizes the results; the two models perform similarly.
    The main benefit of our model is the effect on rule extraction, discussed below.
    We also compared our French results to the public baseline GIZA++ using the script published for the NAACL 2006 Machine Translation Workshop Shared Task.5 Similarly, we compared our Chinese results to the GIZA++ results in Ayan and Dorr (2006).
    Our models substantially outperform GIZA++, confirming results in Liang et al. (2006).
    Table 2 shows the effect on AER of competitive thresholding and different combination functions. method for the syntactic HMM model.
    The competitive thresholding heuristic (CT) is particularly helpful for the hard union combination method.
    The most dramatic effect of competitive thresholdin