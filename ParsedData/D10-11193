 and a universal set of combinatory rules that project that lexicon onto the sentences and meanings of the language via syntactic derivations.
    The learning process starts by postulating, for each sentence in the training data, a single multi-word lexical item pairing that sentence with its complete logical form.
    These entries are iteratively refined with a restricted higher-order unification procedure (Huet, 1975) that defines all possible ways to subdivide them, consistent with the requirement that each training sentence can still be parsed to yield its labeled meaning.
    For the data sets we consider, the space of possible grammars is too large to explicitly enumerate.
    The induced grammar is also typically highly ambiguous, producing a large number of possible analyses for each sentence.
    Our approach discriminates between analyses using a log-linear CCG parsing model, similar to those used in previous work (Clark &amp; Curran, 2003, 2007), but differing in that the syntactic parses are tre