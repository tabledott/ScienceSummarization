n likelihood P(Q, L) can be computed in closed form for any L. In particular, each formula group contributes a term equal to the weight of the currently satisfied formula.
    In addition, the optimal weights that maximize the completion likelihood P(Q, L) can be derived in closed form using empirical relative frequencies.
    E.g., the optimal weight of p E c n Form(p, f) is log(nc,f/nc), where nc,f is the number of parts p that satisfy both p E c and Form(p, f), and nc is the number of parts p that satisfy p E c.7 We leverage this fact for efficient learning in USP.
    6Regularizations, e.g., Gaussian priors on weights, alleviate this problem by penalizing large weights, but it remains true that weights within a short range are roughly equivalent. and update agenda and candidate operations until agenda is empty return the MLN with learned weights and the semantic parses Another major challenge in USP learning is the summation in the likelihood, which is over all possible semantic parses for a given depende