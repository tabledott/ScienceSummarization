
	Experiments with a Higher-Order Projective Dependency Parser
		We present experiments with a dependency parsing model defined on rich factors.
		Ourmodel represents dependency trees with factors that include three types of relations be tween the tokens of a dependency and theirchildren.
		We extend the projective pars ing algorithm of Eisner (1996) for our case,and train models using the averaged perceptron.
		Our experiments show that considering higher-order information yields signifi cant improvements in parsing accuracy, but comes at a high cost in terms of both timeand memory consumption.
		In the multi lingual exercise of the CoNLL-2007 shared task (Nivre et al, 2007), our system obtains the best accuracy for English, and the second best accuracies for Basque and Czech.
	
	
			Structured prediction problems usually involve models that work with factored representations of structures.
			The information included in the factors determines the type of features that the model can exploit.
			However, rich