t.
    Note that the templates of Ng and Low (2004) have already contained some lexical-target ones.
    With the two kinds of predications, the perceptron model will do exact predicating to the best of its ability, and can back off to approximately predicating if exact predicating fails.
    We adopt the perceptron training algorithm of Collins (2002) to learn a discriminative model mapping from inputs x &#8712; X to outputs y &#8712; Y , where X is the set of sentences in the training corpus and Y is the set of corresponding labelled results.
    Following Collins, we use a function GEN(x) generating all candidate results of an input x , a representation 4) mapping each training example (x, y) &#8712; X &#215; Y to a feature vector 4)(x, y) &#8712; Rd, and a parameter vector &#945;&#65533; &#8712; Rd corresponding to the feature vector. d means the dimension of the vector space, it equals to the amount of features in the model.
    For an input character sequence x, we aim to find an output F(x) satisfying: