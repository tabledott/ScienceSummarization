03).
    Conference papers routinely claim improvements in translation quality by reporting improved Bleu scores, while neglecting to show any actual example translations.
    Workshops commonly compare systems using Bleu scores, often without confirming these rankings through manual evaluation.
    All these uses of Bleu are predicated on the assumption that it correlates with human judgments of translation quality, which has been shown to hold in many cases (Doddington, 2002; Coughlin, 2003).
    However, there is a question as to whether minimizing the error rate with respect to Bleu does indeed guarantee genuine translation improvements.
    If Bleu&#8217;s correlation with human judgments has been overestimated, then the field needs to ask itself whether it should continue to be driven by Bleu to the extent that it currently is.
    In this paper we give a number of counterexamples for Bleu&#8217;s correlation with human judgments.
    We show that under some circumstances an improvement in Bleu is not s