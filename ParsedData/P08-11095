rsing model is based on a conditional random field model, however, unlike previous TreeCRF work, e.g., (Cohn and Blunsom, 2005; Jousse et al., 2006), we do not assume a particular tree structure, and instead find the most likely structure and labeling.
    This is similar to conventional probabilistic context-free grammar (PCFG) parsing, with two exceptions: (a) we maximize conditional likelihood of the parse tree, given the sentence, not joint likelihood of the tree and sentence; and (b) probabilities are normalized globally instead of locally &#8211; the graphical models depiction of our trees is undirected.
    Formally, we have a CFG G, which consists of (Manning and Sch&#168;utze, 1999): (i) a set of terminals {wk},k = 1,...,V; (ii) a set of nonterminals {Nk},k = 1,...,n; (iii) a designated start symbol ROOT; and (iv) a set of rules, {&#961; = Ni &#8212;* &#950; j}, where &#950; j is a sequence of terminals and nonterminals.
    A PCFG additionally assigns probabilities to each rule &#961; such that Vi&#