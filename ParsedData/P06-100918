ls which were trained on only the first four letters of each word obtained superior results to those using the full words (Martin et al., 2005).
    We observed the same result with our model on the trial set and thus have only used the first four letters when training the Dice and Model 1 translation probabilities.
    Tables 1 and 2 show the results when all feature types are employed on both language pairs.
    We report the results for both translation directions and when combined using the refined and intersection methods.
    The Model 4 results are from GIZA++ with the default parameters and the training data lowercased.
    For Romanian, Model 4 was trained using the first four letters of each word.
    The Romanian results are close to the best reported result of 26.10 from the ACL shared task (Martin et al., 2005).
    This result was from a system based on Model 4 plus additional parameters such as a dictionary.
    The standard Model 4 implementation in the shared task achieved a result of 31.65, 