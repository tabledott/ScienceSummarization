n figure 3.
    Note, however, that all parameter vectors for are stored.
    Thus the training phase can be thought of as a way of constructing different parameter settings.
    Each of these parameter settings will have its own highest ranking candidate, where .
    The idea behind the voted perceptron is to take each of the parameter settings to &#8220;vote&#8221; for a candidate, and the candidate which gets the most votes is returned as the most likely candidate.
    See figure 4 for the algorithm.5
  
  
    We applied the voted perceptron and boosting algorithms to the data described in section 2.3.
    Only features occurring on 5 or more distinct training sentences were included in the model.
    This resulted precision, recall, F-measure.
    Figures in parantheses are relative improvements in error rate over the maximum-entropy model.
    All figures are percentages. in 93,777 distinct features.
    The two methods were trained on the training portion (41,992 sentences) of the training set.
    We 