as sifier, and got a Precision/Recall of 59.1% ? about 8 points higher than the baseline.
			Since the coarse and fine-grained disambiguation tasks have been part ofthe two previous Senseval competitions, and we happen to have access to that data, we can take this op portunity to look at the disambiguation performancetrend.
			Although different test sets were used for ev ery evaluation, we can get a rough indication of the trend.
			For the fine-grained All Words sense tagging task, which has always used WordNet, the systemperformance has ranged from our 59% to 65.2 (Sen seval3, (Decadt et al, 2004)) to 69% (Seneval2, (Chklovski and Mihalcea, 2002)).
			Because of time constraints on the data preparation, this year?s task has proportionally more verbs and fewer nouns thanprevious All-Words English tasks, which may ac count for the lower scores.
			As expected, the Lexical Sample task using coarse 88 Rank Participant System ID Classifier F 1 Stephen Tratz &lt;stephen.tratz@pnl.gov&gt; PNNL MaxEnt 59.1?4.5.
		