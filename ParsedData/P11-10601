oney, 2001; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010) rely on manual annotation of logical forms, which is expensive.
    On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives.
    As in Clarke et al. (2010), we obviate the need for annotated logical forms by considering the endto-end problem of mapping questions to answers.
    However, we still model the logical form (now as a latent variable) to capture the complexities of language.
    Figure 1 shows our probabilistic model: with respect to a world w (database of facts), producing an answer y.
    We represent logical forms z as labeled trees, induced automatically from (x, y) pairs.
    We want to induce latent logical forms z (and parameters 0) given only question-answer pairs (x, y), which is much cheaper to obtain than 