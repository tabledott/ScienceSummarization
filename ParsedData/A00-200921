ndant errors made by classifiers that represent very similarly sized windows of context.
    The ultimate success of an ensemble depends on the ability to select classifiers that make complementary errors.
    This is discussed in the context of combining part&#8212;of&#8212;speech taggers in (Brill and Wu, 1998).
    They provide a measure for assessing the complementarity of errors between two taggers that could be adapted for use with larger ensembles such as the one discussed here, which has nine members.
    In this paper ensemble disambiguation is based on a simple majority vote of the nine member classifiers.
    An alternative strategy is to weight each vote by the estimated joint probability found by the Naive Bayesian classifier.
    However, a preliminary study found that the accuracy of a Naive Bayesian ensemble using a weighted vote was poor.
    For interest, it resulted in accuracy of 83% while for line it was 82%.
    The simple majority vote resulted in accuracy of 89% for interest and 88% fo