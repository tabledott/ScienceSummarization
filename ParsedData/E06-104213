arget set sentences into literal and nonliteral by attracting them to the corresponding feature sets using Algorithms 1 &amp; 2.
    Using the basic KE algorithm, target sentence 2 is correctly attracted to the nonliteral set, and sentences 1 and 3 are equally attracted to both sets.
    When we apply our sum of similarities enhancement, sentence 1 is correctly attracted to the literal set, but sentence 3 is now incorrectly attracted to the literal set too.
    In the following sections we describe some enhancements &#8211; Learners &amp; Voting, SuperTags, and Context &#8211; that try to solve the problem of incorrect attractions.
    In this section we describe how we clean up the feedback sets to improve the performance of the Core algorithm.
    We also introduce the notion of Learners &amp; Voting.
    Recall that neither the raw data nor the collected feedback sets are manually annotated for training purposes.
    Since, in addition, the feedback sets are collected automatically, they are very noisy.
  