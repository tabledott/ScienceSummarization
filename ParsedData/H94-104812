re inconsistent or redundant with those word or class questions in fi.
  The newly created features are then added to P,  and compete for selection in the next Delta-Likelihood ranking process.
  This method allows the introduction of complex features on word classes while keeping the search space manageable; "P grows linearly with .M.
  Resu l ts We applied the Maximum Entropy model to sentences from two corpora, the I.B.M.
  Computer Manuals Data, annotated by Univ.
  of Lancaster, and the Wall St. Journal Data, annotated by Univ.
  The size of the training sets, test sets, and the results are shown in Tables 1 &amp; 2.
  The experiments in Table 2 differ in the following manner: "Words Only" The search space P begins with all possible n-gram word features with n being 1, 2, 3,or 4; this feature set does not grow during the feature search.
  "Classes Only" The search space P begins with only un- igram class features, and grows by dynamically contructing class n-gram questions as described earlier.
  "Word a