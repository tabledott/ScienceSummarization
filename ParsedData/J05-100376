lection: McCallum uses a two-norm regularizer; Riezler and Vasserman use a one-norm regularizer.
    Finally, note that other feature selection methods have been proposed within the machine-learning community: for example, &#8220;filter&#8221;methods, in which feature selection is performed as a preprocessing step before applying a learning method, and backward selection methods (Koller and Sahami 1996), in which initially all features are added to the model and features are then incrementally removed from the model.
    6.5 Boosting, Perceptron, and Support Vector Machine Approaches for Ranking Problems Freund et al. (1998) introduced a formulation of boosting for ranking problems.
    The problem we have considered is a special case of the problem in Freund et al. (1998), in that we have considered a binary distinction between candidates (i.e., the best parse vs. other parses), whereas Freund et al. consider learning full or partial orderings over candidates.
    The improved algorithm that we introduced in