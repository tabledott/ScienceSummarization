r a judge to know the source of a label nor the system's ranking of the labels.
    For each name, we asked the judges to assign a score of correct, partially correct, or incorrect.
    We then computed the mean reciprocal rank (MRR) of the system, human, and WordNet labels.
    For each concept, a naming scheme receives a score of 1 / M where M is the rank of the first name judged correct.
    Table 2 shows the results.
    Table 3 shows similar results for a more lenient evaluation where M is the rank of the first name judged correct or partially correct.
    Our system achieved an overall MRR score of 77.1%.
    We performed much better than the baseline WordNet (19.9%) because of the lack of coverage (mostly proper nouns) in the hierarchy.
    For the 33 concepts that WordNet named, it achieved a score of 75.3% and a lenient score of 82.7%, which is high considering the simple algorithm we used to extract labels using WordNet.
    The Kappa statistic (Siegel and Castellan Jr. 1988) measures the agreements