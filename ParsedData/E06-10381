relevant information retained as well as their compression rate.
    Thus, returning highly compressed, yet informative, sentences allows summarization systems to return larger sets of sentences and increase the overall amount of information extracted.
    We focus on the particular instantiation of sentence compression when the goal is to produce the compressed version solely by removing words or phrases from the original, which is the most common setting in the literature (Knight and Marcu, 2000; Riezler et al., 2003; Turner and Charniak, 2005).
    In this framework, the goal is to find the shortest substring of the original sentence that conveys the most important aspects of the meaning.
    We will work in a supervised learning setting and assume as input a training set T=(xt,yt)|?
    | t&#65533;1 of original sentences xt and their compressions yt.
    We use the Ziff-Davis corpus, which is a set of 1087 pairs of sentence/compression pairs.
    Furthermore, we use the same 32 testing examples from Knigh