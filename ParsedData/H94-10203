st in clear cases, how subconstituents are semantically related to their predicates.
  Such a representation could serve as both a starting point for the kinds of SEMEVAL representations now being discussed as a basis for evaluation of human lan- guage technology within the ARPA HLT program, and as a basis for "glass box" evaluation of parsing technology.
  The ongoing effort [1] to develop a standard objective methodology to compare parser outputs across widely diver- gent grammatical frameworks has now resulted in a widely supported standard for parser comparison.
  On the other hand, many existing parsers cannot be evaluated by this metric because they directly produce a level of representa- tion closer to predicate-argument structure than to classical surface grammatical nalysis.
  Hand-in-hand with this limi- tation of the existing Penn Treebank for parser testing is a parallel imitation for automatic methods for parser training for parsers based on deeper epresentations.
  There is also a problem of mai