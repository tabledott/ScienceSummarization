t systems on a common translation task, and can be applied on a frequent and ongoing basis during MT system development.
    The most commonly used MT evaluation metric in recent years has been IBM&#8217;s BLEU metric (Papineni et al., 2002).
    BLEU is fast and easy to run, and it can be used as a target function in parameter optimization training procedures that are commonly used in state-of-the-art statistical MT systems (Och, 2003).
    Various researchers have noted, however, various weaknesses in the metric.
    Most notably, BLEU does not produce very reliable sentence-level scores.
    METEOR , as well as several other proposed metrics such as GTM (Melamed et al., 2003), TER (Snover et al., 2006) and CDER (Leusch et al., 2006) aim to address some of these weaknesses.
    METEOR , initially proposed and released in 2004 (Lavie et al., 2004) was explicitly designed to improve correlation with human judgments of MT quality at the segment level.
    Previous publications on METEOR (Lavie et al., 2004; Ba