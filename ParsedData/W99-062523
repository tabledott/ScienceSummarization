orrect answers over both categories of similar and non-similar pairs) is considered, the numbers are much closer together: 98.8% for our approach; 96.6% and 97.8% for TF*IDF on the two P-R points mentioned for that method 96.5% and for SMART, again at the two P-R points mentioned for SMART and 97.5% for the default Nevertheless, since the challenge of identifying sparsely occurring similar small text units is our goal, the accuracy measure and the baseline technique of classifying everything as not similar are included only for reference but do tests of significance cannot be performed for cmnparing these values, since paragraphs appear in multiple comparisons and consequently the comparisons are not independent.
    Figure 5: Precision-recall graph comparing our using line with squares) versus TF*IDF (dotted line with triangles). not reflect our task.
    6 Analysis and Discussion of Feature Performance We computed statistics on how much each feature helps in identifying similarity, summarized in Table 2.
  