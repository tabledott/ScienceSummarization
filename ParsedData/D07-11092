mesthat permeate the collection.
			Topic models have re cently been applied to information retrieval (Wei and Croft, 2006), text classification (Blei et al, 2003), and dialogue segmentation (Purver et al, 2006).
			While topic models capture the polysemous use of words, they do not carry the explicit notion of sense that is necessary for WSD.
			LDAWN extends the topic modeling framework to include a hidden meaning in the word generation process.
			In this case, posterior inference discovers both the topics of the corpus and the meanings assigned to each of its words.
			After introducing a disambiguation scheme basedon probabilistic walks over the WORDNET hierar chy (Section 2), we embed the WORDNET-WALK in a topic model, where each topic is associated withwalks that prefer different neighborhoods of WORDNET (Section 2.1).
			Then, we describe a Gibbs sam pling algorithm for approximate posterior inference that learns the senses and topics that best explain a corpus (Section 3).
			Finally, we evaluate our