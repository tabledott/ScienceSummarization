 The results show that the naive Bayes models and SVM perform surprisingly well on both the Editors and Guests subsets of the bitterlemons corpus.
    The naive Bayes models perform slightly better than SVM, possibly because generative models (i.e., naive Bayes models) achieve optimal performance with a smaller number of training examples than discriminative models (i.e., SVM) (Ng and Jordan, 2002), and the size of the bitterlemons corpus is indeed small.
    NB-B, which performs full Bayesian inference, improves on NB-M, which only performs point estimation.
    The results suggest that the choice of words made by the authors, either consciously or subconsciously, reflects much of their political perspectives.
    Statistical models can capture word usage well and can identify the perspective of documents with high accuracy.
    Given the performance gap between Editors and Guests, one may argue that there exist distinct editing artifacts or writing styles of the editors and guests, and that the statistical 