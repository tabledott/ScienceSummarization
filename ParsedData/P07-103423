  In particular, we set At,,, = as such that the total contribution of the added target instances is equal to that of all the labeled source instances.
    We call this second method the balanced bootstrapping method.
    Table 3 shows the results.
    As we can see, while bootstrapping can generally improve the performance over the baseline where no unlabeled data is used, the balanced bootstrapping method performed slightly better than the standard bootstrapping method.
    This again shows that weighting the target instances more is a right direction to go for domain adaptation.
  
  
    There have been several studies in NLP that address domain adaptation, and most of them need labeled data from both the source domain and the target domain.
    Here we highlight a few representative ones.
    For generative syntactic parsing, Roark and Bacchiani (2003) have used the source domain data to construct a Dirichlet prior for MAP estimation of the PCFG for the target domain.
    Chelba and Acero (2004) use the 