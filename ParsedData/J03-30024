ed by fees or licensing restrictions.
    For all these reasons, it is difficult to follow the &#8220;more data are better data&#8221; advice of Church and Mercer (1993), abandoning balance in favor of volume, with respect to parallel text.
    Then there is the World Wide Web.
    People tend to see the Web as a reflection of their own way of viewing the world&#8212;as a huge semantic network, or an enormous historical archive, or a grand social experiment.
    We are no different: As computational linguists working on multilingual issues, we view the Web as a great big body of text waiting to be mined, a huge fabric of linguistic data often interwoven with parallel threads.
    This article describes our techniques for mining the Web in order to extract the parallel text it contains.
    It presents, in revised and considerably extended form, our early work on mining the Web for bilingual text (STRAND) (Resnik 1998, 1999), incorporating new work on content-based detection of translations (Smith 2001, 2002),