tion.
    The final column shows the target category; the disambiguated tag for the focus word.
    We will refer to this case representation as ddf at (d for disambiguated, f for focus, a for ambiguous, and t for target).
    The information gain values are given as well.
    A search among a selection of different context sizes suggested ddf at as a suitable case representation for tagging known words.
    An interesting property of memory-based learning is that case representations can be easily extended with different sources of information if available (e.g. feedback from a parser in which the tagger operates, semantic types, the words themselves, lexical representations of words obtained from a different source than the corpus, etc.).
    The information gain feature relevance ordering technique achieves a delicate relevance weighting of different information sources when they are fused in a single case representation.
    The window size used by the algorithm will also dynamically change depending on t