 reliability measure indicates how reproducible a data set is by quantifying similarity across subjects in terms of the proportion of times that each response category occurs.
    This differs from a significance test of the null hypothesis (e.g., our use of Cochran's Q), where observed data is compared to random distribution.
    We use Krippendorff's a (1980) to evaluate the reliability of the two data sets from partitions A and B.
    The general formula for a is 1 &#8212; , where Do and DE are observed disagreements and expected disagreements.
    Computation of a is described below.
    Krippendorff's a reports to what degree the observed number of matches could be expected to arise by chance.
    Again in contrast with Cochran's Q, it is simply a ratio rather than a point on a distribution curve with known probabilities.
    Values range from 1 to &#8212;1, with 0 representing that there are no more agreements observed in the data than would happen by chance.
    A value of .5 would indicate that the ob