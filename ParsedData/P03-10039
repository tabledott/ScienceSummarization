onstructed so as to be consistent with our intuition that a generative process that makes the question and answer as similar-looking as possible is most likely to enable us learn a useful model.
    Each questionanswer pair results in one training example.
    It is the examples generated through this procedure that we use to estimate the parameters of our model.
    SNT the faithful return b y the hundreds each year to mark the anniversary Assume now that the sentence in Figure 1 is returned by an IR engine as a potential candidate for finding the answer to the question &#8220;When did Elvis Presley die?&#8221; In this case, we don&#8217;t know what the answer is, so we assume that any semantic/syntactic node in the answer sentence can be the answer, with the exception of the nodes that subsume question terms and stop words.
    In this case, given a question and a potential answer sentence, we generate an exhaustive set of question-answer test cases, each test case labeling as answer (A_) a different syntac