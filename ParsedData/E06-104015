
    Scores are averaged over the 18 forecasts that were used in the expert experiments (for which we had scores by all metrics and humans) in order to make results as directly comparable as possible.
    Human scores are normalised to range 0 to 1.
    Systems are ranked in order of the scores given to them by experts.
    All ranks are shown in brackets behind the absolute scores.
    Both experts and non-experts score SUMTIMEHybrid the highest, and pCRU-2gram and pCRUrandom the lowest.
    The experts have pCRUgreedy in second place, where the non-experts have pCRU-roulette.
    The experts rank the corpus forecasts fourth, the non-experts second.
    We used approximate randomisation (AR) as our significance test, as recommended by Riezler and Maxwell III (2005).
    Pair-wise tests between results in Table 2 showed all but three differences to be significant with the likelihood of incorrectly rejecting the null hypothesis p &lt; 0.05 (the standard threshold in NLP).
    The exceptions were the difference