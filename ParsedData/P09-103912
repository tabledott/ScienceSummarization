s and grandparents, modeling valency, or preferring nearly projective parses).
    While, as pointed out by McDonald and Satta (2007), the inclusion of these features makes inference NPhard, by relaxing the integer constraints we obtain approximate algorithms that are very efficient and competitive with state-of-the-art methods.
    In this paper, we focus on unlabeled dependency parsing, for clarity of exposition.
    If it is extended to labeled parsing (a straightforward extension), our formulation fully subsumes that of Riedel and Clarke (2006), since it allows using the same hard constraints and features while keeping the ILP polynomial in size.
    We start by describing our constraint space.
    Our formulations rely on a concise polyhedral representation of the set of candidate dependency parse trees, as sketched in &#167;2.1.
    This will be accomplished by drawing an analogy with a network flow problem.
    Let D = (V, A) be the complete directed graph S+(v) , {hi, ji &#8712; A  |i = v} denote its 