g stage and the testing stage, and two separate results are presented: testing with constraints (denoted I for inference) and without constraints (no I).
    The I results are consistently better.
    And, it is also clear from Table 2, that using constraints in training always improves the model and the amount of improvement depends on the amount of labeled data.
    Figure 3 compares two protocols on the advertisements domain: H&amp;W+I, where we first run the H&amp;W protocol and then apply the constraints during testing stage, and H&amp;W&amp;C+I, which uses constraints to guide the model during learning and uses it also in testing.
    Although injecting constraints in the learning process helps, testing with constraints is more important than using constraints during learning, especially when the labeled data size is large.
    This confirms results reported for the supervised learning case in (Punyakanok et al., 2005; Roth and Yih, 2005).
    However, as shown, our proposed algorithm H&amp;W&amp;C for 