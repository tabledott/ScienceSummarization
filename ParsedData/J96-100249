lasses of these words as derived from a mutual-information clustering scheme described in Brown et al. (1990).
    The complete (x, y) pair is illustrated in Figure 9.
    In creating p(riftlx), we are (at least in principle) modeling the decisions of an expert French segmenter.
    We have a sample of his work in the training sample j3(x, y), and we measure the worth of a model by the log-likelihood Li3(p).
    During the iterative model-growing procedure, the algorithm selects constraints on the basis of how much they increase this objective function.
    As the algorithm proceeds, more and more constraints are imposed on the model p, bringing it into ever-stricter compliance with the empirical data p&amp;quot; (x,y).
    This is useful to a point; insofar as the empirical data embodies the expert knowledge of the French segmenter, we would like to incorporate this knowledge into a model.
    But the data contains only so much expert knowledge; the algorithm should terminate when it has extracted this knowl