 PLTM is appropriate for aligning topics in corpora that have only a small subset of comparable documents.
    One area for future work is to explore whether initialization techniques or better representations of topic co-occurrence might result in alignment of topics with a smaller proportion of comparable texts.
    Although the PLTM is clearly not a substitute for a machine translation system&#8212;it has no way to represent syntax or even multi-word phrases&#8212;it is clear from the examples in figure 2 that the sets of high probability words in different languages for a given topic are likely to include translations.
    We therefore evaluate the ability of the PLTM to generate bilingual lexica, similar to other work in unsupervised translation modeling (Haghighi et al., 2008).
    In the early statistical translation model work at IBM, these representations were called &#8220;cepts,&#8221; short for concepts (Brown et al., 1993).
    We evaluate sets of high-probability words in each topic and multilin