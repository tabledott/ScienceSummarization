erage precision/recall for sentences of length &lt; 40, and 89.5% for sentences of length &lt; 100, when trained and tested on the previously established [5,9,10,15,17] &amp;quot;standard&amp;quot; sections of the Wall Street Journal tree-bank.
    This represents a 13% decrease in error rate over the best single-parser results on this corpus [9].
    Following [5,10], our parser is based upon a probabilistic generative model.
    That is, for all sentences s and all parses 7r, the parser assigns a probability p(s , 7r) = p(r), the equality holding when we restrict consideration to 7r whose yield * This research was supported in part by NSF grant LIS SBR 9720368.
    The author would like to thank Mark Johnson and all the rest of the Brown Laboratory for Linguistic Information Processing. is s. Then for any s the parser returns the parse ir that maximizes this probability.
    That is, the parser implements the function arg maxrp(7r s) = arg maxirp(7r, s) = arg maxrp(w).
    What fundamentally distinguishes p