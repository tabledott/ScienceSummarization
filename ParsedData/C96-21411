approach, we use a first-order Hidden Markov model (HMM) (aelinek, 1976), which is similar, but not identical to those used in speech recognition.
			The key component of this approach is to make the alignment probabilities dependent not on the absolute position of the word align- ment, but on its relative position; i.e. we consider the differences in the index of the word positions rather than the index itself.
			The organization of the paper is as follows.
			After reviewing the statistical approach to ma- chine translation, we first describe the convention- al model (mixture model).
			We then present our first-order HMM approach in lull detail.
			Finally we present some experimental results and compare our model with the conventional model.
	
	
			The goal is the translation of a text given in some language F into a target language E. For conve- nience, we choose for the following exposition as language pair French and English, i.e. we are giv- en a French string f~ = fx ...fj...fJ, which is to be trans