, which minimizes an empirical loss of the predictor (with regularization) on thentraining examples{(Xi;Yi)}: L(f(Xi);Yi)+r(f)): L(.) is a loss function to quantify the difference between the prediction f (Xi) and the true output Yi, andr(.
    )is a regularization term to control the model complexity.
    ERM-based methods for discriminative learning are known to be effective for NLP tasks such as chunking (e.g.
    Kudoh and Matsumoto (2001), Zhang and Johnson (2003)).
    We present a linear prediction model for structural learning, which extends the traditional model to multiple problems.
    Specifically, we assume that there exists a low-dimensional predictive structure shared by multiple prediction problems.
    We seek to discover this structure through joint empirical risk minimization over the multiple problems.
    Consider m problems indexed by ` E { 1 each with nt samples (Xti; Yt) indexed by i E {1; ::: ; nt}.
    In our joint linear model, a predictor for problem ` takes the following form wher