on containing entries for 49,206 word types).
    The InitEM-HMM system from Goldberg et al. (2008) reports an accuracy of 93.8%, followed by the LDA+AC model (Latent Dirichlet Allocation model with a strong Ambiguity Class component) from Toutanova and Johnson (2008).
    In comparison, the Bayesian HMM (BHMM) model from Goldwater et al. (2007) and the CE+spl model (Contrastive Estimation with a spelling model) from Smith and Eisner (2005) report lower accuracies (87.3% and 88.7%, respectively).
    Our system (IP+EM) which uses integer programming and EM, gets the highest accuracy (96.8%).
    The accuracy numbers reported for Init-HMM and LDA+AC are for models that are trained on all the available unlabeled data from the Penn Treebank.
    The IP+EM models used in the 17-tagset experiments reported here were not trained on the entire Penn Treebank, but instead used a smaller section containing 77,963 tokens for estimating model parameters.
    We also include the accuracies for our IP+EM model when using o