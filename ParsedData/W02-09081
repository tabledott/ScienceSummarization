, 2001) and text classification (Baker and McCallum, 1998).
    Unfortunately, thesauri are expensive and timeconsuming to create manually, and tend to suffer from problems of bias, inconsistency, and limited coverage.
    In addition, thesaurus compilers cannot keep up with constantly evolving language use and cannot afford to build new thesauri for the many subdomains that NLP techniques are being applied to.
    There is a clear need for methods to extract thesauri automatically or tools that assist in the manual creation and updating of these semantic resources.
    Much of the existing work on thesaurus extraction and word clustering is based on the observation that related terms will appear in similar contexts.
    These systems differ primarily in their definition of &#8220;context&#8221; and the way they calculate similarity from the contexts each term appears in.
    Most systems extract co-occurrence and syntactic information from the words surrounding the target term, which is then converted into a