ory representation.
    Thus this model is making no a priori hard independence assumptions, just a priori soft biases.
    As mentioned above, top also includes top itself, which means that the inputs to always include the history representation for the most recent derivation step assigned to top .
    This input imposes an appropriate bias because the induced history features which are relevant to previous derivation decisions involving top are likely to be relevant to the decision at step as well.
    As a simple example, in figure 1, the prediction of the left corner terminal of the VP node (step 4) and the decision that the S node is the root of the whole sentence (step 9) are both dependent on the fact that the node on the top of the stack in each case has the label S (chosen in step 3).
    The pre-defined features of the derivation history which are input to for node top at step are chosen to reflect the information which is directly relevant to choosing the next decision .
    In the parser presented