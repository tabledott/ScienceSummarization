e that the FH and FC bounds allow overlap between some HFWs and CWs.
			See (Davidov and Rappoport, 2008) for a short discussion.
			3As with word and n-gram features, the maximal featureweight of a pattern p is defined as the inverse count of a pat tern in the complete Twitter corpus.
			243 Davidov et al, 2010).
			3.1.3 Efficiency of feature selection Since we avoid selection of textual features which have a training set frequency below 0.5%, we perform feature selection incrementally, on each stage using the frequencies of the features obtained during the previous stages.
			Thus first we estimate the frequencies of single words in the training set, then we only consider creationof n-grams from single words with sufficient frequency, finally we only consider patterns composed from sufficiently frequent words and n grams.
			3.1.4 Punctuation-based features In addition to pattern-based features we used the following generic features: (1) Sentence length in words, (2) Number of ?!?
			characters in the sent