 though its recall is 3% lower on Hu?s data sets.
			We show that 1/3 of this increase in precision comes from using OPINE?s feature assessment mechanism on review data while the rest is due to Web PMI statistics.
			3.
			While many other systems have used extracted opin-.
			ion phrases in order to determine the polarity of sentences or documents, OPINE is the first to report its precision andrecall on the tasks of opinion phrase extraction and opin ion phrase polarity determination in the context of known product features and sentences.
			On the first task, OPINEhas a precision of 79% and a recall of 76%.
			On the sec ond task, OPINE has a precision of 86% and a recall of 89%.
			339 Input: product class C, reviews R. Output: set of [feature, ranked opinion list] tuples R??
			parseReviews(R); E?
			findExplicitFeatures(R?, C); O?
			findOpinions(R?, E); CO? clusterOpinions(O); I?
			findImplicitFeatures(CO, E); RO?
			rankOpinions(CO); {(f , oi, ...oj)...}?outputTuples(RO, I ? E); Figure 1: OPINE Overvi