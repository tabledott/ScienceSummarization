ce are the use of a more sophisticated statistical classifier and more training material.
    We have experimented with a maximum entropy model, Repeated Incremental Pruning to Produce Error Reduction (RIPPER), and decision trees; preliminary results do not show significant improvement over the naive Bayesian model.
    One problem is that 4% of the sentences in our current annotated material are ambiguous: They receive the same feature representation but are classified differently by the annotators.
    A possible solution is to find better and more distinctive features; we believe that robust, higher-level features like actions and agents are a step in the right direction.
    We also suspect that a big improvement could be achieved with smaller annotation units.
    Many errors come from instances in which one half of a sentence serves one rhetorical purpose, the other another, as in the following example: The current paper shows how to implement this general notion, without following Krifka&#8217;s analys