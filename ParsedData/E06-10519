pport Vector Machines (Vapnik, 1998).
    In order to implement the approach based on shallow linguistic information we employed a linear combination of kernels.
    Different works (Gliozzo et al., 2005; Zhao and Grishman, 2005; Culotta and Sorensen, 2004) empirically demonstrate the effectiveness of combining kernels in this way, showing that the combined kernel always improves the performance of the individual ones.
    In addition, this formulation allows us to evaluate the individual contribution of each information source.
    We designed two families of kernels: Global Context kernels and Local Context kernels, in which each single kernel is explicitly calculated as follows where 0(&#183;) is the embedding vector and II &#183; II is the 2-norm.
    The kernel is normalized (divided) by the product of the norms of embedding vectors.
    The normalization factor plays an important role in allowing us to integrate information from heterogeneous feature spaces.
    Even though the resulting feature space h