proposed by Zhao and Grishman (2005).
    They use composite kernels to integrate information from different syntactic sources (tokenization, sentence parsing, and deep dependency analysis) so that processing errors occurring at one level may be overcome by information from other levels.
    Bunescu and Mooney (2005a) present an alternative approach which uses information concentrated in the shortest path in the dependency tree between the two entities.
    As mentioned in Section 1, another relevant approach is presented in (Roth and Yih, 2002).
    Classifiers that identify entities and relations among them are first learned from local information in the sentence.
    This information, along with constraints induced among entity types and relations, is used to perform global probabilistic inference that accounts for the mutual dependencies among the entities.
    All the previous approaches have been evaluated on different data sets so that it is not possible to have a clear idea of which approach is better