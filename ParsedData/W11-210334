e the systems are ranked in the reverse order).
    Thus an automatic evaluation metric with a higher absolute value for &#961; is making predictions that are more similar to the human judgments than an automatic evaluation metric with a lower absolute &#961;.
    The system-level correlations are shown in Table 13 for translations into English, and Table 12 out of English, sorted by average correlation across the language pairs.
    The highest correlation for each language pair and the highest overall average are bolded.
    This year, nearly all of the metrics had stronger correlation with human judgments than BLEU.
    The metrics that had the strongest correlation this year included two metrics, MTeRater and TINE, as well as metrics that have demonstrated strong correlation in previous years like TESLA and Meteor.
    We measured the metrics&#8217; segment-level scores with the human rankings using Kendall&#8217;s tau rank correlation coefficient.
    The reference was not included as an extra translatio