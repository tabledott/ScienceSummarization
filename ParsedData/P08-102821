ore similar to the reference sentence.
    A Wilcoxon rank sum test confirmed that the difference is statistically significant (p &lt; 0.01).
    We also measured how well humans agree in their ratings.
    We employed leave-one-out resampling (Weiss and Kulikowski, 1991), by correlating the data obtained from each participant with the ratings obtained from all other participants.
    We used Spearman&#8217;s &#961;, a non parametric correlation coefficient, to avoid making any assumptions about the distribution of the similarity ratings.
    The average inter-subject agreement5 was &#961; = 0.40.
    We believe that this level of agreement is satisfactory given that naive subjects are asked to provide judgments on fine-grained semantic distinctions (see Table 1).
    More evidence that this is not an easy task comes from Figure 2 where we observe some overlap in the ratings for High and Low similarity items.
    Model Parameters Irrespectively of their form, all composition models discussed here are based on