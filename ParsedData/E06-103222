e (2005) introduce the Meteor metric, which also incorporates recall on the unigram level and further provides facilities incorporating stemming, and WordNet synonyms as a more flexible match.
    Lin and Hovy (2003) as well as Soricut and Brill (2004) present ways of extending the notion of ngram co-occurrence statistics over multiple references, such as those used in Bleu, to other natural language generation tasks such as summarization.
    Both these approaches potentially suffer from the same weaknesses that Bleu has in machine translation evaluation.
    Coughlin (2003) performs a large-scale investigation of Bleu&#8217;s correlation with human judgments, and finds one example that fails to correlate.
    Her future work section suggests that she has preliminary evidence that statistical machine translation systems receive a higher Bleu score than their non-n-gram-based counterparts.
  
  
    In this paper we have shown theoretical and practical evidence that Bleu may not correlate with human judgment 