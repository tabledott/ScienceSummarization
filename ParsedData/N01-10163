s us to treat the editing problem as a pre-process, keeping the parser unchanged.
    Second, the major clues in detecting edited words in transcribed speech seem to be relatively shallow phenomena, such as repeated word and part-of-speech sequences.
    The kind of information that a parser would add, e.g., the node dominating the EDITED node, seems much less critical.
    Note that of the major problems associated with transcribed speech, we choose to deal with only one of them, speech repairs, in a special fashion.
    Our reasoning here is based upon what one might and might not expect from a secondpass statistical parser.
    For example, ungrammaticality in some sense is relative, so if the training corpus contains the same kind of ungrammatical examples as the testing corpus, one would not expect ungrammaticality itself to be a show stopper.
    Furthermore, the best statistical parsers [3,5] do not use grammatical rules, but rather define probability distributions over all possible rules.
    Similarl