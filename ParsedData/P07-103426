daptation.
    In particular, it can support adaptation with some target domain labeled instances as well as that without any labeled target instances.
    Experiment results on three NLP tasks show that while regular semi-supervised learning methods and supervised learning methods can be applied to domain adaptation without considering domain difference, they do not perform as well as our new method, which explicitly captures domain difference.
    Our results also show that incorporating and exploiting more information from the target domain is much more useful than excluding misleading training examples from the source domain.
    The framework opens up many interesting future research directions, especially those related to how to more accurately set/estimate those weighting parameters.
  
  
    This work was in part supported by the National Science Foundation under award numbers 0425852 and 0428472.
    We thank the anonymous reviewers for their valuable comments.
  

