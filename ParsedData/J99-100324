es feasible to spend a few hours creating one bitext map by hand.
    Melamed (1996c) explains how to do so quickly and efficiently.
    Better yet, Fung (1995) shows how it may be possible to extract a small translation lexicon and a rough bitext map simultaneously.
    Frequent word types cause false points of correspondence that line up in rows and columns.
    Inspection of several bitext spaces has revealed a common noise pattern, illustrated in Figure 3.
    It consists of correspondence points that line up in rows or columns associated with frequent word types.
    Word types like the English article a can produce one or more correspondence points for almost every sentence in the opposite text.
    Only one point of correspondence in each row and column can be correct; the rest are noise.
    It is difficult to measure exactly how much noise is generated by frequent tokens, and the proportion is different for every bitext.
    Informal inspection of some bitext spaces indicated that frequent tokens are