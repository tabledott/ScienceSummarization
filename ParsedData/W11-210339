ct class.
    They ran Z-MERT on the dev set with the provided decoder/models, and created a weight vector for the system parameters.
    Each team produced a distinct final weight vector, which was used to produce English translations of sentences in the test set.
    The different translations produced by tuning the system to different metrics were then evaluated using the manual evaluation pipeline.7 The results of the evaluation are in Table 18.
    The scores show that the entries were quite close to each other, with the notable exception of the SHEFFIELDROSE-tuned system, which produced overly-long and erroneous output (possibly due to an implementation issue).
    This is also evident from the fact that 38% of pairwise comparisons indicated a tie between the two systems, with the tie rate increasing to a full 47% when excluding comparisons involving the reference.
    This is a very high tie rate &#8211; the corresponding figure in, say, European language pairs (individual systems) is only 21%.
    Wha