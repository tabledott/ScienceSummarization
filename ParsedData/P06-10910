
  A Discriminative Global Training Algorithm For Statistical MT
  
    This paper presents a novel training algorithm for a linearly-scored block sequence translation model.
    The key component is a new procedure to directly optimize the global scoring function used by a SMT decoder.
    No translation, language, or distortion model probabilities are used as in earlier work on SMT.
    Therefore our method, which employs less domain specific knowledge, is both simpler and more extensible than previous approaches.
    Moreover, the training procedure treats the decoder as a black-box, and thus can be used to optimize any decoding scheme.
    The training algorithm is evaluated on a standard Arabic-English translation task.
  
  
    .
    This paper presents a view of phrase-based SMT as a sequential process that generates block orientation sequences.
    A block is a pair of phrases which are translations of each other.
    For example, Figure 1 shows an Arabic-English translation example that uses four bl