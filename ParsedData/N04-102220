ics to emerge frequently in the future.
    Given any translation metric, the MBR decoding framework will allow us to optimize existing MT systems for the new criterion.
    This is intended to compensate for any mismatch between decoding strategy of MT systems and their evaluation criteria.
    While we have focused on developing MBR procedures for loss functions that measure various aspects of translation quality, this framework can also be used with loss functions which measure application-specific error criteria.
    We now describe related training and search procedures for NLP that explicitly take into consideration taskspecific performance metrics.
    Och (2003) developed a training procedure that incorporates various MT evaluation criteria in the training procedure of log-linear MT models.
    Foster et al. (2002) developed a text-prediction system for translators that maximizes expected benefit to the translator under a statistical user model.
    In parsing, Goodman (1996) developed parsing algorit