be used to produces useful data for machine translation and computer vision.
    By pairing up descriptions of the same video in different languages, we obtain parallel data without requiring any bilingual skills.
    Another application for our data is to apply it to computer vision tasks such as video retrieval.
    The dataset can be readily used to train and evaluate systems that can automatically generate full descriptions of unseen videos.
    As far as we know, there are currently no datasets that contain whole-sentence descriptions of open-domain video segments.
  
  
    We introduced a data collection framework that produces highly parallel data by asking different annotators to describe the same video segments.
    Deploying the framework on Mechanical Turk over a two-month period yielded 85K English descriptions for 2K videos, one of the largest paraphrase data resources publicly available.
    In addition, the highly parallel nature of the data allows us to use standard MT metrics such as BLEU to