ASR)(Jurafsky and Martin, 2000, chp.
    5,7).
    The states of the ASR model are phones, where each observation is a vector of spectral features.
    Given a sequence of observations for a sentence, the encoding &#8211; based on the lattice formed by the phones distribution of the observations, and the language model &#8211; searches for the set of words, made of phones, which maximizes the acoustic likelihood and the language model probabilities.
    In a similar manner, the supervised training of a speech recognizer combines a training corpus of speech wave files, together with word-transcription, and language model probabilities, in order to learn the phones model.
    There are two main differences between the typical ASR model and ours: (1) an ASR decoder deals with one aspect - segmentation of the observations into a set of words, where this segmentation can be modeled at several levels: subphones, phones and words.
    These levels can be trained individually (such as training a language model from a