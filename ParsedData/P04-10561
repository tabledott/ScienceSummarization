re difficult and time-consuming to construct, most recent research has focused on empirical techniques that automatically construct information extractors by training on supervised corpora (Cardie, 1997; Califf, 1999).
    One of the current best empirical approaches to IE is conditional random fields (CRF's) (Lafferty et al., 2001).
    CRF's are a restricted class of undirected graphical models (Jordan, 1999) designed for sequence segmentation tasks such as IE, part-of-speech (POS) tagging (Lafferty et al., 2001), and shallow parsing (Sha and Pereira, 2003).
    In a recent follow-up to previously published experiments comparing a large variety of IE-learning methods (including HMM, SVM, MaxEnt, and rule-based methods) on the task of tagging references to human proteins in Medline abstracts (Bunescu et al., 2004), CRF's were found to significantly out-perform competing techniques.
    As typically applied, CRF's, like almost all IE methods, assume separate extractions are independent and treat each potentia