basis of the arguments made above, to choose to compare the performance of our system on ccomp to theirs for comp, ignoring subord form.
    King et al. do report individual results for selected features and relations from an evaluation of the complete XLE parser on all 700 DepBank sentences with an almost identical overall microaveraged F1 score of 79.5%, suggesting that these results provide a reasonably accurate idea of the XLE parser&#8217;s relative performance on different features and relations.
    Where we believe that the information captured by a DepBank feature or relation is roughly comparable to that expressed by a GR in our extended DepBank, we have included King et al.&#8217;s scores in the rightmost column in Table 1 for comparison purposes.
    Even if these features and relations were drawn from the same experiment, however, they would still not be exactly comparable.
    For instance, as discussed in &#167;3 nearly half (just over 1K) the DepBank subj relations include pro as one element, 