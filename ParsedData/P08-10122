orm of the alignment, and the strong independence assumption between words.
    Furthermore it would obviate the need for heuristic combination of word alignments.
    A unified procedure may also improve the identification of non-compositional phrasal translations, and the attachment decisions for unaligned words.
    In this direction, Expectation Maximization at the phrase level was proposed by Marcu and Wong (2002), who, however, experienced two major difficulties: computational complexity and controlling overfitting.
    Computational complexity arises from the exponentially large number of decompositions of a sentence pair into phrase pairs; overfitting is a problem because as EM attempts to maximize the likelihood of its training data, it prefers to directly explain a sentence pair with a single phrase pair.
    In this paper, we attempt to address these two issues in order to apply EM above the word level.
    We attack computational complexity by adopting the polynomial-time Inversion Transduction Gr