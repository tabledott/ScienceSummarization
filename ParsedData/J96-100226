reatest entropy reflects ever-increasing knowledge and thus, hopefully, becomes a more accurate representation of the process.
    This narrowing of the space of permissible models was represented in Figure 1 by a series of intersecting lines (hyperplanes, in general) in a probability simplex.
    Perhaps more intuitively, we could represent it by a series of nested subsets of P, as in Figure 2.
    The basic incremental growth procedure may be outlined as follows.
    Every stage of the process is characterized by a set of active features S. These determine a space of models By adding feature f to S, we obtain a new set of active features S U f. Following (19), this set of features determines a set of models C(S '1)E.,- fp E P I p(f) = /3(f) for all fESU (21) The optimal model in this space of models is feature f E .F which maximizes the gain AL(S,h; that is, we select the candidate feature which, when adjoined to the set of active features S, produces the greatest increase in likelihood of the training samp