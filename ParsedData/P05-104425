ith spelling features.
    Each graph corresponds to a different level of dilution.
    Models selected using unlabeled development data are circled.
    These plots (unlike Tab.
    3) are not comparable to each other because each is measured on a different set of ambiguous words. leads to a need for more efficient tuning of the prior parameters on development data.
    The effectiveness of CE (and different neighborhoods) for dependency grammar induction is explored in Smith and Eisner (2005) with considerable success.
    We introduce there the notion of designing neighborhoods to guide learning for particular tasks.
    Instead of guiding an unsupervised learner to match linguists&#8217; annotations, the choice of neighborhood might be made to direct the learner toward hidden structure that is helpful for error-correction tasks like spelling correction and punctuation restoration that may benefit from a grammatical model.
    Wang et al. (2002) discuss the latent maximum entropy principle.
    They advoca