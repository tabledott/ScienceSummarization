methods.
    It can be seen that the learning curve for the definition of Si,j in equation (22) consistently dominates the curve for the simpler definition.
    5.4.3 Efficiency Gains.
    Section 4.5 introduced an efficient algorithm for optimizing ExpLoss.
    In this section we explore the empirical gains in efficiency seen on the parsing data sets in this article.
    We first define the quantity T as follows: Learning curves on development data for various values of &amp;.
    In each case the y-axis is the level of accuracy (100 is the baseline score), and the x-axis is the number of rounds of boosting.
    The three graphs compare the curve for &amp; = 0.0025 (the optimal value) to (from top to bottom) &amp; = 0.0001, &amp; = 0.0075, and &amp; = 0.001.
    The top graph shows that &amp; = 0.0001 leads to undersmoothing (overtraining).
    Initially the graph is higher than that for &amp; = 0.0025, but on later rounds the performance starts to decrease.
    The middle graph shows that &amp; = 0.0075 lea