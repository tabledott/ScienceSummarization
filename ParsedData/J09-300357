all the features significantly outperforms both baselines in terms of accuracy, positive F-measure, and negative F-measure.
    These consistent improvements in performance across all four algorithms show that these features are quite useful for polarity classification.
    One interesting thing that Table 15 reveals is that negative polarity words are much more straightforward to recognize than positive polarity words, at least in this corpus.
    For the negative class, precisions and recalls for the word+priorpol baseline range from 82.2 to 87.2.
    For the positive class, precisions and recalls for the word+priorpol baseline range from 63.7 to 76.7.
    However, it is with the positive class that polarity features seem to help the most.
    With the addition of the polarity features, positive F-measure improves by 5 points on average; improvements in negative F-measures average only 2.75 points.
    8.2.2 Feature Set Evaluation.
    To evaluate the performance of the various features for polarity classif