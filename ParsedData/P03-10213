set of feature functions .
    For each feature function, there exists a model parameter .
    The direct translation probability is given by: In this framework, the modeling problem amounts to developing suitable feature functions that capture the relevant properties of the translation task.
    The training problem amounts to obtaining suitable parameter values .
    A standard criterion for loglinear models is the MMI (maximum mutual information) criterion, which can be derived from the maximum entropy principle: The optimization problem under this criterion has very nice properties: there is one unique global optimum, and there are algorithms (e.g. gradient descent) that are guaranteed to converge to the global optimum.
    Yet, the ultimate goal is to obtain good translation quality on unseen test data.
    Experience shows that good results can be obtained using this approach, yet there is no reason to assume that an optimization of the model parameters using Eq.
    4 yields parameters that are optimal