sufficient to improve the ranking of the interpretations found.
    In our tests, the NLP system produces all interpretations satisfying all syntactic and semantic constraints.
    From that set, the intended interpretation must be chosen.
    The context-free probability model reduced the error rate on an independent test set Predictions of probabilistic language model. by a factor of two to four, compared with no model, i.e., random selection from the interpretations satisfying all knowledge-based constraints.
    We tested the predictive power of rule probabilities using this model both in unsupervised and in supervised mode.
    In the former case, the input is all parse trees (whether correct or not) for the sentences in the training set.
    In the latter case, the training data included a specification of the correct parse as hand picked by the grammar's author from among the parse trees produced by the system.
    The detailed results from using a training set of 81 sentences appear in the histogram i