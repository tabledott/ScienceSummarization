ch higher than previously thought.
    Indeed, it may be that adding this new parser to the mix may yield still higher results.
    From our perspective, perhaps the two most important numbers to come out of this research are the overall error reduction of 13% over the results in [9] and the intermediateresult improvement of nearly 2% on labeled precision/recall due to the simple idea of guessing the head's pre-terminal before guessing the head.
    Neither of these results were anticipated at the start of this research.
    As noted above, the main methodological innovation presented here is our &amp;quot;maximumentropy-inspired&amp;quot; model for conditioning and smoothing.
    Two aspects of this model deserve some comment.
    The first is the slight, but important, improvement achieved by using this model over conventional deleted interpolation, as indicated in Figure 2.
    We expect that as we experiment with other, more semantic conditioning information, the importance of this aspect of the model wil