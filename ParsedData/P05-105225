helped with the other deep processing results.
    This design feature of our approach should be best employed when the preprocessing errors at each level are independent, namely when there is no dependency between the preprocessing modules.
    The model was tested on text with annotated entities, but its design is generic.
    It can work with noisy entity detection input from an automatic tagger.
    With all the existing information from other processing levels, this model can be also expected to recover from errors in entity tagging.
  
  
    Kernel functions have many nice properties.
    There are also many well known kernels, such as radial basis kernels, which have proven successful in other areas.
    In the work described here, only linear combinations and polynomial extensions of kernels have been evaluated.
    We can explore other kernel properties to integrate the existing syntactic kernels.
    In another direction, training data is often sparse for IE tasks.
    String matching is not suffic