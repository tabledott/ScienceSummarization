 lexicons.
    Unfortunately, trading space requirements and efficiency for explanatory power often yields non-intuitive results.
    Consider, for example, the parallel corpus of three sentence pairs shown in Figure 1.
    Intuitively, if we allow any Source words to be aligned to any Target words, the best alignment that we can come up with is the one in Figure 1.c.
    Sentence pair (S2, T2) offers strong evidence that &#8220;b c&#8221; in language S means the same thing as &#8220;x&#8221; in language T. On the basis of this evidence, we expect the system to also learn from sentence pair (S1, T1) that &#8220;a&#8221; in language S means the same thing as &#8220;y&#8221; in language T. Unfortunately, if one works with translation models that do not allow Target words to be aligned to more than one Source word &#8212; as it is the case in the IBM models (Brown et al., 1993) &#8212; it is impossible to learn that the phrase &#8220;b c&#8221; in language S means the same thing as word &#8220;x&#8221; in langua