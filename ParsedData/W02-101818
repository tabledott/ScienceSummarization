  We also evaluated the translations automatically, using the IBM-Bleu metric (Papineni et al., 2002).
    The results in Table 1 show that the phrased-based translation model proposed in this paper significantly outperforms IBM Model 4 on both the subjective and objective metrics.
    6 Discussion 6.1 Limitations The main shortcoming of the phrase-based model in this paper concerns the size of the t-table and the cost of the training procedure we currently apply.
    To keep the memory requirements manageable, we arbitrarily restricted the system to learning phrase translations of at most six words on each side.
    Also, the swap, break, and merge operations used during the Viterbi training are computationally expensive.
    We are currently investigating the applicability of dynamic programming techniques to increase the speed of the training procedure.
    Clearly, there are language pairs for which it would be helpful to allow concepts to be realized as non-contiguous phrases.
    The English word &#8220