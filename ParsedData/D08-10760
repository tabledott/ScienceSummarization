
  Lattice-based Minimum Error Rate Training for Statistical Machine Translation
  
    Minimum Error Rate Training (MERT) is an effective means to estimate the feature function weights of a linear model such that an automated evaluation criterion for measuring system performance can directly be optimized in training.
    To accomplish this, the training procedure determines for each feature function its exact error surface on a given set of candidate translations.
    The feature function weights are then adjusted by traversing the error surface combined over all sentences and picking those values for which the resulting error count reaches a minimum.
    Typically, in MERT are represented as lists which contain the probable translation hypotheses produced by a decoder.
    In this paper, we present a novel algorithm that allows for efficiently constructing and reprethe exact error surface of translations that are encoded in a phrase lattice. to MERT, the number of candidate translations thus taken into acco