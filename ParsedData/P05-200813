re of the datasets &#8212; one would expect language to be informal in movie reviews, and even more so in Usenet articles.
    In contrast, language in newswire articles is far more formal.
    We might therefore infer a further type of dependence in sentiment classification, that of language-style dependency.
    Also, note that neither machine-learning model consistently out-performs the other.
    We speculate that this, and the generally mediocre performance of the classifiers, is due (at least) to two factors; poor coverage of the features found in the test domains and a high level of noise found in Usenet article extracts.
    We investigate these factors below.
    Figure 8 shows the coverage of the Emoticon-trained classifiers on the various test sets.
    In these experiments, we are interested in the coverage in terms of unique token types rather than the frequency of features, as this more closely reflects the training of the models (see Section 2.1).
    The mean coverage of the Polarity 1.0 datas