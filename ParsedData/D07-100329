812 0.7636 0.6029 0.6852 +2,293 noisy Cui et al 0.2165 0.3690 0.2833 0.4248 +WN 0.4333 0.5363 0.3811 0.4964 Jeopardy (base only) 0.5174 0.5570 0.4922 0.5732 Jeopardy 0.6683 0.7443 0.5655 0.6687 Table 2: Results on development and test sets.
			TreeMatch is our implementation of Punyakanok et al (2004); +WN modifies their edit distance function using WordNet.
			We also report our implementation of Cui et al (2005), along with our WordNet expansion (+WN).
			The Jeopardy base model and mixture with the lexical-semantics log-linear model perform best; both are trained using conditional maximum likelihood estimation.
			The top part of the table shows performance using 100 manually-annotated question examples (questions 1?100 in TREC 8?12), and the bottom part adds noisily, automatically annotated questions 101?
			2,393.
			Boldface marks the best score in a column and any scores in that column not significantly worse under a a two-tailed paired t-test (p &lt; 0.03).
			5.3 Results.
			Evaluation results on the