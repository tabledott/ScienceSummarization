 adding the tsim score to the set of structural features associated with each candidate pair, and then training a new decision tree classifier.
    Because Arabic is a highly inflected language with many surface forms, we found it necessary to use morphological preprocessing in order to make effective use of a dictionary.
    For English, we tokenized the text and used the WordNet lemmatizer to strip suffixes.
    The Arabic texts were tokenized at punctuation, then romanized and converted to root forms using a morphological analysis tool (Darwish 2002).
    This approximately halved the vocabulary size for the Arabic texts (from 89,047 types to 48,212 types).
    The translation lexicon used to compute tsim contained 52,211 entries, each containing one English lemma and one Arabic root.27 Of these, 16,944 contained two items that were both present in the candidate set of 8,294 Web page pairs.
    The approximations discussed in Section 3.2.2 were employed: Competitive linking on the first 500 words in each d