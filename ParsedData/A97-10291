ot;Nymble&amp;quot;.
    To our knowledge, Nymble out-performs the best published results of any other learning name-finder.
    Furthermore, it performs at or above the 90% accuracy level, often considered &amp;quot;near-human performance&amp;quot;.
    The system arose from the NE task as specified in the last Message Understanding Conference (MUC), where organization names, person names, location names, times, dates, percentages and money amounts were to be delimited in text using SGML-markup.
    We will describe the various models employed, the methods for training these models and the method for &amp;quot;decoding&amp;quot; on test data (the term &amp;quot;decoding&amp;quot; borrowed from the speech recognition community, since one goal of traversing an HMM is to recover the hidden state sequence).
    To date, we have successfully trained and used the model on both English and Spanish, the latter for MET, the multi-lingual entity task.
  
  
    The basic premise of the approach is to consider the raw 