that satisfy the GSD assumption is shown in Figure 2.
    The algorithm can be justified as an instance of Lagrangian relaxation applied to the problem The algorithm employs two sets of Lagrange multipliers, u(i, j) and v(i, j), corresponding to constraints in Eqs.
    11 and 12.
    As in Theorem 1, if at any point in the algorithm z(k) = y(k), then (z(k), y(k)) is an exact solution to the problem in Eq.
    10.
  
  
    In our experiments we make use of discriminative linear models, where for an input sentence x, the score for a parse y is f(y) = w ' &#966;(x, y) where w E Rd is a parameter vector, and &#966;(x, y) E Rd is a feature-vector representing parse tree y in conjunction with sentence x.
    We will assume that the features decompose in the same way as the siblingdecomposable or grandparent/sibling-decomposable models, that is &#966;(x, y) = Pni=0 &#966;(x, y|i) for some feature vector definition &#966;(x, y|i).
    In the bigram sibling models in our experiments, we assume that where as before l1