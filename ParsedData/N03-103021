discourse boundaries of 24.5% (recall accuracy improvement from 77.1% to 82.7%) over (Marcu, 2000).
    The overall error reduction is of 15.1% (improvement in F-score from 80.1% to 83.1%).
    In order to asses the impact on the performance of the discourse segmenter due to incorrect syntactic parse trees, we also carry an evaluation using syntactic trees from the Penn Treebank.
    The results are shown in row .
    Perfect syntactic trees lead to a further error reduction of 9.5% (F-score improvement from 83.1% to 84.7%).
    The performance ceiling for discourse segmentation is given by the human annotation agreement F-score of 98.3%.
    We train our discourse parsing model on the Training section of the corpus described in Section 2, and test it on the Test section.
    The training regime uses syntactic trees from the Penn Treebank.
    The performance is assessed using labeled recall and labeled precision as defined by the standard Parseval metric (Black et al., 1991).
    As mentioned in Section 2, w