 tagger, we compare the chosen tag with one provided by a human annotator.
    Various methods of quoting accuracy have been used in the literature, the most common being the proport ion of words (tokens) receiving the correct tag.
    A better measure is the proportion of ambiguous words which are given the correct tag, where by ambiguous we mean that more than one tag was hypothesised.
    The former figure looks more impressive, but the latter gives a better measure of how well the tagger is doing, since it factors out the trivial assignment of tags to non-ambiguous words.
    For a corpus in which a fraction a of the words are ambiguous, and p is the accuracy on ambiguous words, the overall accuracy can be recovered from 1 &#8212; a + pa. All of the accuracy figures quoted below are for ambiguous words only.
    The training and test corpora were drawn from the LOB corpus and the Penn treebank.
    The hand tagging of these corpora is quite different.
    For example, the LOB tagset used 134 tags, while t