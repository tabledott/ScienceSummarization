an our system for each of the four loss functions and asked two human judgesto rate the output on a scale of 1 to 5.
			The Ham ming loss over tokens performed best with a meanrating of 3.18, closely followed by the edit dis tance (3.17).
			We chose the former over the latter as it is less coarsely approximated during search.
			Baseline There are no existing models thatcan be readily trained on our abstractive com pression data.
			Instead, we use Cohn and Lapata?s (2007) extractive model as a baseline.
			The latter was trained on an extractive compression corpus drawn from the BNC (Clarke, 2008) and tunedto provide a similar compression rate to our sys tem.
			Note that their model is a strong baseline: it performed significantly better than competitive approaches (McDonald, 2006) across a variety of compression corpora.Evaluation Methodology Sentence compres sion output is commonly evaluated by eliciting human judgments.
			Following Knight and Marcu(2002), we asked participants to rate the grammati cali