 function independently for each level of each facet and chose the category with the highest prediction.
    The most discriminating of the 55 variables were selected using stepwise backward selection based on the AIC criterion (see documentation for STEP.GLNI in Statistical Sciences (1991)).
    A separate set of variables was selected for each binary discrimination task.
    In order to see whether our easily-computable surface cues are comparable in power to the structural cues used in Karlgren and Cutting (1994), we also ran LR with the cues used in their experiment.
    Because we use individual texts in our experiments instead of the fixed-length conglomerate samples of Karlgren and Cutting, we averaged all count features over text length.
    Because of the high number of variables in our experiments. there is a danger that overfitting occurs.
    LR also forces us to simulate polytomous decisions by a series of binary decisions. instead of directly modeling a multinomial response.
    Finally, classic