atsuzaki et al. (2005).
    We present experiments which explicitly minimize various evaluation risks over a candidate set using samples from the split PCFG, and relate those conditions to the existing non-sampling algorithms.
    We demonstrate that n-best reranking according to likelihood is superior for exact match, and that the non-reranking methods are superior for maximizing F1.
    A specific contribution is to discuss the role of unary productions, which previous work has glossed over, but which is important in understanding why the various methods work as they do.
    Finally, in Sec.
    5, we learn state-split PCFGs for German and Chinese and examine out-of-domain performance for English.
    The learned grammars are compact and parsing is very quick in our multi-stage scheme.
    These grammars produce the highest test set parsing figures that we are aware of in each language, except for English for which non-local methods such as feature-based discriminative reranking are available (Charniak and 