.
    This can be through the use of more sophisticated models, such as additional language models that take into account the signed distance between words in the original story to condition the probability that they should appear separated by some distance in the headline.
    Recently, we have extended the model to generate multi-sentential summaries as well: for instance, given an initial sentence such as &#8220;Clinton to meet visit MidEast.&#8221; and words that are related to nouns (&#8220;Clinton&#8221; and &#8220;mideast&#8221;) in the first sentence, the system biases the content selection model to select other nouns that have high mutual information with these nouns.
    In the example sentence, this generated the subsequent sentence &#8220;US urges Israel plan.&#8221; This model currently has several problems that we are attempting to address: for instance, the fact that the words co-occur in adjacent sentences in the training set is not sufficient to build coherent adjacent sentences (problems wit