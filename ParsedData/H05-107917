omains (domainsizeabsdif, domainsizereldif) and the size of the models (modelsizeabsdif, modelsizereldif).
	
	
			There are not many test suites available for textual inference.
			We use throughout this section the dataset made available as part of the RTE challenge.
			4.1 Dataset Design and Evaluation Measures.
			The organisers released a development set of 567 sentence pairs and a test set of 800 sentence pairs.In both sets, 50% of the sentence pairs were anno tated as TRUE and 50% as FALSE, leading to a 50% most frequent class baseline for automatic systems.
			The examples are further distinguished according to the way they were designed via a so-called Task variable.
			For examples marked CD (Comparable Documents), sentences with high lexical overlap in comparable news articles were selected, whereas thehypotheses of examples marked QA (Question An swering) were formed by translating questions from e.g., TREC into statements.
			The other subsets are IE (Information extraction), MT (Machine Translati