 and evaluate the results of computation.
    This linguistic phenomenon has proved to be far more elusive and complex than many others.
    We have discussed this at length elsewhere (Wilks 1997) and will assume here that humans can mark up text for senses to a sufficient degree.
    Kilgarriff (1993) questioned the possibility of creating sense-tagged texts, claiming the task to be impossible.
    However, it should be borne in mind that no alternative has yet been widely accepted and that Kilgarriff himself used the markup-and-test model for SENSEVAL.
    In the following discussion we compare the evaluation methodology adopted here with those proposed by others.
    The standard evaluation procedure for WSD is to compare the output of the system against gold standard texts, but these are very labor-intensive to obtain; lexical semantic markup is generally considered to be a more difficult and time-consuming task than part-of-speech markup (Fellbaum et al. 1998).
    Rather than expend a vast amount of eff