re weights unless they produce great score gain.
    The regularized objective F is: Since we use a conjugate-gradientprocedure to maximize the data likelihood, the addition of a penalty term is easily incorporated.
    Both the total size of the penalty and the partial derivatives with repsect to each &#955;j are trivial to compute; these are added to the log-likelihood and log-likelihood derivatives, and the penalized optimization procedes without further modification.
    We have not extensively experimented with the value of U2 &#8211; which can even be set differently for different parameters or parameter classes.
    All the results in this paper use a constant U2 = 0.5, so that the denominator disappears in the above expression.
    Experiments on a simple model with U made an order of magnitude higher or lower both resulted in worse performance than with U2 = 0.5.
    Our experiments show that quadratic regularization is very effective in improving the generalization performance of tagging models, mos