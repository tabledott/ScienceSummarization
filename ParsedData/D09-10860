
  Parser Adaptation and Projection with Quasi-Synchronous Grammar Features
  
    We connect two scenarios in structured parser trained on one corpus to another annotation style, and annotations from one to another.
    We propose quasigrammar features for these structured learning tasks.
    That is, we score a aligned pair of source and target trees based on local features of the trees and the alignment.
    Our quasi-synchronous model assigns positive probability to any alignment of any trees, in contrast to a synchronous grammar, which would insist on some form of structural parallelism.
    In monolingual dependency parser adaptation, we achieve high accuracy in translating among multiple annotation styles for the same sentence.
    On the more difficult problem of cross-lingual parser projection, we learn a dependency parser for a target language by using bilingual text, an English parser, and automatic word alignments.
    Our experiments show that unsupervised QG projection improves on parses trained