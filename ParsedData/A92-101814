of 50,000 words in the Brown corpus can be reduced to approximately 400 distinct ambiguity classes [Kupiec, 1992].
    To further reduce the number of parameters, a first-order model can be employed (this assumes that a word's category depends only on the immediately preceding word's category).
    In [Kupiec, 1989a], networks are used to selectively augment the context in a basic firstorder model, rather than using uniformly second-order dependencies.
    We next describe how our choice of techniques satisfies the criteria listed in section 1.
    The use of an HMM permits complete flexibility in the choice of training corpora.
    Text from any desired domain can be used, and a tagger can be tailored for use with a particular text database by training on a portion of that database.
    Lexicons containing alternative tag sets can be easily accommodated without any need for re-labeling the training corpus, affording further flexibility in the use of specialized tags.
    As the resources required are simply 