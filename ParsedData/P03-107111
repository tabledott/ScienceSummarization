n at x.
    This score is supposed to capture the sharpness of the change in lexical cohesion, and give probabilities close to 1 for breaks like sentence 179 in Figure 1.
    Finally, the algorithm selects the hypothesized boundaries with the highest computed probabilities.
    If the number of reference boundaries is unknown, the algorithm has to make a guess.
    It computes the 5Normalizing anything in these windows has little effect, since the cosine similarity is scale invariant, that is cosine(&#945;xa, xb) = cosine(xa, xb) for &#945; &gt; 0. x-axis represent sentence indices, and y-axis represents the lexical cohesion function.
    The representative example presented here is segmented by LCseg with an error of Pk = 15.79, while the average performance of the algorithm is Pk = 15.31 on the WSJ test corpus (unknown number of segments). mean and the variance of the hypothesized probabilities of all potential boundaries (local minima).
    As we can see in Figure 1, there are many local minima that do not