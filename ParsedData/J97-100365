fewer judges) found in discourse segmentation experiments.
    An unfortunate aspect of the algorithm in its current form is that it requires the setting of several interdependent parameters, the most important of which are the size of the text unit that is compared, and the number of words in a token-sequence (which controls the number of times a term appears in a window as well as the number of data points that are sampled).
    The method, width, and number of rounds of smoothing must also be chosen.
    Usually only modest amounts of smoothing can be allowed, since more dramatic smoothing tends to obscure the point at which the subtopic transition takes place.
    Finally, the method for determining how many boundaries to assign must be specified.
    The three are interrelated: for example, using a larger text window requires less smoothing and fewer boundaries will be found, yielding a coarser-grained segmentation.
    Initial testing was done on the texts evaluated with several different sets of parame