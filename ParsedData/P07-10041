y yields two different statistical models which can be trained independently of each other: the translation model p(s  |t) and the target language model p(t).
    State-of-the-art SMT systems are trained on large collections of text which consist of bilingual corpora (to learn the parameters of p(s  |t)), and of monolingual target language corpora (for p(t)).
    It has been shown that adding large amounts of target language text improves translation quality considerably.
    However, the availability of monolingual corpora in the source language does not help improve the system&#8217;s 25 performance.
    We will show how such corpora can be used to achieve higher translation quality.
    Even if large amounts of bilingual text are given, the training of the statistical models usually suffers from sparse data.
    The number of possible events, i.e. phrase pairs or pairs of subtrees in the two languages, is too big to reliably estimate a probability distribution over such pairs.
    Another problem is that f