call that judges were excluded to judge system output from their own institution), we normalized the scores.
    The normalized judgement per judge is the raw judgement plus (3 minus average raw judgement for this judge).
    In words, the judgements are normalized, so that the average normalized judgement per judge is 3.
    Another way to view the judgements is that they are less quality judgements of machine translation systems per se, but rankings of machine translation systems.
    In fact, it is very difficult to maintain consistent standards, on what (say) an adequacy judgement of 3 means even for a specific language pair.
    The way judgements are collected, human judges tend to use the scores to rank systems against each other.
    If one system is perfect, another has slight flaws and the third more flaws, a judge is inclined to hand out judgements of 5, 4, and 3.
    On the other hand, when all systems produce muddled output, but one is better, and one is worse, but not completely wrong, a judge i