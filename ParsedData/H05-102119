n estimating the reordering parameters from bitext.
			Finally, the MJ-2 VT model performs better than the flat MJ-2 model, but onlymarginally better than the MJ-1 VT model.
			There fore estimation does improve the MJ-2 model but allowing reordering beyond a window of 1 phrase is not useful when translating either Arabic or Chinese into English in this framework.The flat MJ-1 model outperforms the no reordering case and the flat MJ-2 model is better than the flat MJ-1 model; we hypothesize that phrase reordering increases search space of translations thatallows the language model to select a higher qual ity hypothesis.
			This suggests that these models of phrase reordering actually require strong languagemodels to be effective.
			We now investigate the inter action between language models and reordering.Our goal here is to measure translation performance of reordering models over variable span n gram LMs (Table 6).
			We observe that both MJ-1 and MJ-2 models yield higher improvements under higher order LM