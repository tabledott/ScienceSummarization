LBFGS, but do coarse-to-fine pruning to approximate their gradients and log likelihood.
    Because they were focusing on grammar splitting they, like (Johnson, 2001), did not employ any features, and, like (Taskar et al., 2004), they saw only small gains from switching from generative to discriminative training.
  
  
    We have presented a new, feature-rich, dynamic programming based discriminative parser which is simpler, more effective, and faster to train and test than previous work, giving us new state-of-the-art performance when training and testing on sentences of length &lt; 15 and the first results for such a parser trained and tested on sentences of length &lt; 40.
    We also show that the use of SGD for training CRFs performs as well as L-BFGS in a fraction of the time.
    Other recent work on discriminative parsing has neglected the use of features, despite their being one of the main advantages of discriminative training methods.
    Looking at how other tasks, such as named entity recognitio