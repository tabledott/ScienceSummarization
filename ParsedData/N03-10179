y consider word sequences as phrases, if they are constituents, i.e. subtrees in a syntax tree (such as a noun phrase).
    To identify these, we use a word-aligned corpus annotated with parse trees generated by statistical syntactic parsers [Collins, 1997; Schmidt and Schulte im Walde, 2000].
    The third method for comparison is the joint phrase model proposed by Marcu and Wong [2002].
    This model learns directly a phrase-level alignment of the parallel corpus.
    The Giza++ toolkit was developed to train word-based translation models from parallel corpora.
    As a byproduct, it generates word alignments for this data.
    We improve this alignment with a number of heuristics, which are described in more detail in Section 4.5.
    We collect all aligned phrase pairs that are consistent with the word alignment: The words in a legal phrase pair are only aligned to each other, and not to words outside [Och et al., 1999].
    Given the collected phrase pairs, we estimate the phrase translation probability