ausing the feature space of the percptron becoming even larger.
    Experimental results show that, it achieves obvious improvement over the perceptron-only model, about from 0.973 to 0.978 on segmentation, and from 0.925 to 0.934 on Joint S&amp;T, with error reductions of 18.5% and 12% respectively.
  
  
    We proposed a cascaded linear model for Chinese Joint S&amp;T.
    Under this model, many knowledge sources that may be intractable to be incorporated into the perceptron directly, can be utilized effectively in the outside-layer linear model.
    This is a substitute method to use both local and non-local features, and it would be especially useful when the training corpus is very large.
    However, can the perceptron incorporate all the knowledge used in the outside-layer linear model?
    If this cascaded linear model were chosen, could more accurate generative models (LMs, word-POS co-occurrence model) be obtained by training on large scale corpus even if the corpus is not correctly labelled entire