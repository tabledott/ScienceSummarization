   In contrast, our model is not specific to any subject and uses 12 individual grade models trained on a greatly expanded training set.
    While our model is also initially based on na&#239;ve Bayes, we do not treat each class as independent.
    Instead, we use a mixture of grade models, which greatly improves accuracy.
    We also do not include sentence length as a syntactic component.
    Si and Callan did not perform any analysis of feature selection methods so it is unclear whether their classifier was conflating topic prediction with difficulty prediction.
    In this paper we examine feature selection as well as our model's ability to generalize.
  
  
    Our statistical model is based on a variation of the multinomial na&#239;ve Bayes classifier, which we call the &#8216;Smoothed Unigram&#8217; model.
    In text classification terms, each class is described by a language model corresponding to a predefined level of difficulty.
    For English Web pages, we trained 12 language models corresponding