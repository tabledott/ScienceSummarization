ser with scarce resources, see (Steedman et al., 2003), who apply co-training and corrected co-training to bootstrapping an English parser starting with 1000 parsed training senvalidation.
    The SITG system is evaluated on test data, but is trained without labeled data; the SITG with English trees uses true treebank English parses to constrain the search and thus represents an upper bound.
    The table shows means and standard deviations for five-fold cross-validation.
    The best test results in each column are in bold. validation.
    Bold-faced numbers in the bilingual parsers indicate significant improvements on the PCFG baseline using the paired-sample t-test at the 0.01 level. tences.
    Although this technique has interesting properties, our combined optimization should be more stable since it does not involve iterative example selection.
  
  
    We have presented a novel technique for merging simple, separately trained models for Korean parsing, English dependency parsing, and word translation,