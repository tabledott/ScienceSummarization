= O, B i t  1 o f  Verb  == 1 .
  B i t  m o f  Verb  == 0, B i t  m o f  Verb  ==I The feature search then proceeds as follows: 1.
  Initialize 79 as described above, initialize A,4 to contain complement and null feature 2.
  Select the best feature from 79 using Delta-Likelihood rank 3.
  Add it to .A4 2With a certain f requency cut-off, usual ly 3 to 5 3 Also with a certain f requency cut-off 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 PERFORMANCE: Wall St. Journal io io .
  20 1 O0 120 140 160 180 200 Figure 1" Performance of Maximum Entropy Model on Wall St. Journal Data 4.
  Train Maximum Entropy Model, using features in .A4 5.
  Grow 79 based on last feature selected 6. repeat from (2) If we measure the training entropy and test entropy after the addition of each feature, the training entropy will monotoni- cally decrease while the test entropy will eventually reach a minimum (due to overtraining).
  Test set performance usually peaks at the test entropy minimum ( see Fig.
  Delta-Likelihood At step (2) in the