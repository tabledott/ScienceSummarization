o filter noise from the process.
	
	
			Table 1 shows the results of training translation models on data extracted by both methods and then tested on the blind data.
			The best overall performance, irrespective of test data type, is achieved by the L12 training set, with an 11.58% overall AER on the 250 sentence pair edit distance test set (20.88% AER for non-identical words).
			The F2 training data is probably too sparse and, with 40% unrelated sentence pairs, too noisy to achieve equally good results; nevertheless the gap between the results for the two training data types is dramatically narrower on the F2 test data.
			The nearly comparable numbers for the two training data sets, at 13.2% and 14.7% respectively, suggest that the L12 training corpus provides no substantive advantage over the F2 data when tested on the more complex test data.
			This is particularly striking given the noise inherent in the F2 training data.
	
	
			To explore some of the differences between the training sets, we hand-exami