
  Arabic Preprocessing Schemes For Statistical Machine Translation
  
    In this paper, we study the effect of different word-level preprocessing decisions for Arabic on SMT quality.
    Our results show that given large amounts of training data, splitting off only proclitics performs best.
    However, for small amounts of training data, it is best to apply English-like tokenization using part-of-speech tags, and sophisticated morphological analysis and disambiguation.
    Moreover, choosing the appropriate preprocessing produces a significant increase in BLEU score if there is a change in genre between training and test data.
  
  
    Approaches to statistical machine translation (SMT) are robust when it comes to the choice of their input representation: the only requirement is consistency between training and evaluation.1 This leaves a wide range of possible preprocessing choices, even more so for morphologically rich languages such as Arabic.
    We use the term &#8220;preprocessing&#8221; to describe 