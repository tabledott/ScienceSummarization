dered.
    It is therefore not surprising that systems often employ scoring functions to select the most coherent output among alternative renderings (see the discussion in Section 2.2).
    In this article we argue that encoding texts as entity transition sequences constitutes an appropriate feature set for learning (rather than manually specifying) such a ranking function (see Section 4 for details).
    We present two task-based experiments that put this hypothesis to the test: information ordering (Experiment 1) and summary coherence rating (Experiment 2).
    Both tasks can be naturally formulated as ranking problems; the learner takes as input a set of alternative renderings of the same document and ranks them based on their degree of local coherence.
    Examples of such renderings are a set of different sentence orderings of the same text and a set of summaries produced by different systems for the same document.
    Note that in both ranking experiments we assume that the algorithm is provided with a