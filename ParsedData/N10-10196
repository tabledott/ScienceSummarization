ssification approach also has an advantage in terms of data requirements: Our primary models are trained on large sets of widely available well-formed English text.
    The metaclassifier, in contrast, is trained on a smaller set of error-annotated learner data.
    This allows us to address the problem of domain mismatch: We can leverage large well-formed data sets that are substantially different from real-life learner language for the primary models, and then fine-tune the output to learner English using a much smaller set of expensive and hard-to-come-by annotated learner writing.
    For the purpose of this paper, we restrict ourselves to article and preposition errors.
    The questions we address are: Our evaluation is conducted on a large data set of error-annotated learner data.
  
  
    Our error-specific primary models are maximum entropy classifiers (Rathnaparki 1997) for articles and for prepositions.
    Features include contextual features from a window of six tokens to the right and left, suc