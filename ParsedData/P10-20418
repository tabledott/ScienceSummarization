ter as a selection criterion than random selection.
  
  
    We have empirically evaluated our proposed method for selecting data from a non-domainspecific source to model text in a specific domain.
    For the in-domain corpus, we chose the English side of the English-French parallel text from release v5 of the Europarl corpus (Koehn, 2005).
    This consists of proceedings of the European Parliament from 1999 through 2009.
    We used the text from 1999 through 2008 as in-domain training data, and we used the first 2000 sentences from January 2009 as test data.
    For the nondomain-specific corpus, we used the LDC English Gigaword Third Edition (LDC Catalog No.
    : LDC2007T07).
    We used a simple tokenization scheme on all data, splitting on white space and on boundaries between alphanumeric and nonalphanumeric (e.g., punctuation) characters.
    With this tokenization, the sizes of our data sets in terms of sentences and tokens are shown in Table 1.
    The token counts include added end-of-sentence 