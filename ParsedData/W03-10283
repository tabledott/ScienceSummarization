.
    The features used are, for example, the frequency of the most frequent phrase component; the relative number of characters of the phrase; the first relative occurrence of a phrase component; and whether the last word is an adjective, as judged by the unstemmed suffix.
    Turney reports that the genetic algorithm outputs better keywords than the decision trees.
    Part of the same training and test material is later used by Frank et al. (1999) for evaluating their algorithm in relation to Turney&#8217;s algorithm.
    This algorithm, which is based on naive Bayes, uses a smaller and simpler set of features&#8212; term frequency, collection frequency (idf), and relative position&#8212;although it performs equally well.
    Frank et al. also discuss the addition of a fourth feature that significantly improves the algorithm, when trained and tested on domain-specific documents.
    This feature is the number of times a term is assigned as a keyword to other documents in the collection.
    It should be no