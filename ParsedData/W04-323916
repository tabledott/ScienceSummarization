11 respectively.
    To employ learning and classification, we have to represent a given sentence as a labeled ordered tree.
    In this paper, we use the following three representation forms.
    Ignoring structural information embedded in text, we simply represent a text as a set of words.
    This is exactly the same setting as Boostexter.
    Word boundaries are identified using a Japanese morphological analyzer, ChaSen3.
    We represent a text in a word-based dependency tree.
    We first use CaboCha4 to obtain a chunk-based dependency tree of the text.
    The chunk approximately corresponds to the basephrase in English.
    By identifying the head word in the chunk, a chunk-based dependency tree is converted into a word-based dependency tree.
    It is the word-based dependency tree that assumes that each word simply modifies the next word.
    Any subtree of this structure becomes a word n-gram.
    We compared the performance of our Boosting algorithm and support vector machines (SVMs) with bag-of-w