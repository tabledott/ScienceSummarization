odel to be more probable than the correct word.
    Thus, We is the 9th most probable word to begin a sentence.
    At this point in the sentence, in the absence of any other context, the trigram model is as good as any model we could have.
    Following We at the beginning of the sentence, need is the 7th most probable word, ranking behind are, will, the, would, also, and do.
    Here, again, the trigram model still accounts for all of the context there is and so should be doing as well as any model can.
    Following We need, to is the most probable word.
    Although by now, the trigram model has lost track of the complete context (it no longer realizes that we are at the beginning of a sentence), it is still doing very well.
    Table 4 shows that the trigram model captures a number of important frequencybased constraints that would be missed by most traditional parsers.
    For example, the trigram model captures the fact that issues is particularly predictable in the collocation: important issues.
    I