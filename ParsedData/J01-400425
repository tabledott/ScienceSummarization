ce engine in Figure 5 and Figure 6, showing its accuracy averaged over three random trials when trained on 1, 2, 3, 4, 5, 10, 15, 20, 25, and 30 training documents.
    The learning curves indicate that our coreference engine achieves its peak performance with about 25 training documents, or about 11,000 to 17,000 words of training documents.
    This number of training documents would generate tens of thousands of training examples, sufficient for the decision tree learning algorithm to learn a good classifier.
    At higher numbers of training documents, our system seems to start overfitting the training data.
    For example, on MUC-7 data, training on the full set of 30 training documents results in a more complex decision tree.
    Our system's scores are in the upper region of the MUC-6 and MUC-7 systems.
    We performed a simple one-tailed, paired sample t-test at significance level p = 0.05 to determine whether the difference between our system's F-measure score and each of the other systems' F-measu