ts are averaged.
    The training length is given on a logarithmic scale.
    As for the NEGRA corpus, tagging accuracy is very high for known tokens even with small amounts of training data.
    We exploit the fact that the tagger not only determines tags, but also assigns probabilities.
    Figure 7 shows the accuracy when separating assignments with quotients larger and smaller than the threshold (hence reliable and unreliable assignments).
    Again, we find that accuracies for reliable assignments are much higher than for unreliable assignments.
    Average part-of-speech tagging accuracy is between 96% and 97%, depending on language and tagset, which is at least on a par with state-of-the-art results found in the literature, possibly better.
    For the Penn Treebank, (Ratnaparkhi, 1996) reports an accuracy of 96.6% using the Maximum Entropy approach, our much simpler and therefore faster HMM approach delivers 96.7%.
    This comparison needs to be re-examined, since we use a ten-fold crossvalidation an