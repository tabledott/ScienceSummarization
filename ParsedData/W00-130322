of chunks need not consider since there is no possibility of dependency between them from grammatical constraints.
    Such pairs of chunks are not necessary to use as negative examples in the training phase.
    For example, a chunk within quotation marks may not modify a chunk that locates outside of the quotation marks.
    Of course, we have to be careful in introducing such constraints, and they should be learned from existing corpus.
    &#8226; Integration with other simple models Suppose that a computationally light and moderately accuracy learning model is obtainable (there are actually such systems based on probabilistic parsing models).
    We can use the system to output some redundant parsing results and use only those results for the positive and negative examples.
    This is another way to reduce the size of training data.
    We can start with a small size of training data with a small size of feature set.
    Then, by analyzing held-out training data and selecting the features that affect th