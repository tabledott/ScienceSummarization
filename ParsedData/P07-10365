d similarity.
    This follows a conceptually similar approach by (Cohen and Sarawagi, 2004) that uses a large named-entity dictionary, where the similarity between the candidate named-entity and its matching prototype in the dictionary is encoded as a feature in a supervised classifier.
    In our framework, dictionary lookup approaches are viewed as unary constraints on the output states.
    We extend these kinds of constraints and allow for more general, n-ary constraints.
    In the supervised learning setting it has been established that incorporating global information can significantly improve performance on several NLP tasks, including information extraction and semantic role labeling.
    (Punyakanok et al., 2005; Toutanova et al., 2005; Roth and Yih, 2005).
    Our formalism is most related to this last work.
    But, we develop a semi-supervised learning protocol based on this formalism.
    We also make use of soft constraints and, furthermore, extend the notion of soft constraints to account for