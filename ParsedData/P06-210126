ample of only 1000 training sentences.
    We then trained the vector 0, used to combine the experts, to minimize the number of labeled dependency attachment errors on a 200-sentence development set.
    Optimization proceeded over lists of the 200-best parses of each sentence produced by a joint decoder using the 10 experts.
    Evaluating on labeled dependency accuracy on 200 test sentences for each language, we see that minimum error and annealed minimum risk training are much closer than for MT.
    For Bulgarian and Dutch, they are statistically indistinguishable using a paired-sample permutations test with 1000 replications.
    Indeed, on Dutch, all three optimization procedures produce indistinguishable results.
    On Slovenian, annealed minimum risk training does show a significant improvement over the other two methods.
    Overall, however, the results for this task are mediocre.
    We are still working on improving the underlying experts.
  
  
    We have seen that annealed minimum risk trainin