iminate the quirks, and hence errors, that are due to the bias of one particular learner.
    However, there is also a way to make better use of the differences: we can create an arbiter effect.
    We can train a second-level classifier to select its output on the basis of the patterns of co-occurrence of the outputs of the various classifiers.
    In this way, we not only counter the bias of each component, but actually exploit it in the identification of the correct output.
    This method even admits the possibility of correcting collective errors.
    The hypothesis is that both types of approaches can yield a more accurate model from the same training data than the most accurate component of the combination, and that given enough training data the arbiter type of method will be able to outperform the gang type.'
    In the machine learning literature there has been much interest recently in the theoretical aspects of classifier combination, both of the gang effect type and of the arbiter type (see Secti