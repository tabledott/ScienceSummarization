he head word itself, wh: lAwmicm,tm,th,wh), e.g.
    Finally, word features, fm, for modifiers are predicted based on the modifier, cm, the partof-speech tag of the modifier word , t&#8222;&#8222; the part-of-speech tag of the head word th, the head word itself, wh, and whether or not the modifier head word, w&#8222;&#8222; is known or unknown.
    The probability of a complete tree is the product of the probabilities of generating each element in the tree.
    If we generalize the tree components (constituent labels, words, tags, etc.) and treat them all as simply elements, e, and treat all the conditioning factors as the history, h, we can write:
  
  
    Maximum likelihood estimates for the model probabilities can be obtained by observing frequencies in the training corpus.
    However, because these estimates are too sparse to be relied upon, we use interpolated estimates consisting of mixtures of successively lowerorder estimates (as in Placeway et al. 1993).
    For modifier constituents, the mixture c