 a batch size of 15 and we allowed twenty passes through the data.3 The length 40 models had a batch size of 30 and we allowed ten passes through the data.
    We used development data to decide when the models had converged.
    Additionally, we provide generative numbers for training on the entire PTB to give a sense of how much performance suffered from the reduced training data (generative-all in Table 4).
    The full results for WSJ15 are shown in Table 3 and for WSJ40 are shown in Table 4.
    The WSJ15 models were each trained on a single Dual-Core AMD OpteronTM using three gigabytes of RAM and no parallelization.
    The discriminatively trained generative model (discriminative in Table 3) took approximately 12 minutes per pass through the data, while the feature-based model (feature-based in Table 3) took 35 minutes per pass through the data.
    The feature-based model with the relaxed grammar (relaxed in Table 3) took about four times as long as the regular feature-based model.
    The discriminat