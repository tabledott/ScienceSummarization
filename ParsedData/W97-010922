data.
    Therefore, we relaxed the complete homogeneity condition by terminating the expansion when more than 77% of the examples in the set belonged to the same class (the value of 77% was set experimentally as it provided the best classification results).
    If the set T is still heterogeneous and there are no more attribute values to divide with, the tree is terminated and the leaf is marked by the majority class of the node.
    2.
    We consider the most informative attribute to be the one which splits the set T into the most homogenous subsets, i.e. subsets with either a high percentage of samples with adjectival attachments and a low percentage of adverbial ones, or vice-versa.
    The optimal split would be such that all the subsets would contain only samples of one attachment type.
    For each attribute A, we split the set into subsets, each associated with attribute value Aw and containing samples which were unifiable with value Aw (belong to the same WordNet class).
    Then, we calculate the o