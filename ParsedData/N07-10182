 any value of ?, but computing this may not be tractable analytically or numerically.
			For this reason a variety of methods have been developed to support approximate Bayesian inference.
			One of the most popular methods is Markov chain Monte Carlo(MCMC), in which a Markov chain is used to sam ple from the posterior distribution.
			This paper presents two new MCMC algorithms for inferring the posterior distribution over parses and rule probabilities given a corpus of strings.
			The first algorithm is a component-wise Gibbs samplerwhich is very similar in spirit to the EM algorithm, drawing parse trees conditioned on the current parameter values and then sampling the param eters conditioned on the current set of parse trees.
			The second algorithm is a component-wise Hastingssampler that ?collapses?
			the probabilistic model, in tegrating over the rule probabilities of the PCFG,with the goal of speeding convergence.
			Both algo 139rithms use an efficient dynamic programming tech nique to sample parse t