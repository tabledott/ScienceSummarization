nt data; and section 23 was for evaluation.
    After each pass over the training data, the averaged perceptron model was scored on the development data, and the best performing model was used for test evaluation.
    For this paper, we used POS tags that were provided either by the Treebank itself (gold standard tags) or by the perceptron POS tagger3 presented in Collins (2002).
    The former gives us an upper bound on the improvement that we might expect if we integrated the POS tagging with the parsing.
    Table 3 shows results on section 23, when either goldstandard or POS-tagger tags are provided to the parser4.
    With the base features, the generative model outperforms the perceptron parser by between a half and one point, but with the additional punctuation features, the perceptron model matches the generative model performance.
    Of course, using the generative model and using the perceptron algorithm are not necessarily mutually exclusive.
    Another training scenario would be to include the g