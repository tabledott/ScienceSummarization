s directly encode linguistic knowledge.
    Typically, these models extract rules using parse trees from both or either side(s) of the bitext.
    The former case, with trees on both sides, is often called tree-to-tree models; while the latter case, with trees on either source or target side, include both treeto-string and string-to-tree models (see Table 1).
    Leveraging from structural and linguistic information from parse trees, these models are believed to be better than their phrase-based counterparts in tree-to-string string-to-tree handling non-local reorderings, and have achieved promising translation results.1 However, these systems suffer from a major limitation, that the rule extractor only uses 1-best parse tree(s), which adversely affects the rule set quality due to parsing errors.
    To make things worse, modern statistical parsers are often trained on domains quite different from those used in MT.
    By contrast, formally syntax-based models (Chiang, 2005) do not rely on parse trees, yet us