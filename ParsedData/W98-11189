cause the &amp;quot;AllCap&amp;quot; feature would take precedence on &amp;quot;IBM&amp;quot; and an &amp;quot;Initial-and-internal-cap&amp;quot; feature would take precedence on &amp;quot;ValuJet&amp;quot;.
    To create a lexical history view, the tokens at w-2 &#8226; &#8226; &#8226; w2 are compared with a vocabulary and their vocabulary indices are recorded.
    For a given training corpus. we define the vocabulary to be all tokens with a count of three or more.
    Words not found in the vocabulary are assigned a distinguished &amp;quot;Unknown&amp;quot; index.
    Lexical feature example: A more subtle feature picked up by MENE: preceding word is &amp;quot;to&amp;quot; and future is &amp;quot;location_unique&amp;quot;.
    Given the domain of the MUC-7 training data (aviation disasters), &amp;quot;to&amp;quot; is a weak indicator, but a real one.
    This is an example of a feature which MENE can make use of but which the constructor of a handcoded system would probably regard as too risky to incorporat