in Figure 2 to each word in the sentence (for simplicity, we assume that the noun phrases are generated here as a single word).
    We use a tool described in (Xia et al., 2000) to convert the Penn Treebank into this representation.
    Combining the trees together by rewriting nodes as trees (explained in Section 2.1) gives us the parse tree in Figure 1.
    A history of the bi-lexical dependencies that define the probability model used to construct the parse is shown in Figure 3.
    This history is called the derivation tree.
    In addition, as a byproduct of this kind of representation we obtain more than the phrase structure of each sentence.
    We also produce a more embellished parse in which phenomena such as predicate-argument structure, subcategorization and movement are given a probabilisA stochastic LTAG derivation proceeds as follows (Schabes, 1992; Resnik, 1992).
    An initial tree is selected with probability Pinit and other trees selected by words in the sentence are combined using the oper