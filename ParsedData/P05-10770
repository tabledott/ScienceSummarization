
  Randomized Algorithms And NLP: Using Locality Sensitive Hash Functions For High Speed Noun Clustering
  
    In this paper, we explore the power of randomized algorithm to address the challenge of working with very large amounts of data.
    We apply these algorithms to generate noun similarity lists from 70 million pages.
    We reduce the running time from quadratic to practically linear in the number of elements to be computed.
  
  
    In the last decade, the field of Natural Language Processing (NLP), has seen a surge in the use of corpus motivated techniques.
    Several NLP systems are modeled based on empirical data and have had varying degrees of success.
    Of late, however, corpusbased techniques seem to have reached a plateau in performance.
    Three possible areas for future research investigation to overcoming this plateau include: The above listing may not be exhaustive, but it is probably not a bad bet to work in one of the above directions.
    In this paper, we investigate the first tw