
  Guided Learning for Bidirectional Sequence Classification
  
    In this paper, we propose guided learning, a new learning framework for bidirectional sequence classification.
    The tasks of learning the order of inference and training the local classifier are dynamically incorporated into a single Perceptron like learning algorithm.
    We apply this novel learning algorithm to POS tagging.
    It obtains an error rate of 2.67% on the standard PTB test set, which represents 3.3% relative error reduction over the previous best result on the same data set, while using fewer features.
  
  
    Many NLP tasks can be modeled as a sequence classification problem, such as POS tagging, chunking, and incremental parsing.
    A traditional method to solve this problem is to decompose the whole task into a set of individual tasks for each token in the input sequence, and solve these small tasks in a fixed order, usually from left to right.
    In this way, the output of the previous small tasks can be used as the