 of times that a is mentioned.
    We also observe that the position of a pronoun in a story influences the mention count of its referent.
    In other words, the nearer the end of the story a pronoun occurs, the more probable it is that its referent has been mentioned several times.
    We measure position by the sentence number, j.
    The method to compute this probability is: (We omitted j from equations (1-7) to reduce the notational load.)
    After collecting the statistics on the training examples, we run the program on the test data.
    For any pronoun we collect n(= 15 in the experiment) candidate antecedents proposed by Hobbs' algorithm.
    It is quite possible that a word appears in the test data that the program never saw in the training data and fow which it hence has no P(plwo) probability.
    In this case I wain the antecedent for p I we simply use the prior probability of the pronoun P(p).
    From the parser project mentioned earlier, we obtain the probability P(walhl Finally, we extract 