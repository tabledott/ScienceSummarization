 accuracies when half of the data set is used (1,000 pairwise rankings).
    This is encouraging, because for some applications (e.g., summarization) large amounts of training data may be not readily available.
    Table 7 illustrates the accuracy of the best performing model Coreference+ Syntax+Salience+ when trained on the Earthquakes corpus and tested on Accidents texts and reversely when trained on the Accident corpus and tested on Earthquakes documents.
    We also illustrate how this model performs when trained and tested on a data set that contains texts from both domains.
    For the latter experiment the training data set was created by randomly sampling 50 Earthquakes and 50 Accidents documents.
    As can be seen from Table 7, the model&#8217;s performance degrades considerably (approximately by 20%) when tested on out-of-domain texts.
    On the positive side, the model&#8217;s out-of-domain performance is better than chance (i.e., 50%).
    Furthermore, once the model is trained on data represent