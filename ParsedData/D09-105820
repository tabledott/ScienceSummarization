 regularization constant, and the Dirichlet prior for the generative models.
    We selected a fixed value q = 2, which was found to work well in preliminary experiments.4 The value of C was chosen to optimize performance on development data.
    Note that C for supervised SCMs were also tuned on development data.
    For the two-stage SS-SCM for incorporating second-order parsing model, we have additional one tunable parameter B shown in Eq.
    8.
    This was also chosen by the value that provided the best performance on development data.
    In addition to providing results for models trained on the full training sets, we also performed experiments with smaller labeled training sets.
    These training sets were either created through random sampling or by using a predefined subset of document IDs from the labeled training data.
  
  
    Table 3 gives results for the SS-SCM method under various configurations: for first and secondorder parsing models, with and without the cluster features of (Koo et al.,