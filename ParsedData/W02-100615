) combining all four knowledge sources with feature selection (ix) combining all four knowledge sources without feature selection.
    SVM is only capable of handling binary class problems.
    The usual practice to deal with multiclass problems is to build one binary classifier per output class (denoted &#8220;1-per-class&#8221;).
    The original AdaBoost, Naive Bayes, and decision tree algoalgorithm is significantly better.
    &#8220; &#8221;) correspond to the p-value , , and respectively.
    &#8220; &#8221; or &#8220; &#8221; means our rithms can already handle multi-class problems, and we denote runs using the original AdB, NB, and DT algorithms as &#8220;normal&#8221; in Table 2 and Table 3.
    Accuracy for each word task can be measured by recall (r) or precision (p), defined by: no. of test instances correctly labeled no. of test instances in word task no. of test instances correctly labeled no. of test instances output in word task Recall is very close (but not always identical) to precision for 