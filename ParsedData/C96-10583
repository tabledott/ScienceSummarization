heses abou(.
  (,he probability space underlying seHl]ence structure.
  We il]ustrate how each hypothesis is (:xl)ressed in a depemteney framework, and how each can be used to guide our parser toward its favored so- lution.
  Finally, we point to experimental resul(;s that compare the three hypotheses parsing per- formance on sentences fi:om the Wall ,btreel dour- hal.  ]
  he parser is trained on an annol,ated corpus; no hand-written grammar  is required.
  2 Probabilistic Dependencies It cannot be emphasized too strongly that a gram- marital rcprcsentalion (de4)endency parses, tag se- quen(-es, phrase-structure trees) does not entail any particular probability model.
  In principle, one couht model the distribution of dependency l)arses l()ur novel parsing algorithm a/so rescues depen dency from certain criticisins: "l)ependency granl- mars .
  .are not lexicM, and (as far ~ as we know) lacl( a parsing algorithm of efficiency compara.ble to link grammars."
  (LMferty et ;LI., 1992, p. 3) 340 in any uuml)er 