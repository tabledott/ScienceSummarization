 dimensions by projecting yd into the principal component space, but this did not help text regression.
    K-Nearest Neighbors Linear regression is a poor model for the multimodal density of human populations.
    As an alternative baseline, we applied supervised K-nearest neighbors to predict the location yd as the average of the positions of the K most similar authors in the training set.
    We computed termfrequency inverse-document frequency features and applied cosine similarity over their first 30 principal components to find the neighbors.
    The choices of principal components, IDF weighting, and neighborhood size K = 20 were tuned on the development set.
    Our principle error metrics are the mean and median distance between the predicted and true location in kilometers.9 Because the distance error may be difficult to interpret, we also report accuracy of classification by state and by region of the United States.
    Our data includes the 48 contiguous states plus the District of Columbia; the U