 as the contexts are more likely to use similar sets of words that in turn are selected from a large feature collection.
    Nearly all of the experiments carried out with the 6 different methods perform better than the majority sense in the case of the mix-words.
    This is partially due to the fact that these words have a large number of senses, and therefore have low majority classifiers.
    In addition, recall that this data is created by mixing instances of distinct target words, which leads to a subset of coarse grained (distinct) senses within the data that are easier to discover than the senses of a single word.
    Table 1 shows that the top 3 experiments for each of the mixed-words are all second order vectors (SC).
    We believe that this is due to the sparsity of the feature spaces of this data.
    Since there are so many different senses, the number of first order features that would be required to correctly discriminate them is very high, leading to better results for second order vectors.
 