ller, namely 20.3%.
    A summary of the corpus used in the experiments is given in Table 1.
    Here the term word refers to full-form word as there is no morphological processing involved.
    In some of our experiments we use a domain-specific preprocessing which consists of a list of 803 (for German) and 458 (for English) word-joinings and wordsplittings for word compounds, numbers, dates and proper names.
    To improve the lexicon probabilities and to account for unseen words we added a manually created German-English dictionary with 13 388 entries.
    The classes used were constrained so that all proper names were included in a single class.
    Apart from this, the classes were automatically trained using the described bilingual clustering method.
    For each of the two languages 400 classes were used.
    For the single-word based approach, we used the manual dictionary as well as the preprocessing steps described above.
    Neither the translation model nor the language model used classes in this 