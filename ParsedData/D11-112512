erence vectors, using the sampler template in Figure 4.
    For each source sentence i, the sampler generates F candidate translation pairs hj, j'i, and accepts each pair with probability &#945;i(|g(i,j) &#8722; g(i, j')|).
    Among the accepted pairs, it keeps the &#926; with greatest g differential, and adds their difference vectors to the training data.5 We repeated the scalability study from Section 3, now using our pairwise ranking optimization (hereafter, PRO) approach.
    Throughout all experiments with PRO we choose &#915; = 5000, &#926; = 50, and the following step function &#945; for each &#945;z: 6 We used MegaM III, 2004) as a binary classifier in our contrasting synthetic experiment and of the i.e., with all default settings for binary Figure 3 shows that PRO is able to learn nearly perfectly at all dimensionalities from 10 to 1000.
    As noted previously, though, this is a rather simple task.
    To encourage a disconnect between g and h, and make the synthetic scenario look more like obtaine