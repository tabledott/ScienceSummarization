 Such analysis could be significant in tracking international research trends, where language barriers slow the transfer of ideas.
    Previous work on bilingual topic modeling has focused on machine translation applications, which rely on sentence-aligned parallel translations.
    However, the growth of the internet, and in particular Wikipedia, has made vast corpora of topically comparable texts&#8212;documents that are topically similar but are not direct translations of one another&#8212;considerably more abundant than ever before.
    We argue that topic modeling is both a useful and appropriate tool for leveraging correspondences between semantically comparable documents in multiple different languages.
    In this paper, we use two polylingual corpora to answer various critical questions related to polylingual topic models.
    We employ a set of direct translations, the EuroParl corpus, to evaluate whether PLTM can accurately infer topics when documents genuinely contain the same content.
    We also