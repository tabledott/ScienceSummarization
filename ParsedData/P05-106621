tions to be of equal quality; and 20 translations to be worse under the reordered model.
    Annotator 2 judged 44 translations to be improved by the reordered model; 37 translations to be of equal quality; and 19 translations to be worse under the reordered model.
    Table 2 gives figures indicating agreement rates between the annotators.
    Note that if we only consider preferences where both annotators were in agree'We chose these shorter sentences for human evaluation because in general they include a single clause, which makes human judgements relatively straightforward. ment (and consider all disagreements to fall into the &#8220;equal&#8221; category), then 33 translations improved under the reordering system, and 13 translations became worse.
    Figure 3 shows a random selection of the translations where annotator 1 judged the reordered model to give an improvement; Figure 4 shows examples where the baseline system was preferred by annotator 1.
    We include these examples to give a qualitative im