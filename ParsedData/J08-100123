t considerable latitude is available when specifying the transition types to be included in a feature vector.
    These can be all transitions of a given length (e.g., two or three) or the most frequent transitions within a document collection.
    An example of One of the central research issues in developing entity-based models of coherence is determining what sources of linguistic knowledge are essential for accurate prediction, and how to encode them succinctly in a discourse representation.
    Previous approaches tend to agree on the features of entity distribution related to local coherence&#8212;the disagreement lies in the way these features are modeled.
    Our study of alternative encodings is not a mere duplication of previous efforts (Poesio et al. 2004) that focus on linguistic aspects of parameterization.
    Because we are interested in an automatically constructed model, we have to take into account computational and learning issues when considering alternative representations.
    Therefore,