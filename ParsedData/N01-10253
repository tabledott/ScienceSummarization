ems, we introduce a new type of weighting strategy which are derived from the theoretical basis of the SVMs.
  
  
    Let us define the training samples each of which belongs either to positive or negative class as: is a feature vector of the-th sample represented by an dimensional vector. is the class (positive( ) or negative( ) class) label of theth sample.is the number of the given training samples.
    In the basic SVMs framework, we try to separate the positive and negative samples by a hyperplane expressed as: .
    SVMs find an &#8220;optimal&#8221; hyperplane (i.e. an optimal parameter set for ) which separates the training data into two classes.
    What does &#8220;optimal&#8221; mean?
    In order to define it, we need to consider the margin between two classes.
    Figure 1 illustrates this idea.
    Solid lines show two possible hyperplanes, each of which correctly separates the training data into two classes.
    Two dashed lines parallel to the separating hyperplane indicate the boundaries in 