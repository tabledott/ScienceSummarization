s of the neighboring words into account.
  
  
    Sequential models are common in NER, POS tagging, shallow parsing, etc..
    Most of the work in WSD, instead, has focused on labeling each word individually, possibly revising the assignments of senses at the document level; e.g., following the &#8220;one sense per discourse&#8221; hypothesis (Gale et al., 1992).
    Although it seems reasonable to assume that occurrences of word senses in a sentence can be correlated, hence that structured learning methods could be successful, there has not been much work on sequential WSD.
    Segond et al. (1997) are possibly the first to have applied an HMM tagger to semantic disambiguation.
    Interestingly, to make the method more tractable, they also used the supersense tagset and estimated the model on Semcor.
    By cross-validation they show a marked improvement over the first sense baseline.
    However, in (Segond et al., 1997) the tagset is used differently, by defining equivalence classes of words with the sam