 from NANC, the curves corresponding to higher WSJ weights achieve a higher asymptote.
    Looking at the performance of various weights across sections 1, 22, and 24, we decided that the best combination of training data is to give WSJ a relative weight of 5 and use the first 1,750k reranker-best sentences from NANC.
    Finally, we evaluate our new model on the test section of Wall Street Journal.
    In Table 3, we note that baseline system (i.e. the parser and reranker trained purely on Wall Street Journal) has improved by 0.3% over Charniak and Johnson (2005).
    The 92.1% f-score is the 1.1% absolute improvement mentioned in the abstract.
    The improvement from self-training is significant in both macro and micro tests (p &lt; 10&#8722;5). freranker are the evaluation of the parser and reranking parser on all sentences, respectively.
    &#8220;WSJ + NANC&#8221; represents the system trained on WSJ training (with a relative weight of 5) and 1,750k sentences from the reranker-best list of NANC.
  
  
