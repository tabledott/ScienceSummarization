ion in these systems.
  
  
    The learning algorithm used is a variation of the Winnow update rule incorporated in SNoW (Roth, 1998; Roth and Yih, 2002), a multi-class classifier that is tailored for large scale learning tasks.
    SNoW learns a sparse network of linear functions, in which the targets (argument border predictions or argument type predictions, in this case) are represented as linear functions over a common feature space.
    It improves the basic Winnow multiplicative update rule with a regularization term, which has the effect of trying to separate the data with a large margin separator (Grove and Roth, 2001; Hang et al., 2002) and voted (averaged) weight vector (Freund and Schapire, 1999).
    Softmax function (Bishop, 1995) is used to convert raw activation to conditional probabilities.
    If there are n classes and the raw activation of class i is acti, the posterior estimation for class i is each In summary, training used both full and partial syntactic information as described in Sect