
			The greatest challenge we are facing is the reduction of ?false flags?, i.e. flags where both error detection and suggested correction are incorrect.
			Such flags?especially for a non-native speaker?can be confusing, despite the fact that the impact is mitigated by the set of examples which may clarify the picture somewhat and help the users determine that they are dealing with an inappropriate correction.
			In the current system we use a set of carefully crafted heuristic thresholds that are geared towards minimizing false flags on a development set, based on detailed error analysis.
			As with all manually imposed thresholding, this is both a laborious and brittle process where each retraining of a model requires a re-tuning of the heuristics.
			We are currently investigating a learned ranker that combines information from language model and classifiers, using web counts as a supervision signal.
	
	
			We thank Claudia Leacock (Butler Hill Group) for her meticulous analysis of errors and human evalua