dle the output ambiguity, we use static knowledge of how morphemes are combined into a word, such as the four known combinations of the word bclm, the two possible combinations of the word hn`im, and their possible tags within the original words.
    Based on this information, we encode the sentence into a structure that represents all the possible &#8220;readings&#8221; of the sentence, according to the possible morpheme combinations of the words, and their possible tags.
    The representation consists of a set of vectors, each vector containing the possible morphemes and their tags for each specific &#8220;time&#8221; (sequential position within the morpheme expansion of the words of the sentence).
    A morpheme is represented by a tuple (symbol, state, prev, next), where symbol denotes a morpheme, state is one possible tag for this morpheme, prev and next are sets of indexes, denoting the indexes of the morphemes (of the previous and the next vectors) that precede and follow the current morpheme in the o