l number of examples) improved when increasing the number of classifiers, the F-score often decreased.
    For the pattern approach without the tag features the best model consists of a 5-bagged classifier, for the pattern approach with the tag feature a 20-bagged, and finally for the n-gram approach with the tag feature a 10-bagged classifier.
    For the other three runs a single classifier had the best performance.
    When extracting the terms from the test set according to the n-gram approach, the data consisted of 42 159 negative examples, and 3 330 positive examples, thus in total 45 489 examples were classified by the trained model.
    Using this manner of extracting the terms meant that 12.8% of the keywords originally present in the test set were lost.
    To summarise the n-gram approach (see Table 2), without the tag feature it finds on average 4.37 keywords per document, out of originally on average 7.63 manual keywords present in the abstracts.
    However, the price paid for these correct term