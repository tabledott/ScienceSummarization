2?
			= ?start, start, start, start, start?)
			return 1; else return 0; // recursive case P = localClassification(i, ?ti?2, ti?1, ti, ti+1, ti+2?, ?d?i?1, di?1, di, d?i+1?); return maxd?
			i?2 maxdi?3 maxti?3 P?
			bestScoreSub(i+1, ?ti?3, ti?2, ti?1, titi+1?, ?d?i?2, di?2, di?1, d?i?, ?di?3, d?i?1?); } Figure 3: Pseudo-code for bidirectional inference for the second-order conditional markov models.
			di is the direction of the edge between ti and ti+1.
			d?i is the direction of the edge between ti?1 and ti+1.
			We omit the localClassification function because it is the obvious extension of that for the first-order case.
			is extremely simple and significantly more efficient than full bidirectional decoding.Instead of enumerating all possible decomposition structures, the algorithm determines the struc ture by adopting the easiest-first strategy.
			The whole decoding algorithm is given below.
			1.
			Find the ?easiest?
			word to tag..
			2.
			Tag the word..
			We assume in this paper that the ?easie