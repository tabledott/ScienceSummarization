ance gains seem possible.
    We adopt a maximum entropy approach because it allows the inclusion of diverse sources of information without causing fragmentation and without necessarily assuming independence between the predictors.
    A maximum entropy approach has been applied to partof-speech tagging before (Ratnaparkhi 1996), but the approach's ability to incorporate nonlocal and non-HMM-tagger-type evidence has not been fully explored.
    This paper describes the models that we developed and the experiments we performed to evaluate them.
  
  
    We started with a maximum entropy based tagger that uses features very similar to the ones proposed in Ratnaparkhi (1996).
    The tagger learns a loglinear conditional probability model from tagged text, using a maximum entropy method.
    The model assigns a probability for every tag t in the set T of possible tags given a word and its context h, which is usually defined as the sequence of several words and tags preceding the word.
    This model can be used