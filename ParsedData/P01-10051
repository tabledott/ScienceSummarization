blems throughout the last decade.
    A large percentage of papers published in this area involve comparisons of different learning approaches trained and tested with commonly used corpora.
    While the amount of available online text has been increasing at a dramatic rate, the size of training corpora typically used for learning has not.
    In part, this is due to the standardization of data sets used within the field, as well as the potentially large cost of annotating data for those learning methods that rely on labeled text.
    The empirical NLP community has put substantial effort into evaluating performance of a large number of machine learning methods over fixed, and relatively small, data sets.
    Yet since we now have access to significantly more data, one has to wonder what conclusions that have been drawn on small data sets may carry over when these learning methods are trained using much larger corpora.
    In this paper, we present a study of the effects of data size on machine learning for n