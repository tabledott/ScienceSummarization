but also improve the performance over HMMs and MEMMs.
  
  
    Conditional random fields (CRFs) (Lafferty et al., 2001) applied to sequential labeling problems are conditional models, trained to discriminate the correct sequence from all other candidate sequences without making independence assumption for features.
    They are considered to be the state-of-the-art framework to date.
    Empirical successes with CRFs have been reported recently in part-of-speech tagging (Lafferty et al., 2001), shallow parsing (Sha and Pereira, 2003), named entity recognition (McCallum and Li, 2003), Chinese word segmentation (Peng et al., 2004), and Information Extraction (Pinto et al., 2003; Peng and McCallum, 2004).
    Previous applications with CRFs assumed that observation sequence (e.g. word) boundaries are fixed, and the main focus was to predict label sequence (e.g. part-of-speech).
    However, word boundaries are not clear in non-segmented languages.
    One has to identify word segmentation as well as to predict 