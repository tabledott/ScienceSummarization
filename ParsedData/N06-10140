
  Alignment By Agreement
  
    We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models.
    Compared to the standard practice of intersecting predictions of independently-trained models, joint training provides a 32% reduction in AER.
    Moreover, a simple and efficient pair of HMM aligners provides a 29% reduction in AER over symmetrized IBM model 4 predictions.
  
  
    Word alignment is an important component of a complete statistical machine translation pipeline (Koehn et al., 2003).
    The classic approaches to unsupervised word alignment are based on IBM models 1&#8211;5 (Brown et al., 1994) and the HMM model (Ney and Vogel, 1996) (see Och and Ney (2003) for a systematic comparison).
    One can classify these six models into two groups: sequence-based models (models 1, 2, and HMM) and fertility-based models (models 3, 4, and 5).1 Whereas the sequence-based