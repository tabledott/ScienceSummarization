n four iterations of Model 4.
    4.
    The discriminatively reranked extended model outperforms four iterations of Model 4 in both cases with the best heuristic symmetrization, but some of the gain is lost as we are optimizing the F-measure of the 1-to-many alignments rather than the F-measure of the many-to-many alignments directly.
    Overall, the results show our approach is better than or competitive with running four iterations of unsupervised Model 4 training.
    Brown et al. (1993) introduced operations defining a hillclimbing search appropriate for Model 4.
    Their search starts with a complete hypothesis and exhaustively applies two operations to it, selecting the best improved hypothesis it can find (or terminating if no improved hypothesis is found).
    This search makes many search errors2.
    We developed a new alignment algorithm to reduce search errors: The first two improvements are related to the well-known Tabu local search algorithm (Glover, 2A search error in a word aligner is a fa