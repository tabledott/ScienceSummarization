ional experiments examining various aspects of the algorithm.
    Table 1 shows results for previous work on the various data sets, and results for an arc-factored model with pure MST decoding with our features.
    (We use the acronym UAS (unlabeled attachment score) for dependency accuracy.)
    We also show results for the bigram-sibling and grandparent/sibling (G+S) models under dual decomposition.
    Both the bigramsibling and G+S models show large improvements over the arc-factored approach; they also compare favorably to previous work&#8212;for example the G+S model gives better results than all results reported in the CoNLL-X shared task, on all languages.
    Note that we use different feature sets from both Martins et al. (2009) and Smith and Eisner (2008).
    Next, we consider how often our algorithms return an exact solution to the original optimization problem, with a certificate&#8212;i.e., how often the algorithms in Figures 1 and 2 terminate with y(k) = z(k) for some value of k &lt; 5000 (an