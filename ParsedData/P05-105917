runed LITG against the unlexicalized ITG.
    A separate development set of hand-aligned sentence pairs was used to control overfitting.
    The subset of up to 15 words in both languages was used for cross-validating in the first experiment.
    The subset of up to 25 words in both languages was used for the same purpose in the second experiment.
    Table 1 compares results using the full (unpruned) model of unlexicalized ITG with the full model of lexicalized ITG.
    The two models were initialized from uniform distributions for all rules and were trained until AER began to rise on our held-out cross-validation data, which turned out to be 4 iterations for ITG and 3 iterations for LITG.
    The results from the second experiment are shown in Table 2.
    The performance of the full model of unlexicalized ITG is compared with the pruned model of lexicalized ITG using more training data and evaluation data.
    Under the same check condition, we trained ITG for 3 iterations and the pruned LITG for 1 iterati