sibly reranked 6 systems - marked in bold in the table - which did not assign a sense to all word instances in the test set).
			Comparedto previous results on fine-grained evaluation exer cises (Edmonds and Kilgarriff, 2002; Snyder and Palmer, 2004), the systems?
			results are much higher.
			On the other hand, the difference in performancebetween the MFS baseline and state-of-the-art sys tems (around 5%) on coarse-grained disambiguationis comparable to that of the Senseval-3 all-words ex ercise.
			However, given the novelty of the task webelieve that systems can achieve even better perfor 32 System A P R F1 NUS-PT 100.0 82.50 82.50 82.50 NUS-ML 100.0 81.58 81.58 81.58 LCC-WSD 100.0 81.45 81.45 81.45 GPLSI 100.0 79.55 79.55 79.55 BLMFS 100.0 78.89 78.89 78.89 UPV-WSD 100.0 78.63 78.63 78.63 TKB-UO 100.0 70.21 70.21 70.21 PU-BCD 90.1 69.72 62.80 66.08 RACAI-SYNWSD 100.0 65.71 65.71 65.71 SUSSX-FR 72.8 71.73 52.23 60.44 USYD 95.3 58.79 56.02 57.37 UOFL 92.7 52.59 48.74 50.60 SUSSX-C-WD 72.8 54.54 39.71 45.96