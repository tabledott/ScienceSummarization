 by 10% to 87.4%.
    3) 4 f is impressive too with another 5.5% performance improvement.
    4) However, 3 f contributes only further 1.2% to the performance.
    This may be because information included in 3 f has already been captured by 2 f and f4 .
    Actually, the experiments show that the contribution of 3 f comes from where there is no explicit indicator information in/around the NE and there is no reference to other NEs in the macro context of the document.
    The NEs contributed by 3 f are always well-known ones, e.g.
    Microsoft, IBM and Bach (a composer), which are introduced in texts without much helpful context.
  
  
    This paper proposes a HMM in that a new generative model, based on the mutual information independence assumption (2-3) instead of the conditional probability independence assumption (I-1) after Bayes' rule, is applied.
    Moreover, it shows that the HMM-based chunk tagger can effectively apply and integrate four different kinds of sub-features, ranging from internal word 