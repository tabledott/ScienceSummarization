the better modeling of relatedness (as opposed to similarity).
    Distributional similarities have proven to be competitive when compared to knowledgebased methods, with context windows being better for similarity and bag of words for relatedness.
    Distributional similarity was effectively used to cover out-of-vocabulary items in the WordNet-based measure providing our best unsupervised results.
    The complementarity of our methods was exploited by a supervised learner, producing the best results so far for RG and WordSim353.
    Our results include confidence values, which, surprisingly, were not included in most previous work, and show that many results over RG and WordSim353 are indistinguishable.
    The algorithm for WordNet-base similarity and the necessary resources are publicly available8.
    This work pioneers cross-lingual extension and evaluation of both distributional and WordNet-based measures.
    We have shown that closely aligned wordnets provide a natural and effective way to compute c