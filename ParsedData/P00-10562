uced alignment.
    This allows an automatic evaluation, once a reference alignment has been produced.
    In addition, it results in a very precise and reliable evaluation criterion that is well suited to assess various design decisions in modeling and training of statistical alignment models.
  
  
    In this paper we use the models IBM-1 to IBM-5 from (Brown et al., 1993b) and the Hidden-Markov alignment model (HMM) from (Vogel et al., 1996; Och and Ney, 2000).
    All these models provide different decompositions of the probability Pr(fil ,41e{).
    The alignment a may contain alignments ai = 0 with the 'empty' word co to account for French words that are not aligned to any English word.
    All models include lexicon parameters p(f le) and additional parameters describing the probability of an alignment.
    We now sketch the structure of the six models: cient as they waste probability mass on non-strings.
    IBM-5 is a reformulation of IBM-4 with a suitably refined alignment model in order to avoid d