 no such network training has been completed.
    The discriminative model does not need to calculate word predictions, so it was feasible to train networks for the 11,993 word vocabulary (&#8220;DSSN-Freq&gt;5&#8221;).
    Previous results (Henderson, 2003a) indicate that this vocabulary size performs better than the smaller ones, as would be expected.
    For the networks trained with the discriminative optimization criteria and the generative probability model, we trained networks for the 508 (&#8220;DGSSN-Freq&gt;200&#8221;) and 4215 (&#8220;DGSSNFreq&gt;20&#8221;) word vocabularies.
    For this training, we need to select a small set of the most probable incorrect parses.
    When we tried using only the network being trained to choose these top parses, training times were very long and the resulting networks did not outperform their generative counterparts.
    In the experiments reported here, we provided the training with a list of the top 20 parses found by a network of the same type which had been 