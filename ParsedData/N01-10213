w, given that a sequence of words has been seen.
    Given some lexicon of all possible words, a language model assigns a probability to every string of words from the lexicon.
    This defines a probabilistic language (Grenander, 1967) (Booth and Thompson, 1973) (Soule, 1974) (Wetherell, 1980).
    A language model helps a speech recognizer focus its attention on words that are likely continuations of what it has recognized so far.
    This is typically done using conditional probabilities of the form the probability that the nth word will actually be wn given that the words leading up to the nth have been w1, w2, ... wn&#8722;1.
    Given some finite lexicon, the probability of each possible outcome for Wn can be estimated using that outcome&#8217;s relative frequency in a sample.
    Traditional language models used for speech are ngram models, in which n &#8722; 1 words of history serve as the basis for predicting the nth word.
    Such models do not have any notion of hierarchical syntactic structure, ex