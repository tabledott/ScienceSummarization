is easy for the complete data problem; the E-step is not necessarily so.
    However, for decomposable models, such as the Naive Bayes, the E-step simplifies to the calculation of the expected counts in the marginal distributions of interdependent features, where the expectation is with respect to 0.
    The M-step simplifies to the calculation of new parameter estimates from these counts.
    Further, these expected counts can be calculated by multiplying the sample size N by the probability of the complete data within each marginal distribution given 0 and the observed data within each marginal Yrn.
    This simplifies to: where count i is the current estimate of the expected count and P(Sm1Y,n) is formulated using 0.
    For the Naive Bayes model with 3 observable features A, B, C and an unobservable classification feature 5, where 0 = {P(a, s), P(b, s), P(c, s), P(s)} , the E and M-steps are: where s, a, b, and c denote specific values of S, A, B, and C respectively, and P(s1b) and P(s1c) are defined anal