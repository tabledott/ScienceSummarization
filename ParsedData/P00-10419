he overall score used in ranking can be obtained as a weighted combination of the content and structure model log probabilities.
    Cross-validation is used to learn weights , and for a particular document genre.
    To generate a summary, it is necessary to find a sequence of words that maximizes the probability, under the content selection and summary structure models, that it was generated from the document to be summarized.
    In the simplest, zerolevel model that we have discussed, since each summary term is selected independently, and the summary structure model is first order Markov, it is possible to use Viterbi beam search (Forney, 1973) to efficiently find a near-optimal summary.
    2 Other statistical models might require the use of a different heuristic search algorithm.
    An example of the results of a search for candidates of various lengths is shown in Figure 1.
    It shows the set of headlines generated by the system when run against a real news story discussing Apple Computer&#8217;s de