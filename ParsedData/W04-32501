ears.
    Instead of reporting human judgment of translation quality, researchers now rely on automatic measures, most notably the BLEU score, which measures n-gram overlap with reference translations.
    Since it has been shown that the BLEU score correlates with human judgment, an improvement in BLEU is taken as evidence for improvement in translation quality.
    Building the tools for any translation system involves many iterations of changes and performance testing.
    It is important to have a method at hand that gives us assurances that the observed increase in the test score on a test set reflects true improvement in system quality.
    In other words, we need to be able to gauge, if the increase in score is statistically significant.
    Since complex metrics such as BLEU do not lend themselves to an analytical technique for assessing statistical significance, we propose bootstrap resampling methods.
    We also provide empirical evidence that the estimated significance levels are accurate by compa