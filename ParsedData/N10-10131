 language processing tasks.
    The standard empirical approach to this task exploits the distributional hypothesis, i.e. that similar words appear in similar contexts (Curran and Moens, 2002; Lin and Pantel, 2002; Pereira et al., 1993).
    Traditionally, word types are represented by a single vector of contextual features derived from cooccurrence information, and semantic similarity is computed using some measure of vector distance (Lee, 1999; Lowe, 2001).
    However, due to homonymy and polysemy, capturing the semantics of a word with a single vector is problematic.
    For example, the word club is similar to both bat and association, which are not at all similar to each other.
    Word meaning violates the triangle inequality when viewed at the level of word types, posing a problem for vector-space models (Tversky and Gati, 1982).
    A single &#8220;prototype&#8221; vector is simply incapable of capturing phenomena such as homonymy and polysemy.
    Also, most vector-space models are context independe