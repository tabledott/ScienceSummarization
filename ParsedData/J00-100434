gesting accuracy can be further improved by increasing the size of our training sets, though also suggesting that the learning curve is relatively shallow beyond the current size of corpus.
  
  
    Formalisms for finite-state and context-free transduction have a long history (e.g., Lewis and Stearns 1968; Aho and Ullman 1972), and such formalisms have been applied to the machine translation problem, both in the finite-state case (e.g., Vilar et al. 1996) and the context-free case (e.g., Wu 1997).
    In this paper we have added to this line of research by providing a method for automatically constructing fully lexicalized statistical dependency transduction models from training examples.
    Automatically training a translation system brings important benefits in terms of maintainability, robustness, and reducing expert coding effort as compared with traditional rule-based translation systems (a number of which are described in Hutchins and Somers [1992]).
    The reduction of effort results, in large part,