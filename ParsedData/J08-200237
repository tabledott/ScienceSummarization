hese results, the constraint that argument phrases do not overlap was enforced using the algorithm presented in Section 4.2.
    The most direct way to use trained local identification and classification models in testing is to select a labeling L of the parse tree that maximizes the product of the Performance of local classifiers on ALL arguments, using the features in Figure 3 only and using the additional local features.
    Using gold standard parse trees on Section 23. probabilities according to the two models, as in Equation (1).
    Because these models are local, this is equivalent to independently maximizing the product of the probabilities of the two models for the label li of each parse tree node ni as shown below in Equation (2).
    A problem with this approach is that a maximizing labeling of the nodes could possibly violate the constraint that argument nodes should not overlap with each other.
    Therefore, to produce a consistent set of arguments with local classifiers, we must have a way of 