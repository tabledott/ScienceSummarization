ve story.
    We assume that each sentence pair in our corpus is generated by the following stochastic process: phrases , according to the distribution , whereandeach contain at least one word.
    For simplicity, we initially assume that the bag of concepts and the ordering of the generated phrases are modeled by uniform distributions.
    We do not assume that is a hidden variable that generates the pair , but rather that .
    Under these assumptions, it follows that the probability of generating a sentence pair (E, F) using concepts is given by the product of all phrase-tophrase translation probabilities, that yield bags of phrases that can be ordered linearly so as to obtain the sentences E and F. For example, the sentence pair &#8220;a b c&#8221; &#8212; &#8220;x y&#8221; can be generated using two concepts, (&#8220;a b&#8221; : &#8220;y&#8221;) and (&#8220;c&#8221; : &#8220;x&#8221;); or one concept, (&#8220;a b c&#8221; : &#8220;x y&#8221;), because in both cases the phrases in each language can be ar