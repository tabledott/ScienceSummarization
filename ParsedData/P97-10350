
  PARADISE: A Framework For Evaluating Spoken Dialogue Agents
  
    This paper presents PARADISE (PARAdigm for DIalogue System Evaluation), a general framework for evaluating spoken rlialogue agents.
    The framework decouples task requirements from an agent's dialogue behaviors, supports comparisons among dialogue strategies, enables the calculation of performance over subdialogues and whole dialogues, specifies the relative contribution of various factors to performance, and makes it possible to compare agents performing different tasks by normalizing for task complexity.
  
  
    Recent advances in dialogue modeling, speech recognition, and natural language processing have made it possible to build spoken dialogue agents for a wide variety of applications.'
    Potential benefits of such agents include remote or hands-free access, ease of use, naturalness, and greater efficiency of interaction.
    However, a critical obstacle to progress in this area is the lack of a general framework for evaluating a