ively.
    230, 000 sentences (;z:&#65533; 5 million words) had been processed and were used as training material by the taggers.
    The other experiment used our agreement-based co-training approach (50 seed sentences, cache size of 1, 000 sentences, exploring at most 10 subsets in the maximisation process per round).
    The agreement rate was 98%, with performance levels of 86.0% and 85.9% for both taggers.
    124, 000 sentences had been processed, of which 30, 000 labelled sentences were selected for training TNT and 44, 000 labelled sentences were selected for training C&amp;C.
    Co-training using this much larger amount of unlabelled material did improve our previously mentioned results, but not by a large margin.
    It is interesting to consider what happens when one view is initially much more accurate than the other view.
    We trained one of the taggers on much more labelled seed data than the other, to see how this affects the co-training process.
    Both taggers were initialised with either