lation/system, an automatic evaluation will do the same with high probability.
    This enables us to use an automatic evaluation procedure in place of human assessments to compare system performance, as in the NIST MT evaluations (NIST 2002).
    The second criterion is critical in interpreting the significance of automatic evaluation results.
    For example, if an automatic evaluation shows there is a significant difference between run A and run B at &#945; = 0.05 using the z-test (t-test or bootstrap resampling), how does this translate to &amp;quot;real&amp;quot; significance, i.e. the statistical significance in a human assessment of run A and run B?
    Ideally, we would like there to be a positive correlation between them.
    If this can be asserted with strong reliability (high recall and precision), then we can use the automatic evaluation to assist system development and to be reasonably sure that we have made progress.
    As stated in Section 3, direct application of BLEU on the DUC 2001 data sh