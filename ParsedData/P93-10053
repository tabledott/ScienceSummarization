 &#8212;&#9632; NP1 prevent the probabilistic model from allowing the NP1 constituent to interact with the VP rule which is the functional parent of NP1.
    When the two parents are identical as it often happens, the duplicate information will be ignored.
    However, when they differ, the decision tree will select that parental context which best resolves ambiguities.
    Figure 3 shows an example of the representation of a history in HBG for the prepositional phrase &amp;quot;with a list.&amp;quot; In this example, the immediate parent of the Ni node is the NBAR4 node and the functional parent of Ni is the PP1 node.
    Results We compared the performance of HBG to the &amp;quot;broad-coverage&amp;quot; probabilistic context-free gram- P-CFG.
    The of the grammar is 90% on test sentences of 7 to 17 words.
    The of P-CFG is 60% on the same test corpus of 760 sentences used in our experiments.
    On the same test sentences, the HBG model has a of 75%.
    This is a reduction of 37% in error rate.
    Ac