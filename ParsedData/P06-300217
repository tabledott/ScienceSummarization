nificantly.
    Finnish figures are generally worse than for the other languages, akin to higher baselines.
    The high OOV perplexities for English in experiment TM and TMA can be explained as follows: The smaller the OOV rate gets, the more likely it is that the corresponding words were also OOV in the gold standard tagger.
    A remedy would be to evaluate on hand-tagged data.
    Differences between languages are most obvious when comparing OMA and TM: whereas for English it pays off much more to add ambiguous words than to merge the two partitionings, it is the other way around in the German and Finnish experiments.
    To wrap up: all steps undertaken improve the performance, yet their influence's strength varies.
    As a flavour of our system's output, consider the example in table 4 that has been tagged by our English TMA model: as in the introductory example, &amp;quot;saw&amp;quot; is disambiguated correctly.
    We compare our results to (Freitag, 2004), as most other works use different evaluati