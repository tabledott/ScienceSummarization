alyzer based on (Itai et al., 2006) should cater for a better coverage, and incorporating lexical probabilities learned from a big (unannotated) corpus (cf.
    (Levinger et al., 1995; Goldberg et al., ; Adler et al., 2008)) will make the parser more robust and suitable for use in more realistic scenarios.
    Acknowledgments We thank Meni Adler and Michael Elhadad (BGU) for helpful comments and discussion.
    We further thank Khalil Simaan (ILLCUvA) for his careful advise concerning the formal details of the proposal.
    The work of the first author was supported by the Lynn and William Frankel Center for Computer Sciences.
    The work of the second author as well as collaboration visits to Israel was financed by NWO, grant number 017.001.271.
  

