.
			NEAREST-10 has higher recall (66.3%), but the precision is really low (20.9%).
			Performance of the opinion and source entity classifiers will be discussed in Section 8.SRL baselines Next, we consider two baselines that use a state-of-the-art SRL system (Pun yakanok et al, 2005).
			In many link relations, the opinion expression entity is a verb phrase andthe source entity is in an agent argument posi tion.
			Hence our second baseline, SRL, extracts all verb(V)-agent(A0) frames from the output of the SRL system and provides an upper bound onrecall (59.7%) for systems that use SRL in isola tion for our task.
			A more sophisticated baseline, SRL+CRF-OP, extracts only those V-A0 frames whose verb overlaps with entities extracted by the opinion expression extractor, CRF-OP.
			As shownin table 2, filtering out V-A0 frames that are incompatible with the opinion extractor boosts pre cision to 83.2%, but the F-measure (58.9) is lower than that of NEAREST-1.ILP results The ILP-n system in table 2 de notes the