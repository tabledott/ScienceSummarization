using a reasonable amount of memory and time.
    The claim of this work is that statistics from a large corpus of parsed sentences combined with information-theoretic classification and training algorithms can produce an accurate natural language parser without the aid of a complicated knowledge base or grammar.
    This claim is justified by constructing a parser, called SPATTER (Statistical PATTErn Recognizer), based on very limited linguistic information, and comparing its performance to a state-of-the-art grammar-based parser on a common task.
    It remains to be shown that an accurate broad-coverage parser can improve the performance of a text processing application.
    This will be the subject of future experiments.
    One of the important points of this work is that statistical models of natural language should not be restricted to simple, context-insensitive models.
    In a problem like parsing, where long-distance lexical information is crucial to disambiguate interpretations accurately, local m