sing only informa- tion from the verb phrase in which the attachment occurs.
  We denote the partially parsed verb phrase, i.e., the verb phrase without the attachment decision, as a history h, and the conditional probability of an attachment asp(dlh), where d 6 .
  [0, 1} and corresponds to a noun or verb attachment (respectively).
  The probability model depends on certain features of the whole event (h, d) denoted by fi(h, d).
  An example of a binary-valued feature function is the indicator function that a particular (V, P)  bigram occured along with the attachment decision being V, i.e.
  fprint,on(h, d) is one if and only if the main verb of h is "print", the preposition is "on", and d is "V".
  As discussed in [6], the ME principle leads to a model for p(dlh ) which maximizes the training data log-likelihood, a) log p(dlh), h,d where ~(h, w) is the empirical distribution of the training set, and where p(dlh ) itself is an exponential model: 250 p(dlh) = k 11 eXY(hd) i=0 1 k YI e~f(h"0 d=0 i=0 4.
  Head