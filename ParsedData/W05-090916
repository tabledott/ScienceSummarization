nce-by-sentence basis, rather than on a coarse grained system-by-system basis* The standard metrics &#8212; BLEU and NIST &#8212; were however designed for system level scoring, hence computing sentence level scores using BLEU or the NIST evaluation mechanism is unfair to those algorithms* To provide a point of comparison however, table 1 shows the system level correlation between human judgments and various MT evaluation algorithms and sub components of METEOR over the Chinese portion of the Tides 2003 dataset* Specifically, these correlation figures were obtained as follows: Using each algorithm we computed one score per Chinese system by calculating the aggregate scores produced by that algorithm for that system* We also obtained the overall human judgment for each system by averaging all the human scores for that system's translations* We then computed the Pearson correlation between these system level human judgments and the system level scores for each algorithm; these numbers are presented in table 1* 