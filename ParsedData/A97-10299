,, w_1) Pr((w,f)firs, I NC, NC_,).
    (3.1) The top level model for generating all but the first word in a name-class is Pr((w, NC).
    (3.2) There is also a magical &amp;quot;+end+&amp;quot; word, so that the probability may be computed for any current word to be the final word of its name-class, i.e., Pr((+end+, o the r) I(w, f)find' NC).
    (3.3) As one might imagine, it would be useless to have the first factor in Equation 3.1 be conditioned off of the +end+ word, so the probability is conditioned on the previous real word of the previous name-class, i.e., we compute W-1 = last observed word otherwise NC , = START - OF - SENTENCE (3.4) Note that the above probability is not conditioned on the word-feature of w_1, the intuition of which is that in the cases where the previous word would help the model predict the next name-class, the world feature&#8212;capitalization in particular&#8212;is not important: &amp;quot;Mr.&amp;quot; is a good indicator of the next word beginning the PERSON name-class, regar