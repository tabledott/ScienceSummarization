ins&#8217; models&#8212;have also been implemented in Dyna, the dynamic programming framework used here (Eisner et al., 2004).
  
  
    Combining separately trained systems and then searching for an (ideally) optimal solution is standard practice in statistical continuous speech recognition (Jelinek, 1998) and statistical machine translation (Brown et al., 1990).
    Composition is even more of a staple in finitestate frameworks (Knight and Graehl, 1998).
    Finally, factored models involving parses have been used to guide search.
    Charniak et al. (2003) combine separately trained parse production probabilities with translation probabilities to prune a parse forest hypothesized by the translation model.
    As discussed in &#167;2, Klein and Manning (2002) guide their parser&#8217;s search using a combination of separate unlexicalized PCFG and lexical dependency models.
    The extent to which assumptions about similarity of syntax across languages are empirically valid has received attention in a few pi