nalysis: that the span under consideration might have been drawn directly from the lexicon.
    This option can be added to our grammar by altering the definition of a terminal production to include phrases: A &#8212;* 6/ 1.
    This third option is shown in Figure 2 (c).
    The model implied by this extended grammar is trained using inside-outside and EM.
    Our approach differs from previous attempts to use ITGs for phrasal bitext analysis.
    Wu (1997) used a binary bracketing ITG to segment a sentence while simultaneously word-aligning it to its translation, but the model was trained heuristically with a fixed segmentation.
    Vilar and Vidal (2005) used ITG-like dynamic programming to drive both training and alignment for their recursive translation model, but they employed a conditional model that did not maintain a phrasal lexicon.
    Instead, they scored phrase pairs using IBM Model 1.
    Our phrasal ITG is quite similar to the JPTM.
    Both models are trained with EM, and both employ generativ