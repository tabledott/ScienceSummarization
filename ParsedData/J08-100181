VPs, and average number of subordinate clauses (SBARs).
    We computed average sentence length by measuring the number of tokens per sentence.
    Their semantic features include the average number of syllables per word, and language model perplexity scores.
    A unigram, bigram, and trigram model was estimated for each class, and perplexity scores were used to assess their performance on test data.
    Following Schwarm and Ostendorf (2005) we used information gain to select words that were good class discriminants.
    All remaining words were replaced by their parts of speech.
    The vocabulary thus consisted of 300 words with high information gain and 36 Penn Treebank part-of-speech tags.
    The language models were estimated using maximum likelihood estimation and smoothed with Witten-Bell discounting.
    The language models described in this article were all built using the CMU statistical language modeling toolkit (Clarkson and Rosenfeld 1997).
    Our perplexity scores were six in total (2 classe