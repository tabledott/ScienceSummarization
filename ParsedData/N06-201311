Decoding weight optimization was done on 200 sentences from the 2003 NIST MT evaluation test set.
    We used two different test sets: (a) the 2004 NIST MT evaluation test set (MT04) and (b) the 2005 NIST MT evaluation test set (MT05).
    MT04 is a mix of news, editorials and speeches, whereas MT05, like the training data, is purely news.
    We use the evaluation metric BLEU-4 (Papineni et al., 2001).
    We conducted all possible combinations of schemes and techniques discussed in Section 4 with different training corpus sizes: 1%, 10% and 100%.
    The results of the experiments are summarized in BLEU-4 difference to be significant at the 95% confidence level for 1% training.
    For all other training sizes, the difference must be over 1.7% BLEU-4.
    Error intervals were computed using bootstrap resampling (Koehn, 2004b).
  
  
    Across different schemes, EN performs the best under scarce-resource condition; and D2 performs best under large-resource condition.
    Across techniques and under scarce-r