r in the word sense disambiguation, or by 2) examples, that can be both adjectival and adverbial if taken out of context.
    The second case cannot be eliminated by a bigger training corpus, however, the reduction of noisy examples would contribute to an increase in accuracy mainly in the case of small nodes which can now contain more noisy examples than correct ones and thus force a wrong attachment.
    We feel that a bigger corpus, would provide us with an increase of accuracy of &amp;quot;certainty I&amp;quot; attachments, which partly includes attachments based on the small leaves.
    Also, we believe that a bigger training corpus would increase performance in the case of less frequent prepositions which do not have enough training examples to allow for induction of a reliable decision tree.
  
  
    The most computationally expensive part of the system is the word sense disambiguation of the training corpus.
    This, however, is done only once and the disambiguated corpus is stored for future classi