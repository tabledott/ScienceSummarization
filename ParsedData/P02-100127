re (1) an EM algorithm for FSTs with cycles and epsilons; (2) training algorithms for HMMs and weighted contextual edit distance that work on incomplete data; (3) endto-end training of noisy channel cascades, so that it is not necessary to have separate training data for each machine in the cascade (cf.
    Knight and Graehl, 20If xi and yi are acyclic (e.g., fully observed strings), and f (or rather its FST) has no a : a cycles, then composition will &#8220;unroll&#8221; f into an acyclic machine.
    If only xi is acyclic, then the composition is still acyclic if domain(f) has no a cycles.
    1998), although such data could also be used; (4) training of branching noisy channels (footnote 7); (5) discriminative training with incomplete data; (6) training of conditional MEMMs (McCallum et al., 2000) and conditional random fields (Lafferty et al., 2001) on unbounded sequences.
    We are particularly interested in the potential for quickly building statistical models that incorporate linguistic and engineerin