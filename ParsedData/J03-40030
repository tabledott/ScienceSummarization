
  Head-Driven Statistical Models For Natural Language Parsing
  
    This article describes three statistical models for natural language parsing.
    The models extend methods from probabilistic context-free grammars to lexicalized grammars, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree.
    Independence assumptions then lead to parameters that encode the X-bar schema, subcategorization, ordering of complements, placement of adjuncts, bigram dependencies, and preferences for close attachment.
    All of these preferences are expressed by probabilities conditioned on lexical heads.
    The models are evaluated on the Penn Wall Street Journal Treebank, showing that their accuracy is competitive with other models in the literature.
    To gain a better understanding of the models, we also give results on different constituent types, as well as a breakdown of precision/recall results in recovering various