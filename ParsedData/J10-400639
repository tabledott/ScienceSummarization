ong links.
    The usefulness of this will of course depend on what the links are.
    We will illustrate in Section 6.4 one function of this space, namely, to perform feature selection, picking links that can then be used to determine a meaningful subspace of the W1W2xL space.
    Direct matricization is just one of the possible uses we can make of the labeled tensor.
    In Section 6.5 we illustrate another use of the tensor formalism by performing smoothing through tensor decomposition.
    Other possibilities, such as graph-based algorithms operating directly on the graph defined by the tensor (Baroni and Lenci 2009), or deriving unstructured semantic spaces from the tensor by removing one of the indices, are left to future work.
    Before we move on, it is worth emphasizing that, from a computational point of view, there is virtually no additional cost in the tensor approach, with respect to traditional structured DSMs.
    The labeled tensor is nothing other than a formalization of distributional data 