
    Another approach is lexicalized parsers (Collins, 2003; Charniak, 2000) that describe each category with a lexical item, usually the head word.
    More recently, Hall and Klein (2012) combine several such annotation schemes in a factored parser.
    We extend the above ideas from discrete representations to richer continuous ones.
    The CVG can be seen as factoring discrete and continuous parsing in one model.
    Another different approach to the above generative models is to learn discriminative parsers using many well designed features (Taskar et al., 2004; Finkel et al., 2008).
    We also borrow ideas from this line of research in that our parser combines the generative PCFG model with discriminatively learned RNNs.
    Deep Learning and Recursive Deep Learning Early attempts at using neural networks to describe phrases include Elman (1991), who used recurrent neural networks to create representations of sentences from a simple toy grammar and to analyze the linguistic expressiveness of the resul