lex downstream processing like parsing is an interesting challenge, since contraction parsing on traditional text is probably a benefit to current parsers.
    We believe that any PTB-trained tool requires substantial retraining and adaptation for Twitter due to the huge genre and stylistic differences (Foster et al., 2011); thus tokenization conventions are a relatively minor concern.
    Our simple-toannotate conventions make it easier to produce new training data.
  
  
    We are primarily concerned with performance on our annotated datasets described in &#167;5 (OCT27, DAILY547), though for comparison to previous work we also test on other corpora (RITTERTW in &#167;6.2, NPSCHAT in &#167;6.3).
    The annotated datasets are listed in Table 1.
    We use OCT27 to refer to the entire dataset described in Gimpel et al. ; it is split into training, development, and test portions (OCT27TRAIN, OCT27DEV, OCT27TEST).
    We use DAILY547 as an additional test set.
    Neither OCT27TEST nor DAILY547 were extensive