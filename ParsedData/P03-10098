e probability obtained when verbj is the JS-divergence We chose two clustering methods which do not involve task-oriented tuning (such as pre-fixed thresholds or restricted cluster sizes) and which approach data straightforwardly, in its distributional form: (i) a simple hard method that collects the nearest neighbours (NN) of each verb (figure 1), and (ii) the Information Bottleneck (IB), an iterative soft method (Tishby et al., 1999) based on information-theoretic grounds.
    The NN method is very simple, but it has some disadvantages.
    It outputs only one clustering configuration, and therefore does not allow examination of different cluster granularities.
    It is also highly sensitive to noise.
    Few exceptional neighbourhood relations contradicting the typical trends in the data are enough to cause the formation of a single cluster which encompasses all elements.
    Therefore we employed the more sophisticated IB method as well.
    The IB quantifies the relevance information of a SCF distributi