(D (d1,...,di_1)) in a history-based parser.
    As a result the model can take into account quite a rich set of features in the history.
    Savings(n)(y-axis) versus n(x-axis).
    Both approaches still rely on decomposing a parse tree into a sequence of decisions, and we would argue that the techniques described in this article have more flexibility in terms of the features that can be included in the model.
    Abney (1997) describes the application of log-linear models to stochastic headdriven phrase structure grammars (HPSGs).
    Della Pietra, Della Pietra, and Lafferty (1997) describe feature selection methods for log-linear models, and Rosenfeld (1997) describes application of these methods to language modeling for speech recognition.
    These methods all emphasize models which define a joint probability over the space of all parse trees (or structures in question): For this reason we describe these approaches as &#8220;Joint log-linear models.&#8221;The probability of a tree xi,j is Here Z is the (