aining data in one model improves performance further, but by less than 0.5% absolute.
    Similarly, adding the Brown data to the WSJ model increased performance on WSJ by less than 0.5%.
    Thus, even a large amount of additional data seems to have relatively little impact if it is not matched to the test material.
    The more varied nature of the Brown corpus also seems to impact results, as all the results on Brown are lower than the WSJ result.
  
  
    The parsers cited above all use some variety of lexical dependency feature to capture statistics on the cooccurrence of pairs of words being found in parentchild relations within the parse tree.
    These word pair relations, also called lexical bigrams (Collins, 1996), are reminiscent of dependency grammars such as Melcuk (1988) and the link grammar of Sleator and Temperley (1993).
    In Collins' Model 1, the word pair statistics occur in the distribution where Hhw represent the head word of a parent node in the tree and Chw the head word of its (non