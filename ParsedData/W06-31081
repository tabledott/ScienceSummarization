 Zens et al., 2005).
    Recently, in (Tillmann and Zhang, 2005) and in (Koehn et al., 2005), a reordering model has been described that tries to predict the orientation of a phrase, i.e. it answers the question &#8217;should the next phrase be to the left or to the right of the current phrase?&#8217; This phrase orientation probability is conditioned on the current source and target phrase and relative frequencies are used to estimate the probabilities.
    We adopt the idea of predicting the orientation, but we propose to use a maximum-entropy based model.
    The relative-frequency based approach may suffer from the data sparseness problem, because most of the phrases occur only once in the training corpus.
    Our approach circumvents this problem by using a combination of phrase-level and word-level features and by using word-classes or part-of-speech information.
    Maximum entropy is a suitable framework for combining these different features with a well-defined training criterion.
    In (Koehn et al