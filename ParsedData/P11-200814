f-domain lexical resources (TAGDICT), in-domain lexical resources (DISTSIM), and sublexical analysis (METAPH).
    Finally, we note that, even though 1,000 training examples may seem small, the test set accuracy when training on only 500 tweets drops to 87.66%, a decrease of only 1.7% absolute.
  
  
    We have developed a part-of-speech tagger for Twitter and have made our data and tools available to the research community at http://www.ark.cs. cmu.edu/TweetNLP.
    More generally, we believe that our approach can be applied to address other linguistic analysis needs as they continue to arise in the era of social media and its rapidly changing linguistic conventions.
    We also believe that the annotated data can be useful for research into domain adaptation and semi-supervised learning.
  

