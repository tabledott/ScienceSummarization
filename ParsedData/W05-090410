ection rules chose the headword of NP to be word corresponding to the POS N in the subtree, and the other child, which corresponds to ART, is the modifier for the headword.
    The dependency tree then is a kind of structure constituted by headwords and every subtree represents the modifier information for its root headword.
    For example, the dependency tree of the sentence I have a red pen is shown as below.
    The dependency tree contains both the lexical and syntactic information, which inspires us to use it for the MT evaluation.
    Noticing that in a dependent tree the child nodes are the modifier of its parent, we propose a dependency-tree based metric by extracting the headwords chains from both the hypothesis and the reference dependency trees.
    A headword chain is a sequence of words which corresponds to a path in the dependency tree.
    Take the dependency tree in Figure 2 as the example, the 2-word headword chains include have I, have pen, pen a, and pen red.
    Before using the headword 