instance in order to update the model as described in Figure 2.
    The experimental results for both domains are in given Table 2.
    As hypothesized, hard EM sometimes from citations and advertisements.
    N is the number of labeled samples.
    H is the traditional hard-EM and H&amp;W weighs labeled and unlabeled data as mentioned in Sec.
    5.
    Our proposed model is H&amp;W&amp;C, which uses constraints in the learning procedure.
    I refers to using constraints during inference at evaluation time.
    Note that adding constraints improves the accuracy during both learning and inference. degrade the performance.
    Indeed, with 300 labeled examples in the citations domain, the performance decreases from 86.1 to 80.7.
    The usefulness of injecting constraints in semi-supervised learning is exhibited in the two right most columns: using constraints H&amp;W&amp;C improves the performance over H&amp;W quite significantly.
    We carefully examined the contribution of using constraints to the learnin