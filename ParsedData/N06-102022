 more complicated methods.
    We still have them to try: restricting consideration to more accurately parsed sentences as training data (sentence selection), trying to learn grammatical generalizations directly rather than simply including the data for training, etc.
    Next there is the question of practicality.
    In terms of speed, once the data is loaded, the new parser is pretty much the same speed as the old &#8212; just under a second a sentence on average for treebank sentences.
    However, the memory requirements are largish, about half a gigabyte just to store the data.
    We are making our current best self-trained parser available3 as machines with a gigabyte or more of RAM are becoming commonplace.
    Nevertheless, it would be interesting to know if the data can be pruned to make the entire system less bulky.
    Finally, there is also the nature of the self-trained data themselves.
    The data we use are from the LA Times.
    Those of us in parsing have learned to expect significant decr