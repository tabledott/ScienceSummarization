rm given perfectly seg mented arguments.
			This evaluates the quality of the argument classifier, and also provides a conceptual upper bound.
			Table 2 first shows the results without using inference (i.e. F(PM ) = PM ).
			The secondrow shows adding inference to the phrase classifica tion can further improve F?=1 by 1%.
			Finally, the overall result on the official test set is given in Table 3.
			Note that the result here is not comparable with the best in this domain (Pradhan et al., 2004) where the full parse tree is assumed given.
			For a fair comparison, our system was among the best at CoNLL-04, where the best system (Hacioglu et al, 2004) achieve a 69.49 F1 score.
	
	
			We show that linguistic information is useful for se mantic role labeling, both in extracting features and Dist. Prec.
			Rec.
			F?=1 Overall 100.00 70.07 63.07 66.39 A0 26.87 81.13 77.70 79.38 A1 35.73 74.21 63.02 68.16 A2 7.44 54.16 41.04 46.69 A3 1.56 47.06 26.67 34.04 A4 0.52 71.43 60.00 65.22 AM-ADV 3.20 39.36 36.16 37.69 AM