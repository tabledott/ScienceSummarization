the speech and language communities.
    The front end of the Raleigh system converted the speech signal (20,000 samples per second) first into a sequence of 80 filter bank outputs (100 80-dimensional vectors per second), and then into a sequence of phoneme-like labels (100 labels per second), using an elaborate set of hand-tuned rules that would soon be replaced with an automatically trained procedure.
    The back end converted these labels into a sequence of words using an artificial finite-state grammar that was so small that the finite-state machine could be written down on a single piece of paper.
    Today, many systems attempt to model unrestricted language using methods that will be discussed in Section 3, but at the time, it was standard practice to work with artificial grammars of this kind.
    When it worked perfectly, the front end produced a transcription of the speech signal such as might be produced by a human phonetician listening carefully to the original speech.
    Unfortunately, it almos