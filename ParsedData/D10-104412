at less direct objective than used by Matsoukas et al, who make an iterative approximation to expected TER.
    However, it is robust, efficient, and easy to implement.4 To perform the maximization in (7), we used the popular L-BFGS algorithm (Liu and Nocedal, 1989), which requires gradient information.
    Dropping the conditioning on 0 for brevity, and letting &#175;c&#955;(s, t) = c&#955;(s, t) + yu(s|t), and &#175;c&#955;(t) = 4Note that the probabilities in (7) need only be evaluated over the support of &#732;p(s, t), which is quite small when this distribution is derived from a dev set.
    Maximizing (7) is thus much faster than a typical MERT run. where co(s, t) are the counts from OUT, as in (6).
    This has solutions: where pI(s|t) is derived from the IN corpus using relative-frequency estimates, and po(s|t) is an instance-weighted model derived from the OUT corpus.
    This combination generalizes (2) and (3): we use either at = a to obtain a fixed-weight linear combination, or at = cI(t)/(cI(t) +