ons: choice of features, choice of classifier, and choice of training data.
    Features range from words and morphological information (Knight and Chander, 1994) to the inclusion of part-of-speech tags (Minnen et al., 2000; Han et al., 2004, 2006; Chodorow et al., 2007; Gamon et al., 2008, 2009; Izumi et al., 2003, 2004; Tetrault and Chodorow, 2008) to features based on linguistic analysis and on WordNet (Lee, 2004; DeFelice and Pulman, 2007, 2008).
    Knight and Chander (1994) and Gamon et al. (2008) used decision tree classifiers but, in general, maximum entropy classifiers have become the classification algorithm of choice.
    Training data are normally drawn from sizeable corpora of native English text (British National Corpus for DeFelice and Pulman (2007, 2008), Wall Street Journal in Knight and Chander (1994), a mix of Reuters and Encarta in Gamon et al. (2008, 2009).
    In order to partially address the problem of domain mismatch between learners&#8217; writing and the news-heavy data sets often u