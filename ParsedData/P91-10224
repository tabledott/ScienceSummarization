ns a number of sentence fragments and other groupings of words that we nonetheless refer to as sentences.
    With this broad interpretation, the English corpus contains 85,016,286 tokens in 3,510,744 sentences, and the French corpus contains 97,857,452 tokens in 3,690,425 sentences.
    The average English sentence has 24.2 tokens, while the average French sentence is about 9.5% longer with 26.5 tokens.
    The left-hand side of Figure 1 shows the raw data for a portion of the English corpus, and the right-hand side shows the same portion after we converted it to TEX and divided it up into sentences.
    The sentence numbers do not advance regularly because we have edited the sample in order to display a variety of phenomena.
    In addition to a verbatim record of the proceedings and its translation, the Hansards include session numbers, names of speakers, time stamps, question numbers, and indications of the original language in which each speech was delivered.
    We retain this auxiliary information in t