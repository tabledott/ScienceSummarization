ng-off distribution &#946;(f), we consider two alternatives.
    The first one is a uniform distribution and the second one is the unigram distribution: Here, Vf denotes the vocabulary size of the source language and N(f) denotes the unigram count of a source word f.
  
  
    The monotone search can be efficiently computed with dynamic programming.
    The resulting complexity is linear in the sentence length.
    We present the formulae for a bigram language model.
    This is only for notational convenience.
    The generalization to a higher order language model is straightforward.
    For the maximization problem in (11), we define the quantity Q(j,e) as the maximum probability of a phrase sequence that ends with the language word e and covers positions 1 to j of the source sentence.
    Q(J + 1, $) is the probability of the optimum translation.
    The $ symbol is the sentence boundary marker.
    We obtain the following dynamic programming recursion.
    Here, M denotes the maximum phrase length in the