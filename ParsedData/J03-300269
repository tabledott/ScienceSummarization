 we described here retains the almost entirely language-independent character of the original STRAND system, adding only the requirement of a reasonable translation lexicon.
    Therefore success in mining for parallel text in other languages depends primarily on whether the data exist in the Archive.
    With regard to corpus size, we demonstrated that the recall of structural matching, and hence its yield, can be significantly improved by simple and automatic classifier construction, requiring only a few hours&#8217; work from a bilingual annotator to create the training material.
    These results are further improved by adding content-based similarity as a feature.
    Our success with English-Arabic, a language pair that is not one of those usually considered well represented on the Web, encourages us to believe that for other languages of interest, we will be similarly successful.
    We have also done a bit of exploration to gauge the potential of the Archive for better-represented language pairs, usin