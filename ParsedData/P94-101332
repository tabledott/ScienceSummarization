vel of representation that best matches the observed probability distributions.
    It is a kitchen-sink approach of the best kind &#8212; throw in many types of potentially relevant features and watch what floats to the top.
    While there are certainly other ways to combine such evidence, this approach has many advantages.
    In particular, precision seems to be at least as good as that achieved with Bayesian methods applied to the same evidence.
    This is not surprising, given the observation in (Leacock et al., 1993) that widely divergent sense-disambiguation algorithms tend to perform roughly the same given the same evidence.
    The distinguishing criteria therefore become: The current algorithm rates very highly on all these standards of evaluation, especially relative to some of the impenetrable black boxes produced by many machine learning algorithms.
    Its output is highly perspicuous: the resulting decision list is organized like a recipe, with the most useful evidence first and in highly rea