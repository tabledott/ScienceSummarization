es of the one billion word training set, where training instances are taken at random.
    We ran three active learning experiments, increasing the size of the total unlabeled training corpus from which we can pick samples to be annotated.
    In all three cases, sample selection outperforms sequential sampling.
    At the endpoint of each training run in the graph, the same number of samples has been annotated for training.
    However, we see that the larger the pool of candidate instances for annotation is, the better the resulting accuracy.
    By increasing the pool of unlabeled training instances for active learning, we can improve accuracy with only a fixed additional annotation cost.
    Thus it is possible to benefit from the availability of extremely large corpora without incurring the full costs of annotation, training time, and representation size.
    While the previous section shows that we can benefit from substantially larger training corpora without needing significant additional manual annot