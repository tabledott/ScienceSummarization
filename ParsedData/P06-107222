de by EM; undirected accuracy also improved significantly under a sign test (p &lt; 10&#8722;6), across all six languages.
    While the most common corrections were to nouns, these account for only 25&#8211;41% of corrections, indicating that corrections are not &#8220;all of the same kind.&#8221; Finally, since more than half of corrections in every language involved reattachment to a noun or a verb (content word), we believe the improved models to be getting closer than EM to the deeper semantic relations between words that, ideally, syntactic models should uncover.
  
  
    One weakness of all recent weighted grammar induction work&#8212;including Klein and Manning (2004), Smith and Eisner (2005b), and the present paper&#8212;is a sensitivity to hyperparameters, including smoothing values, choice of N (for CE), and annealing schedules&#8212;not to mention initialization.
    This is quite observable in the results we have presented.
    An obstacle for unsupervised learning in general is the need for aut