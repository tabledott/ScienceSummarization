 Section 4.1 below), representing a completely random choice from the potential tags for each token (Random) and selection of the lexically most likely tag (LexProb).11 The training/test separation of the corpus is done at utterance boundaries (each 1st to 9th utterance is training and each 10th is test) and leads to a 1,046K token training set and a 115K token test set.
    Around 2.14% of the test set are tokens unseen in the training set and a further 0.37% are known tokens but with unseen tags.'
    3.1.2 WSJ.
    The second data set consists of 1M words of Wall Street Journal material.
    It differs from LOB in that it is American English and, more importantly, in that it is completely made up of newspaper text.
    The material is tagged with the Penn Treebank tagset (Marcus, Santorini, and Marcirtkiewicz 1993), which is much smaller than the LOB one.
    It consists of only 48 tags.'
    There is no attempt to annotate compound words, so there are no ditto tags.
    10 Ditto tags are used for the comp