o totypes to be 10.
			4.1 Qualitative Evaluations.
			In order to show that our model learns more seman tic word representations with global context, we give the nearest neighbors of our single-prototype model versus C&amp;W?s, which only uses local context.
			Thenearest neighbors of a word are computed by com paring the cosine similarity between the center word and all other words in the dictionary.
			Table 1 shows the nearest neighbors of some words.
			The nearest neighbors of ?market?
			that C&amp;W?s embeddings give are more constrained by the syntactic constraint that words in plural form are only close to other words in plural form, whereas our model captures that the singular and plural forms of a word are similar inmeaning.
			Other examples show that our model induces nearest neighbors that better capture seman tics.
			Table 2 shows the nearest neighbors of our model using the multi-prototype approach.
			We see that the clustering is able to group contexts of different 876 Center Word C&amp;W 