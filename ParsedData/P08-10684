c information as a network of head-modifier dependency arcs, typically restricted to be a directed tree (see Figure 1 for an example).
    Dependency parsing depends critically on predicting head-modifier relationships, which can be difficult due to the statistical sparsity of these word-to-word interactions.
    Bilexical dependencies are thus ideal candidates for the application of coarse word proxies such as word clusters.
    In this paper, we take a part-factored structured classification approach to dependency parsing.
    For a given sentence x, let Y(x) denote the set of possible dependency structures spanning x, where each y E Y(x) decomposes into a set of &#8220;parts&#8221; r E y.
    In the simplest case, these parts are the dependency arcs themselves, yielding a first-order or &#8220;edge-factored&#8221; dependency parsing model.
    In higher-order parsing models, the parts can consist of interactions between more than two words.
    For example, the parser of McDonald and Pereira (2006) defines