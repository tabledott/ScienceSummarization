edge.
    Otherwise, the model p(y Ix) will begin to fit itself to quirks in the empirical data.
    A standard approach in statistical modeling, to avoid the problem of overfitting the training data, is to employ cross-validation techniques.
    Separate the training data P(x, y) into a training portion, Pr, and a withheld portion, Ph.
    Use only pr in the modelgrowing process; that is, select features based on how much they increase the likelihood L;), (p).
    As the algorithm progresses, Lip, (p) thus increases monotonically.
    As long as each new constraint imposed allows p to better account for the random process that generated both Pr and P h, the quantity Lph (p) also increases.
    At the point when overfitting begins, however, the new constraints no longer help p model the random process, but instead require p to model the noise in the sample Pr itself.
    At this point, Lp, (p) continues to rise, but Li,, (p) no longer does.
    It is at this point that the algorithm should terminate.
    Figu