sentence splitter and tokenizer.
    When evaluating the systems, we matched against the gold tokenization ignoring punctuation marks.
    Table 6 summarizes the results.
    Note that due to differences in sentence splitting, tokenization and evaluation, these results are not identical to those reported in Table 5.
    Also note that in this experiment we have used token-level accuracy on the CoNLL dataset as well.
    Finally, to complete the comparison to other systems, in Table 7 we summarize the best results reported for the CoNLL03 dataset in literature.
  
  
    We have presented a simple model for NER that uses expressive features to achieve new state of the art performance on the Named Entity recognition task.
    We explored four fundamental design decisions: text chunks representation, inference algorithm, using non-local features and external knowledge.
    We showed that BILOU encoding scheme significantly outperforms BIO and that, surprisingly, a conditional model that does not take into accoun