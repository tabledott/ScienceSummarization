 to zero, and running the same learning algorithm on the base MLN, while assuming that in the ground truth, nonpronouns are clustered by their heads.
    (Effectively, the corresponding InClust atoms are assigned to appropriate values and are included in Y rather than Z during learning.)
    We used 30 iterations of PSCG for learning.
    (In preliminary experiments, additional iterations had little effect on coreference accuracy.)
    We generated 100 samples using MC-SAT for each expectation approximation.6 We conducted experiments on MUC-6, ACE-2004, and ACE Phrase-2 (ACE-2).
    We evaluated our systems using two commonly-used scoring programs: MUC (Vilain et al., 1995) and B3 (Amit &amp; Baldwin, 1998).
    To gain more insight, we also report pairwise resolution scores and mean absolute error in the number of clusters.
    The MUC-6 dataset consists of 30 documents for testing and 221 for training.
    To evaluate the contribution of the major components in our model, we conducted five experiments, each