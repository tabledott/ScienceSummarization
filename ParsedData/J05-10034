uch as news wire text.
    Many of these methods fall into the general category of history-based models, in which a parse tree is represented as a derivation (sequence of decisions) and the probability of the tree is then calculated as a product of decision probabilities.
    While these approaches have many advantages, it can be awkward to encode some constraints within this framework.
    In the ideal case, the designer of a statistical parser would be able to easily add features to the model that are believed to be useful in discriminating among candidate trees for a sentence.
    In practice, however, adding new features to a generative or history-based model can be awkward: The derivation in the model must be altered to take the new features into account, and this can be an intricate task.
    This article considers approaches which rerank the output of an existing probabilistic parser.
    The base parser produces a set of candidate parses for each input sentence, with associated probabilities that defi