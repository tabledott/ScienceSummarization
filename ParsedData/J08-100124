 our exploration of the parameter space is guided by three considerations: the linguistic importance of a parameter, the accuracy of its automatic computation, and the size of the resulting feature space.
    From the linguistic side, we focus on properties of entity distribution that are tightly linked to local coherence, and at the same time allow for multiple interpretations during the encoding process.
    Computational considerations prevent us from considering discourse representations that cannot be computed reliably by existing tools.
    For instance, we could not experiment with the granularity of an utterance&#8212; sentence versus clause&#8212;because available clause separators introduce substantial noise into a grid construction.
    Finally, we exclude representations that will explode the size of the feature space, thereby increasing the amount of data required for training the model.
    Entity Extraction.
    The accurate computation of entity classes is key to computing meaningful entity gr