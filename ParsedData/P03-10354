 types.
    For instance, one would identify a string as a unit, but not identify whether it is a person name.
    This is not always sufficient.
    Second, the probabilistic models used in these methods (e.g.
    Teahan et al., 2000) are trained on a segmented corpus which is not always available.
    Third, the identified unknown words are likely to be linguistically implausible (e.g.
    Dai et al., 1999), and additional manual checking is needed for some subsequent tasks such as parsing.
    We believe that the identification of unknown words should not be defined as a separate problem from word segmentation.
    These two problems are better solved simultaneously in a unified approach.
    One example of such approaches is Sproat et al. (1996), which is based on weighted finite-state transducers (FSTs).
    Our approach is motivated by the same inspiration, but is based on a different mechanism: the improved source-channel models.
    As we shall see, these models provide a more flexible framework to in