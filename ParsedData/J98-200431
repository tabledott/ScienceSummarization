nt value of with very little effect on the parser's selection of constituents from the agenda.
    This thresholding on the propagation of # allows us to update the values on line while still keeping the performance of the parser as 0(n3) empirically.
  
  
    Our figures of merit incorporating boundary statistics use the figures p(Mk ti_i) to represent the effect of the left context and p(to to represent the effect of the right context.
    For our experiments with the first grammar, which was learned from training data taken from the Brown corpus, we estimated these statistics from the same training data.
    First, we parsed the training data according to our grammar.
    (It was necessary to do this, rather than using the hand-annotated parses of the training data, because our grammar does not use the same set of nonterminals as the corpus; see Carroll and Charniak [1992a, 1992b] and Charniak and Carroll [1994] for details.)
    Since we use the tags as our input, the probability of a nonterminal appeari