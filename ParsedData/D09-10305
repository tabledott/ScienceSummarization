e creating data for NLP tasks, Turkers do not have a specialized background in the subject, so there is an obvious tradeoff between hiring individuals from this non-expert labor pool and seeking out annotators who have a particular expertise.
  
  
    We use Mechanical Turk as an inexpensive way of evaluating machine translation.
    In this section, we measure the level of agreement between expert and non-expert judgments of translation quality.
    To do so, we recreate an existing set of goldstandard judgments of machine translation quality taken from the Workshop on Statistical Machine Translation (WMT), which conducts an annual large-scale human evaluation of machine translation quality.
    The experts who produced the goldstandard judgments are computational linguists who develop machine translation systems.
    We recreated all judgments from the WMT08 German-English News translation task.
    The output of the 11 different machine translation systems that participated in this task was scored by rank