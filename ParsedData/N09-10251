than 10,000 features to Hiero (Chiang, 2005) and obtain a +1.5 BLEU improvement.
    Many of the new features use syntactic information, and in particular depend on information that is available only inside a syntax-based translation model.
    Thus they widen the advantage that syntaxbased models have over other types of models.
    The models are trained using the Margin Infused Relaxed Algorithm or MIRA (Crammer et al., 2006) instead of the standard minimum-error-rate training or MERT algorithm (Och, 2003).
    Our results add to a growing body of evidence (Watanabe et al., 2007; Chiang et al., 2008) that MIRA is preferable to MERT across languages and systems, even for very large-scale tasks.
  
  
    The work of Och et al (2004) is perhaps the bestknown study of new features and their impact on translation quality.
    However, it had a few shortcomings.
    First, it used the features for reranking n-best lists of translations, rather than for decoding or forest reranking (Huang, 2008).
    Second, it 