r, and 68% [K -= 0.55] and 60.5% [K = 0.46] with the gold standard, respectively.)
    These results show that the forcedchoice and non-forced-choice task are comparable in accuracy of classification and inter-judge agreement on the target classes, giving us confidence that the forced-choice results provide a reasonably stable upper bound for computational experiments.
  
  
    The work presented here contributes to some central issues in computational linguistics, by providing novel insights, data, and methodology in some cases, and by reinforcing some previously established results in others.
    Our research stems from three main hypotheses: We discuss the relevant debate on each of these hypotheses, and the contribution of our results to each, in the following subsections.
    Argument structure has previously been recognized as one of the most promising candidates for accurate classification.
    For example, Basili, Pazienza, and Velardi (1996) argue that relational properties of verbs&#8212;their argu