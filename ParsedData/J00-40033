tive evaluation techniques are being proposed for semantic interpretation as well, for example, at the Sixth and Seventh Message Understanding Conferences (MUC-6 and MUC-7) (Sundheirn 1995; Chinchor 1997), which also included evaluations of systems on the so-called coreference task, a subtask of which is the resolution of definite descriptions.
    The system we present was developed to be evaluated in a quantitative fashion, as well, but because of the problems concerning agreement between annotators observed in our previous study, we evaluated the system both by measuring precision/recall against a &amp;quot;gold standard,&amp;quot; as done in MUC, and by measuring agreement between the annotations produced by the system and those proposed by the annotators.
    The decision to develop a system that could be quantitatively evaluated on a large number of examples resulted in an important constraint: we could not make use of inference mechanisms such as those assumed by traditional computational theories of d