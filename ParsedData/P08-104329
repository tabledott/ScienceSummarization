does not result in a true joint inference, as executions for different tasks involve tuning a parameter separately.
    In our model there are no such hyper-parameters, and the performance is the result of truly joint disambiguation. sults.
    Furthermore, the combination of pruning and vertical markovization of the grammar outperforms the Oracle results reported by Cohen and Smith.
    This essentially means that a better grammar tunes the joint model for optimized syntactic disambiguation at least in as much as their hyper parameters do.
    An interesting observation is that while vertical markovization benefits all our models, its effect is less evident in Cohen and Smith.
    On the surface, our model may seem as a special case of Cohen and Smith in which &#945; = 0.
    However, there is a crucial difference: the morphological probabilities in their model come from discriminative models based on linear context.
    Many morphological decisions are based on long distance dependencies, and when the globa