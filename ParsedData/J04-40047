o tried to do this and had also gotten performance that fell short of Collins&#8217; published results.
    For example, Gildea (2001) reimplemented Collins&#8217; Model 1 but obtained results with roughly 16.7% more relative error than Collins&#8217; reported results using that model.
  
  
    The Collins parsing model decomposes the generation of a parse tree into many small steps, using reasonable independence assumptions to make the parameter estimation problem tractable.
    Even though decoding proceeds bottom-up, the model is defined in a top-down manner.
    Every nonterminal label in every tree is lexicalized: the label is augmented to include a unique headword (and that headword&#8217;s part of speech) that the node dominates.
    The lexicalized PCFG that sits behind Model 2 has rules of the form where P, L;, R;, and H are all lexicalized nonterminals, and P inherits its lexical head from its distinguished head-child, H. In this generative model, first P is generated, then its head-child H, then e