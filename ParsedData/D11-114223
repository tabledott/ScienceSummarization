1% higher than TEXTRUNNER and performing on par with WOEpOs.
    From the training data, TEXTRUNNER-R was able to learn a model that predicts contiguous relation phrases, but still returned incoherent relation phrases (e.g., starting with a preposition) and overspecified relation phrases.
    These errors are due to TEXTRUNNER-R overfitting the training data and not having access to the lexical constraint.
    Figure 3 shows the precision-recall curves of the systems introduced in this paper.
    TEXTRUNNER-R has much lower precision than REVERB and REVERB&#8212;Lex at all levels of recall.
    The lexical constraint gives REVERB a boost in precision over REVERB&#8212;Lex, reducing overspecified extractions from 20% of REVERB&#8212;Lex&#8217;s output to 1% of REVERB&#8217;s.
    The lexical constraint also boosts recall over REVERB&#8212;Lex, since REVERB is able to find a correct relation phrase where REVERB&#8212;Lex finds an overspecified one.
    Figure 4 shows the precision-recall curves of REVERB and th