been reported for parsing models trained on the Penn Treebank.
    As a possible explanation we considered lack of training data: Negra is about half the size of the Penn Treebank.
    However, the learning curves for the three models failed to produce any evidence that they suffer from sparse data.
    In Experiment 2, we therefore investigated an alternative hypothesis: the poor performance of the lexicalized models is due to the fact that the rules in Negra are flatter than in the Penn Treebank, which makes lexical head-head dependencies less useful for correctly determining constituent boundaries.
    Based on this assumption, we proposed an alternative model hat replaces lexical head-head dependencies with lexical sister-head dependencies.
    This can the thought of as a way of binarizing the flat rules in Negra.
    The results show that sister-head dependencies improve parsing performance not only for NPs (which is well-known for English), but also for PPs, VPs, Ss, and coordinate categories.
    The 