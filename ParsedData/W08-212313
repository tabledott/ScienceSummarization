r of it- erations was 20 and the regularization parameter C was 0.01.
  Interestingly, we noted that the global SRL model outperformed the pipeline even when no global features were added.
  This shows that the global learning model can correct label bias prob- lems introduced by the pipeline architecture.
  4 Syntactic?Semantic Integration Our baseline joint feature representation contained only three features: the log probability of the syn- tactic tree and the log probability of the semantic structure according to the pipeline and the global model, respectively.
  This model was trained on the complete training set using cross-validation.
  The probabilities were obtained using the multinomial logistic function (?softmax?).
  We carried out an initial experiment with a more complex joint feature representation, but failed to improve over the baseline.
  Time prevented us from exploring this direction conclusively.
  5 Results The submitted results on the development and test corpora are presented in the up