ntroids of the respective sets of vectors.
    To calculate the similarity of two words w1 and w2, Ruiz-Casado et al. (2005) collect snippets containing w1 from a Web search engine, extract a context around it, replace it with w2 and check for the existence of that modified context in the Web.
    Using a search engine to calculate similarities between words has the drawback that the data used will always be truncated.
    So, for example, the numbers of hits returned by search engines nowadays are always approximate and rounded up.
    The systems that rely on collecting snippets are also limited by the maximum number of documents returned per query, typically around a thousand.
    We hypothesize that by crawling a large corpus from the Web and doing standard corpus analysis to collect precise statistics for the terms we should improve over other unsupervised systems that are based on search engine results, and should yield results that are competitive even when compared to knowledge-based approaches.
    I