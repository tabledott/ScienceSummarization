 from documents retrieved by different search engines (e.g.
    Google, Yahoo and MSN) for each hypothesis.
    In this application setting it was assumed that relevant documents (from an IR perspective) should entail the given propositional hypothesis.
    For the QA (Question Answering) task, annotators used questions taken from the datasets of official QA competitions, such as TREC QA and QA@CLEF datasets, and the corresponding answers extracted from the Web by actual QA systems.
    Then they transformed the question-answer pairs into t-h pairs as follows: &#167; An answer term of the expected answer type was picked from the answer passage either a correct or an incorrect one.
    &#167; The question was turned into an affirmative sentence plugging in the answer term.
    &#167; t-h pairs were generate, using the affirmative sentences as hypotheses (h&#8217;s) and the original answer passages as texts (t&#8217;s).
    For example, given the question &#8220;How high is Mount Everest?&#8221; and a text (t) 