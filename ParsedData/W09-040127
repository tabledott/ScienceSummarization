ed to be the most problematic language pair to automatically evaluate, with all of the metrics having a negative correlation except wpBleu and TER.
    Table 9 gives detailed results for how well variations on a number of automatic metrics do for the task of ranking five English-Czech systems.6 These systems were submitted by Kos and Bojar (2009), and they investigate the effects of using Prague Dependency Treebank annotations during automatic evaluation.
    They linearizing the Czech trees and evaluated either the lemmatized forms of the Czech (lemma) read off the trees or the Tectogrammatical form which retained only lemmatized content words (tecto).
    The table also demonstrates SemPOS, Meteor, and GTM perform better on Czech than many other metrics.
    Tables 10 and 11 show the percent of times that the metrics&#8217; scores were consistent with human rankings of every pair of translated sentences.7 Since we eliminated sentence pairs that were judged to be equal, the random baseline for this task is 5