word choice.
    This limitation can be overcome by using features on values, so that NLG2 and NLG3 might discover &#8212; to use a hypothetical example &#8212; that &amp;quot;flights leaving $city-fr&amp;quot; is preferred over &amp;quot;flights from $city-fr&amp;quot; when $city-fr is a particular value, such as &amp;quot;Miami&amp;quot;.
  
  
    This paper presents the first systems (known to the author) that use a statistical learning approach to produce natural language text directly from a semantic representation.
    Information to solve the attribute ordering and lexical choice problems&#8212; which would normally be specified in a large handwritten grammar&#8212; is automatically collected from data with a few feature patterns, and is combined via the maximum entropy framework.
    NLG2 shows that using just local n-gram information can outperform the baseline, and NLG3 shows that using syntactic information can further improve generation accuracy.
    We conjecture that NLG2 and NLG3 should work i