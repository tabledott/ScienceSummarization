y the best features for distinguishing dissimilar words.
    Like LCA, the meaning of a text is computed as the sum of the word feature vectors.
    Text similarity is measured by the cosine of the corresponding feature vectors.
    LSA has been shown to match human similarity judgements on a wide range of tasks (Landauer and Dumais, 1997; Wolfe et al., 1998; Wiemer-Hastings et al., 1999, for example).
    LSA is trained on a set of texts A = Y1, ..., with vocabulary twi, turd-.
    Anxm matrix A is calculated, in which, A,i is the number of times to, occurs in Si.
    The values are scaled according to a general form of inverse document frequency, Singular value decomposition, or SVD (Golub and van Loan, 1989) is then applied to yield B = UEVT, where XT denotes the transposed matrix of X.
    The columns of U and V are the eigenvectors of BBT and BTB, respectively.
    The diagonal values of E are the corresponding singular values, i.e. the non-negative square roots of the eigenvalues of BBT.
    These are s