have label NONE.
    The scoring measures are illustrated in Figure 2(d).
    The figure shows performance measures&#8212;F-Measure (F1) and Whole Frame Accuracy (Acc.
    )&#8212;across nine different conditions.
    When the sets of labeled spans are compared directly, we obtain the complete task measures, corresponding to the ID&amp;CLS row and ALL column in Figure 2(d).
    We also define several other measures to understand the performance of the system on different types of labels.
    We measure the performance on identification (ID), classification (CLS), and the complete task (ID&amp;CLS), when considering only the core arguments (CORE), all arguments but with a single ARGM label for the modifier arguments (COARSEARGM), and all arguments (ALL).
    This defines nine sub-tasks, which we now describe.
    For each of them, we compute the Whole Frame Accuracy and F-Measure as follows: Whole Frame Accuracy (Acc.).
    This is the percentage of propositions for which there is an exact match between the pr