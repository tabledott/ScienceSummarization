y small training corpus.
    Also, the performance of the IBM Manual corpus is better than the WSJ corpus when the size of the training corpus is taken into account.
    The baseline for the ATIS domain is remarkably high due to the repetitive constructions and limited vocabulary in that domain.
    This is also true for the IBM Manual corpus, although to a lesser extent.
    The trigram model of supertagging is attractive for limited domains since it performs quite well with relatively insignificant amounts of training material.
    The performance of the supertagger can be improved in an iterative fashion by using the supertagger to supertag larger amounts of training material, which can be quickly hand-corrected and used to train a better-performing supertagger. most to the performance of a POS tagger, since the baseline performance of assigning the most likely POS for each word produces 91% accuracy (Brill 1993).
    Contextual information contributes relatively a small amount towards the performance, imp