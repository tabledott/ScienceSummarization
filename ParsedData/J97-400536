ounding&amp;quot; words and low probability to non-English-sounding words.
    For this application, Gibbs sampling is appropriate.
    Gibbs sampling does not work for the application to AV grammars, however.
    Fortunately, there is an alternative random sampling method we can use: Metropolis-Hastings sampling.
    We will discuss the issue in some detail shortly.
    When a new feature is added to the field, the best value for its initial weight is chosen, but the weights for the old features are held constant.
    In general, however, adding the new feature may make it necessary to readjust weights for all features.
    The second half of the IIS algorithm involves finding the best weights for a given set of features.
    The method is very similar to the method for selecting the initial weight for a new feature.
    Let (i31, , On) be the old weights for the features.
    We wish to compute &amp;quot;increments&amp;quot; (61, .
    .
    SO to determine a new field with weights (601, &#8226; &#8226; &#8