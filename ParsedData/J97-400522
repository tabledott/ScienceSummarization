nded, and we are done.
    Let us back up to (c) again.
    Here we were free to choose rule 4 instead of rule 3 to expand the right-hand A node.
    Rule 4 instructs us to label the 1 child b, but we cannot, inasmuch as it is already labeled a.
    The derivation fails, and no dag is generated.
    The language L(G2) is the set of dags produced by successful derivations, as shown in Figure 7.
    (The edges of the dags should actually be labeled with l's and 2's, but I The language generated by G2. have suppressed the edge labels for the sake of perspicuity.)
    Now we face the question of how to attach probabilities to grammar G2.
    The natural extension of the method we used for context-free grammars is the following: Associate a weight with each of the six rules of grammar G2.
    For example, let M2 be the model consisting of G2 plus weights (i3,.
    .436) = (1 /2, 1 /2, 2/3, 1 /3, 1 /2, 1 /2).
    Let 02(x) be the weight that M2 assigns to dag x; it is defined to be the product of the weights of the