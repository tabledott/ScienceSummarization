ting , we use standard neural network methods for probability estimation (Bishop, 1995).
    A log-linear model (also known as a maximum entropy model, and as the normalized exponential output function) is used to estimate the probability distribution over the four types of decisions, shifting, projecting, attaching, and modifying.
    A separate log-linear model is used to estimate the probability distribution over node labels given that projecting &#10002;project project , which is multiplied is chosen by the probability estimate for projecting to the probability &#10002;get estimates for that set of decisions project .
    &#10002; project &#10002;project project &#10002;project Similarly, the probability estimate for shifting the word which is actually observed in the sentence shift is computed with log-linear models.
    This means that values for all possible words need to be computed, to do the normalization.
    The high cost of this computation is reduced by splitting the computation of shift shift i