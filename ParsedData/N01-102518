nts is summarized as follows: INITJ,LST,PTR,SBAR) are annotated.
    This data set consists of 4 sections (15-18) of the WSJ part of the Penn Treebank for the training data, and one section (20) for the test data 3.
    All the experiments are carried out with our software package TinySVM4, which is designed and optimized to handle large sparse feature vectors and large number of training samples.
    This package can estimate the VC bound and Leave-One-Out bound automatically.
    For the kernel function, we use the 2-nd polynomial function and set the soft margin parameter to be 1.
    In the baseNP identification task, the performance of the systems is usually measured with three rates: precision, recall and .
    In this paper, we refer to as accuracy.
    Table 2 shows results of our SVMs based chunking with individual chunk representations.
    This table also lists the voting weights estimated by different approaches (B:Cross Validation, C:VC-bound, D:Leave-one-out).
    We also show the results of Sta