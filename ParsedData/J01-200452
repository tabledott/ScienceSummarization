of the word probabilities is the numerator at the final word, namely, the string prefix probability.
    We can make a consistent estimate of the string probability by similarly summing over all of the trees within our beam.
    Let Ht be the priority queue H, before any processing has begun with word w, in the look-ahead.
    This is a subset of the possible leftmost partial derivations with respect to the prefix string W. Since RV is produced by expanding only analyses on priority queue H;', the set of complete trees consistent with the partial derivations on priority queue Ht is a subset of the set of complete trees consistent with the partial derivations on priority queue HT'', that is, the total probability mass represented by the priority queues is monotonically decreasing.
    Thus conditional word probabilities defined in a way consistent with Equation 14 will always be between zero and one.
    Our conditional word probabilities are calculated as follows: As mentioned above, the model cannot overesti