n simplify this task by holding A =- Ao constant and performing a line search over the possible values of the new parameter a.
    In (a), the darkened line represents the search space we restrict attention to.
    In (b), we show the reduced problem: a line search over a. optimization problem requiring more sophisticated methods such as conjugate gradient.
    But the savings comes at a price: for any particular feature f, we are probably underestimating its gain, and there is a reasonable chance that we will select a feature f whose approximate gain AL(S, f) was highest and pass over the feature f with maximal gain AL (S, f).
    A graphical representation of this approximation is provided in Figure 3.
    Here the log-likelihood is represented as an arbitrary convex function over two parameters: A corresponds to the &amp;quot;old&amp;quot; parameter, and a to the &amp;quot;new&amp;quot; parameter.
    Holding A fixed and adjusting a to maximize the log-likelihood involves a search over the darkened line, r