4CULOTTA-TEST our system has a B3 F1 score only .4 points lower than Bengston and Roth (2008) and it outperforms all unsupervised approaches.
    In MUC6-TEST, our sieve&#8217;s B3 F1 score is 1.8 points lower than Haghighi and Klein (2009) +S, but it outperforms a supervised system that used gold named entity labels.
    Finally, the multi-pass architecture always beats the equivalent single-pass system with its contribution ranging between 1 and 4 F1 points depending on the corpus and evaluation metric.
    Our approach has the highest precision on all corpora, regardless of evaluation metric.
    We believe this is particularly useful for large-scale NLP applications that use coreference resolution components, e.g., question answering or information extraction.
    These applications can generally function without coreference information so it is beneficial to provide such information only when it is highly precise.
  
  
    The sieve model outperforms all other systems on at least two test sets, even tho