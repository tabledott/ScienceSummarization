ts to summary ranking are unlikely to come from adding more annotated data.
    Comparison with the State-of-the-Art.
    As in Experiment 1, we compared the best performing grid model (Coreference&#8722;Syntax+Salience+) against LSA (see Table 8).
    The former model significantly outperforms the latter (p &lt; .01) by a wide margin.
    LSA is perhaps at a disadvantage here because it has been exposed only to human-authored texts.
    Machine-generated summaries are markedly distinct from human texts even when these are incoherent (as in the case of our ordering experiment).
    For example, manual inspection of our summary corpus revealed that low-quality summaries often contain repetitive information.
    In such cases, simply knowing about high cross-sentential overlap is not sufficient to distinguish a repetitive summary from a well-formed one.
    Furthermore, note that in contrast to the documents in Experiment 1, the summaries being ranked here differ in lexical choice.
    Some are written by human