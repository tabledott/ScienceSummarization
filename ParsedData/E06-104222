ng the sentence with which it has the most words in common.
    This corresponds well to the basic highest similarity TroFi algorithm.
    Sentences attracted to neither, or equally to both, sets are put in the opposite cluster to where they belong.
    Since this baseline actually attempts to distinguish between literal and nonliteral and uses all the data used by the TroFi algorithm, it is the one we will refer to in our discussion below.
    Experiments were conducted to first find the results of the core algorithm and then determine the effects of each enhancement.
    The results are shown in Figure 1.
    The last column in the graph shows the average across all the target verbs.
    On average, the basic TroFi algorithm (KE) gives a 7.6% improvement over the baseline, with some words, like &#8220;lend&#8221; and &#8220;touch&#8221;, having higher results due to transitivity of similarity.
    For our sum of similarities enhancement, all the individual target word results except for &#8220;examine&#8221