
	A Topic Model for Word Sense Disambiguation
		We develop latent Dirichlet alocation with WORDNET (LDAWN), an unsupervised probabilistic topic model that includes word sense as a hidden variable.
		We develop a probabilistic posterior inference algorithm for simultaneously disambiguating a corpusand learning the domains in which to consider each word.
		Using the WORDNET hierarchy, we embed the construction of Ab ney and Light (1999) in the topic model and show that automatically learned domainsimprove WSD accuracy compared to alter native contexts.
	
	
			Word sense disambiguation (WSD) is the task of determining the meaning of an ambiguous word in its context.
			It is an important problem in natural language processing (NLP) because effective WSD can improve systems for tasks such as information retrieval, machine translation, and summarization.In this paper, we develop latent Dirichlet alocation with WORDNET (LDAWN), a generative prob abilistic topic model for WSD where the sense of the word is a hidden 