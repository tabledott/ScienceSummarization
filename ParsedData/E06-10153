re m and n are the number of nodes in the two trees.
    This low complexity allows SVMs to carry out experiments on hundreds of thousands of training instances since it is not higher than the complexity of the polynomial kernel, widely used on large experimentation e.g.
    (Pradhan et al., 2004).
    To confirm such hypothesis, we measured the impact of the algorithm on the time required by SVMs for the learning of about 122,774 predicate argument examples annotated in PropBank (Kingsbury and Palmer, 2002) and 37,948 instances annotated in FrameNet (Fillmore, 1982).
    Regarding the classification properties, we studied the argument labeling accuracy of ST and SST kernels and their combinations with the standard features (Gildea and Jurafsky, 2002).
    The results show that, on both PropBank and FrameNet datasets, the SST-based kernel, i.e. the richest in terms of substructures, produces the highest SVM accuracy.
    When SSTs are combined with the manual designed features, we always obtain the best figur