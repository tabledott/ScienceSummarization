nfortunately, comparisons across vector composition models have been few and far between in the literature.
    The merits of different approaches are illustrated with a few hand picked examples and parameter values and large scale evaluations are uniformly absent (see Frank et al. (2007) for a criticism of Kintsch&#8217;s (2001) evaluation standards).
    Our work proposes a framework for vector composition which allows the derivation of different types of models and licenses two fundamental composition operations, multiplication and addition (and their combination).
    Under this framework, we introduce novel composition models which we compare empirically against previous work using a rigorous evaluation methodology.
  
  
    We formulate semantic composition as a function of two vectors, u and v. We assume that individual words are represented by vectors acquired from a corpus following any of the parametrisations that have been suggested in the literature.1 We briefly note here that a word&#8217;s vect