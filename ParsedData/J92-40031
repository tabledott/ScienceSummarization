based groupings, depending on the nature of the underlying statistics.
  
  
    In a number of natural language processing tasks, we face the problem of recovering a string of English words after it has been garbled by passage through a noisy channel.
    To tackle this problem successfully, we must be able to estimate the probability with which any particular string of English words will be presented as input to the noisy channel.
    In this paper, we discuss a method for making such estimates.
    We also discuss the related topic of assigning words to classes according to statistical behavior in a large body of text.
    In the next section, we review the concept of a language model and give a definition of n-gram models.
    In Section 3, we look at the subset of n-gram models in which the words are divided into classes.
    We show that for n = 2 the maximum likelihood assignment of words to classes is equivalent to the assignment for which the average mutual information of adjacent classes is greatest