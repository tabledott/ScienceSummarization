led the first argument in the tree as ARG0 instead of ARG1, probably because an ARG0 label is more likely for the subject position.
    All joint models for these experiments used the whole sequence and frame features.
    As can be seen from Table 4, our joint models achieve error reductions of 32% and 22% over our local models in FMeasure on CORE and ARGM respectively.
    With respect to the Frame Accuracy metric, the joint error reduction is 38% and 26% for CORE and ARGM respectively.
    We also report results on automatic parses (see Table 5).
    We trained and tested on automatic parse trees from Charniak&#8217;s parser (Charniak, 2000).
    For approximately 5.6% of the argument constituents in the test set, we could not find exact matches in the automatic parses.
    Instead of discarding these arguments, we took the largest constituent in the automatic parse having the same head-word as the gold-standard argument constituent.
    Also, 19 of the propositions in the test set were discarded because C