ver, to align all words in order to meet the goal of helping translators (and lexicographers) with difficult terminology.
    The EM algorithm produces two sets of maximum likelihood probability estimates: translation probabilities, 1(1 le), and offset probabilities, o(k).
    Brown et al. select their preferred alignment simply by choosing the most probable alignment according to the maximum likelihood probabilities, relative to the given sentence alignment.
    In the terms of our 'In this example, French is used as the source language and English as the target.
    2The center of the estimated distribution seems more fiat than in a normal distribution.
    This might be explained by a higher tendency for local changes of word order within phrases than for order changes among phrases.
    This is merely a hypothesis, though, which requires further testing.
    Unfortunately, this method does not model the dependence between connections for French words that are near one another.
    For example, the fact th