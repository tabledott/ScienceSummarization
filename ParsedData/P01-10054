, is that labeled training data is essentially free, since the correct answer is surface apparent in any collection of reasonably well-edited text.
  
  
    This work was partially motivated by the desire to develop an improved grammar checker.
    Given a fixed amount of time, we considered what would be the most effective way to focus our efforts in order to attain the greatest performance improvement.
    Some possibilities included modifying standard learning algorithms, exploring new learning techniques, and using more sophisticated features.
    Before exploring these somewhat expensive paths, we decided to first see what happened if we simply trained an existing method with much more data.
    This led to the exploration of learning curves for various machine learning algorithms: winnow1, perceptron, na&#239;ve Bayes, and a very simple memory-based learner.
    For the first three learners, we used the standard collection of features employed for this problem: the set of words within a window of the t