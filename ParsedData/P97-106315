 each other.
    Where the one-to-one assumption failed, but a link type captured part of a correct translation, it was judged &amp;quot;incomplete.&amp;quot; Whether incomplete links are correct or incorrect depends on the application.
    We evaluated five random samples of 100 link types each at three levels of recall.
    For our bitext, recall of 36%, 46% and 90% corresponded to translation lexicons containing 32274, 43075 and 88633 words, respectively.
    Figure 5 shows the precision of the model with 95% confidence intervals.
    The upper curve represents precision when incomplete links are considered correct, and the lower when they are considered incorrect.
    On the former metric, our model can generate translation lexicons with precision and recall both exceeding 90%, as well as dictionarysized translation lexicons that are over 99% correct.
    Though some have tried, it is not clear how to extract such accurate lexicons from other published translation models.
    Part of the difficulty stems 