fer to the models as head-driven statistical models.
    We describe evaluation of the three models on the Penn Wall Street Journal Treebank (Marcus, Santorini, and Marcinkiewicz 1993).
    Model 1 achieves 87.7% constituent precision and 87.5% consituent recall on sentences of up to 100 words in length in section 23 of the treebank, and Models 2 and 3 give further improvements to 88.3% constituent precision and 88.0% constituent recall.
    These results are competitive with those of other models that have been applied to parsing the Penn Treebank.
    Models 2 and 3 produce trees with information about wh-movement or subcategorization.
    Many NLP applications will need this information to extract predicate-argument structure from parse trees.
    The rest of the article is structured as follows.
    Section 2 gives background material on probabilistic context-free grammars and describes how rules can be &#8220;lexicalized&#8221; through the addition of headwords to parse trees.
    Section 3 introduces th