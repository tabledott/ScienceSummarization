mber of possible trees that can be assigned to strings would then further explode.
    UML-DOP's performance still remains behind that of supervised (binarized) DOP parsers, such as DOP1, which achieved 81.9% average fscore on the 10 WSJ40 splits, and ML-DOP, which performed slightly better with 82.1% average fscore.
    And if DOP1 and ML-DOP are not binarized, their average f-scores are respectively 90.1% and 90.5% on WSJ40.
    However, DOP1 and ML-DOP heavily depend on annotated data whereas UML-DOP only needs unannotated data.
    It would thus be interesting to see how close UML-DOP can get to ML-DOP's performance if we enlarge the amount of training data.
    7 Conclusion: Is the end of supervised parsing in sight?
    Now that we have outperformed a well-known supervised parser by an unsupervised one, we may raise the question as to whether the end of supervised NLP comes in sight.
    All supervised parsers are reaching an asymptote and further improvement does not seem to come from more hand-annotat