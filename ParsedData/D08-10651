 typically employ the Maximum A Posteriori (MAP) decision rule which optimizes the 0-1 loss function.
    In contrast, these systems are evaluated using metrics based on string-edit distance (Word Error Rate), ngram overlap (BLEU score (Papineni et al., 2001)), or precision/recall relative to human annotations.
    Minimum Bayes-Risk (MBR) decoding (Bickel and Doksum, 1977) aims to address this mismatch by selecting the hypothesis that minimizes the expected error in classification.
    Thus it directly incorporates the loss function into the decision criterion.
    The approach has been shown to give improvements over the MAP classifier in many areas of natural language processing including automatic speech recognition (Goel and Byrne, 2000), machine translation (Kumar and Byrne, 2004; Zhang and Gildea, 2008), bilingual word alignment (Kumar and Byrne, 2002), and parsing (Goodman, 1996; Titov and Henderson, 2006; Smith and Smith, 2007).
    In statistical machine translation, MBR decoding is generally implem