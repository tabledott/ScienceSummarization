el.
    As such, our method does not require complex training procedures, and can instead leverage all of the established methods for training high accuracy sequence models.
    It can indeed be used in conjunction with any statistical hidden state sequence model: HMMs, CMMs, CRFs, or even heuristic models.
    Third, our technique employs Gibbs sampling for approximate inference, a simple and probabilistically well-founded algorithm.
    As a consequence of these differences, our approach is easier to understand, implement, and adapt to new applications.
  
  
    We have shown that a constraint model can be effectively combined with an existing sequence model in a factored architecture to successfully impose various sorts of long distance constraints.
    Our model generalizes naturally to other statistical models and other tasks.
    In particular, it could in the future be applied to statistical parsing.
    Statistical context free grammars provide another example of statistical models which are restrict