sessment, it would be potentially unfair to the metric to count a slightly different metric score as discordant with a tie in the relative human rankings.
    A tie in automatic metric rank for two translations was counted as discordant with two corresponding non-tied human judgments.
    The correlations are shown in Table 14 for translations into English, and Table 15 out of English, sorted by average correlation across the four language pairs.
    The highest correlation for each language pair and the highest overall average are bolded.
    There is a clear winner for the metrics that score translations into English: the MTeRater-Plus metric (Parton et al., 2011) has the highest segment level correlation across the board.
    For metrics that score translation into other languages, there is not such a clear-cut winner.
    The AMBER metric variants do well, as do MPF and WMPF.
  
  
    This year we introduced a new shared task that focuses on using evaluation metrics to tune the parameters of a statistica