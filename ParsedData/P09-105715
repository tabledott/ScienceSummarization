odel with the highest data likelihood, we get 83.8% accuracy.
    Likewise, when we extend our alternating EM scheme to 100 random restarts at each step, we improve our tagging accuracy from 91.6% to 91.8% (Figure 8).
    As noted by Toutanova and Johnson (2008), there is no reason to limit the amount of unlabeled data used for training the models.
    Their models are trained on the entire Penn Treebank data (instead of using only the 24,115-token test data), and so are the tagging models used by Goldberg et al. (2008).
    But previous results from Smith and Eisner (2005) and Goldwater and Griffiths (2007) show that their models do not benefit from using more unlabeled training data.
    Because EM is efficient, we can extend our word-sequence trainModel 1 Model 2 Model 3 Model 4 Model 5 ing data from the 24,115-token set to the entire Penn Treebank (973k tokens).
    We run EM training again for Model 5 (the best model from Figure 5) but this time using 973k word tokens, and further increase our accuracy t