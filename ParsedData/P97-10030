
  Three Generative Lexicalized Models For Statistical Parsing
  
    In this paper we first propose a new statistical parsing model, which is a generative model of lexicalised context-free grammar.
    We then extend the model to include a probabilistic treatment of both subcategorisation and wh-movement.
    Results on Wall Street Journal text show that the parser performs at 88.1/87.5% constituent precision/recall, an average improvement of 2.3% over (Collins 96).
  
  
    Generative models of syntax have been central in linguistics since they were introduced in (Chomsky 57).
    Each sentence-tree pair (S, T) in a language has an associated top-down derivation consisting of a sequence of rule applications of a grammar.
    These models can be extended to be statistical by defining probability distributions at points of non-determinism in the derivations, thereby assigning a probability 'P(S,T) to each (S, T) pair.
    Probabilistic context free grammar (Booth and Thompson 73) was an early example of a st