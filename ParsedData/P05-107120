ich the ATB splits each word determines the ATB tokenization.
    The ATB starts with a simple tokenization, and then splits the word into four fields: conjunctions; particles (prepositions in the case of nouns); the word stem; and pronouns (object clitics in the case of verbs, possessive clitics in the case of nouns).
    The ATB does not tokenize the definite article + Al+.
    We compare our output to the morphologically analyzed form of the ATB, and determine if our morphological choices lead to the correct identification of those clitics that need to be stripped off.8 For our evaluation, we only choose the Maj chooser, as it performed best on TE1.
    We evaluate in two ways.
    In the first evaluation, we determine for each simple input word whether the tokenization is correct (no matter how many ATB tokens result).
    We report the percentage of words which are correctly tokenized in the second column in Figure 5.
    In the second evaluation, we report on the number of output tokens.
    Each word i