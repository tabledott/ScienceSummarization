s are presented in the following subsections.
    Four algorithms are compared during the following experiments: The goal of this task is to assign to each word in the given sentence a tag corresponding to its part of speech.
    A multitude of approaches have been proposed to solve this problem, including transformation-based learning, Maximum Entropy models, Hidden Markov models and memory-based approaches.
    The data used in the experiment was selected from the Penn Treebank Wall Street Journal, and is the same used by Brill and Wu (1998).
    The training set contained approximately 1M words and the test set approximately 200k words.
    Table 1 presents the results of the experiment4.
    All the algorithms were trained until a rule with a score of 2 was reached.
    The FastTBL algorithm performs very similarly to the regular TBL, while running in an order of magnitude faster.
    The two assumptions made by the ICA algorithm result in considerably less training time, but the performance is also degra