y, 2000) using IBM Model 4; for Urdu-English and Chinese-English we merged alignments with the refined method, and for Arabic-English we merged with the union method.
    Table 2 notes the sizes of the datasets used in our experiments.
    All tune and test data have four English reference sets for the purposes of scoring.
    The training data for Urdu-English is that made available in the constrained track in the NIST 2009 MT evaluation.
    This includes many lexicon entries and other single-word data, which accounts for the large number of lines relative to word count.
    The NIST 2008 evaluation set, which contains newswire and web data, is split into two parts; we used roughly half each for tune and test.
    We trained a 5-gram English language model on the English side of the training data.
    The training data for Arabic English is that made available in the constrained track in the NIST 2008 MT evaluation.
    The tune set, which contains only newswire data, is a mix from NIST MT evaluation sets f