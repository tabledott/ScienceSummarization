 clean and linguistically justified and but also probabilistically apropriate and empirically sound.
    The overall performance of our joint framework demonstrates that a probability distribution obtained over mere syntactic contexts using a Treebank grammar and a data-driven lexicon outperforms upper bounds proposed by previous joint disambiguation systems and achieves segmentation and parsing results on a par with state-of-the-art standalone applications results.
    Better grammars are shown here to improve performance on both morphological and syntactic tasks, providing support for the advantage of a joint framework over pipelined or factorized ones.
    We conjecture that this trend may continue by incorporating additional information, e.g., three-dimensional models as proposed by Tsarfaty and Sima&#8217;an (2007).
    In the current work morphological analyses and lexical probabilities are derived from a small Treebank, which is by no means the best way to go.
    Using a wide-coverage morphological an