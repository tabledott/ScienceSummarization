v set to determine the optimal number of iterations in perceptron training.
    Table 4 compares our baseline against the state-of-the-art graph-based (McDonald et al., 2005) and transition-based (Zhang and Clark, 2008) approaches, and confirms that our system performs at the same level with those stateof-the-art, and runs extremely fast in the deterministic mode (k=1), and still quite fast in the beamsearch mode (k=16).
    The bilingual data we use is the translated portion of the Penn Chinese Treebank (CTB) (Xue et al., 2002), corresponding to articles 1-325 of PTB, which have English translations with goldstandard parse trees (Bies et al., 2007).
    Table 5 shows the split of this data into training, development, and test subsets according to Burkett and Klein (2008).
    Note that not all sentence pairs could be included, since many of them are not oneto-one aligned at the sentence level.
    Our wordalignments are generated from the HMM aligner of Liang et al. (2006) trained on approximately 1.7M sente