n lv(tword(i) ] tword(i + 1), tword(i + 2)) ~ l,(tag(i) I tag(i + 1), tag(i + 2)).
  P,(word(i) I tag(/)) (a) Pr(words, tags, links) c~ Pr(words, tags, preferences) =/  r (words ,  tags).
  Pr(preferences ] words, t~gs) (4) ]-I l,.
  (twom(i) I two d(i + 1), t o,d(i + 2)).
  H I two,.d(i)) 1 &lt;i&lt;n t&lt; i&lt;n / 1 +#r ight -k ids( i )  ~ Pv(words, t+gs, links)= I I  { 1-[ P,.
  (two,.d(kid+(i))I t,gj +dd+_,(i) ),t+o,d(i)) l&lt; i&lt;n c=-(  ] -k#lef t+kids( i ) ) ,eT~0 kid~q_ 1 if c &lt; 0 Figure 2: tligh-level views of model A (formuhrs I 3); model l:l (forinul;t 4); and model C (lbrmula, 5).
  If i and j are tokens, then tword(i) represents he pair (tag(i), word(i)), and L,j C {0, 1} i~ ~ ill" i is the p~m:nt of j. exactly one parent.
  Rather than having the model select a subset of the ~2 possible links, as in model A, and then discard the result unless each word has exactly one parent, we might restrict the model to picking out one parent per word to be- gin with.
  Model B generates a sequence of t