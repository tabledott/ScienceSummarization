y good or bad on the same data sets: the performance is better for all features on W9-10 and W9-04 than on W9-22 and W9-33 (except for the ugen-4-grams, which occur with very low frequency, and the verbs, which have low frequency in W9-10).
    This is so despite the fact that the features were generated using different procedures and data: The Algorithm for calculating density in subjective-element data. adjectives and verbs were generated from WSJ document-level opinion piece classifications; the n-gram features were generated from newsgroup and WSJ expression-level subjective-element classifications; and the unique unigram feature requires no training.
    This consistency in performance suggests that the results are not brittle.
    In Wiebe (1994), whether a PSE is interpreted to be subjective depends, in part, on how subjective the surrounding context is.
    We explore this idea in the current work, assessing whether PSEs are more likely to be subjective if they are surrounded by subjective elements.
 