we applied 10-fold cross-validation on the Web corpus (Kohavi 1995).
    This chooses ten random partitions for each grade&#8217;s training data such that 90% is used for training and 10% held back as a test set.
    Second, we used two previously unseen test sets: a set of 228 leveled documents from Reading A-Z.com, spanning grade 1 through grade 6; and 17 stories from Diagnostic Reading Scales (DRS) spanning grades 1.4 through 5.5.
    The Reading A-Z files were converted from PDF files using optical character recognition; spelling errors were corrected but sentence boundary errors were left intact to simulate the kinds of problems encountered with Web documents.
    The DRS files were noise-free.
    Because the Smoothed Unigram classifier only models semantic and not syntactic difficulty, we compared its accuracy to predictions based on three widely-used semantic difficulty variables as shown below.
    All prediction methods used a 100-token window size. ative to a large English corpus.
    This is appro