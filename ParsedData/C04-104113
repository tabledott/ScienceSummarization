
			Calculation of these val ues requires all derivations for each sentence in the training data.
			In Clark and Curran (2004) wedescribe efficient methods for performing the cal culations using packed charts.
			However, a very large amount of memory is still needed to store the packed charts for the complete training data even though the representation is very compact; in Clark and Curran (2003) we report a memory usage of 30 GB.
			To handle this we have developed a parallel implementation of the estimation algorithm which runs on a Beowulf cluster.
			The need for large high-performance computing resources is a disadvantage of our earlier approach.In the next section we show how use of the supertag ger, combined with normal-form constraints on thederivations, can significantly reduce the memory re quirements for the model estimation.
	
	
			Since the training data contains the correct lexicalcategories, we ensure the correct category is as signed to each word when generating the packed charts for model e