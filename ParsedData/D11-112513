d these parameters by trial-and-error experimentation on a single MT system (Urdu-English SBMT), then held them fixed throughout our experiments.
    We obtained similar results using P = = 100, and for each a logistic sigmoid function centered at the mean g differential of candidate translation pairs for the ith source sentence.
    This alternative approach has the advantage of being agnostic about which gold scoring function is used. the sampling settings previously described and MegaM as our classifier we were able to optimize two to three times faster than with but added noise to each feature vector, drawn from a zero-mean Gaussian with a standard deviation of 500.
    The results of the noisy synthetic experiments, but still The idea of learning from difference vectors also lies at the heart of the MIRA-based approaches (Watanabe et al., 2007; Chiang et al., 2008b) and the approach of Roth et al. (2010), which, similar to our method, uses sampling to select vectors.
    Here, we isolate these aspects of