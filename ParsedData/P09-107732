ped to capture word polarity, verb classes and orientation, as well as some lexical features are strong indicators of the type of discourse relation.
    We analyze word pair features used in prior work that were intended to capture such semantic oppositions.
    We show that the features in fact do not capture semantic relation but rather give information about function word co-occurrences.
    However, they are still a useful source of information for discourse relation prediction.
    The most beneficial application of such features is when they are selected from a large unannotated corpus of explicit relations, but then trained on manually annotated implicit relations.
    Context, in terms of paragraph boundaries and nearby explicit relations, also proves to be useful for the prediction of implicit discourse relations.
    It is helpful when added as a feature in a standard, instance-by-instance learning model.
    A sequence model also leads to over 1% absolute improvement for the task.
  
  
    This w