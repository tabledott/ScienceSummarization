		shows that such a term in the skew divergence sum is again approximated by ? pi.
			ZKL does not have this property.
			Because ZKL is a better approximation to KL divergence and because they havethe same behavior in the limit, we expect ZKL?s performance to dominate that of skew divergence in many distributions.
			However, if there is a wide range in the ex ponent of noisy terms, the maximum possible penalty tosuch terms ascribed by skew divergence may be benefi cial.
			Figure 3 shows the relative performance of ZKL versus Jensen-Shannon, skew divergence, cosine similarity, and the Jaccard score (a measure from information retrieval) for correlations with human judgment on the MarkovLink model.
			ZKL consistently outperforms the other measures on distributions resulting from this model, but ZKL is not optimal on distributions generated by our other models.
			The next section explores this topic in more detail.
	
	
			Traditionally, there have been two primary types of evaluation for measures of semanti