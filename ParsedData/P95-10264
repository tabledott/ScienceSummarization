nd predicate-argument association).
    The training procedure computes the word-sense probability distributions for all such collocations, and orders them by the log-likelihood ratio Log( r4S enseAlCollocation,)\ 5 Sensealeollocatton,)), with optional steps for interpolation and pruning.
    New data are classified by using the single most predictive piece of disambiguating evidence that appears in the target context.
    By not combining probabilities, this decision-list approach avoids the problematic complex modeling of statistical dependencies 'It is interesting to speculate on the reasons for this phenomenon.
    Most of the tendency is statistical: two distinct arbitrary terms of moderate corpus frequency are quite unlikely to co-occur in the same discourse whether they are homographs or not.
    This is particularly true for content words, which exhibit a &amp;quot;bursty&amp;quot; distribution.
    However, it appears that human writers also have some active tendency to avoid mixing senses within a d