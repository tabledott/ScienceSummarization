d a clustering for each test document set.
			Finally, after the evaluation period was finishedand all the participants sent their data, the task orga nizers sent the evaluation for the test data.
	
	
			29 teams expressed their interest in the task; thisnumber exceeded our expectations for this pilot ex perience, and confirms the potential interest of theresearch community in this highly practical prob lem.
			Out of them, 16 teams submitted results within the deadline; their results are reported below.
			3.1 Results and discussion.
			Table 3 presents the macro-averaged results ob tained by the sixteen systems plus the two baselineson the test data.
			We found macro-average 3 preferable to micro-average 4 because it has a clear inter pretation: if the evaluation measure is F, then we should calculate F for every test case (person name) and then average over all trials.
			The interpretation of micro-average F is less clear.
			The systems are ranked according to the scores obtained with the harmonic mean 