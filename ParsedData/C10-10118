the elapsed time to extract the features.
			The next columns illustrate the parsing time in milliseconds per sentence for the test set, training time in hours, the number of sentences in the training set, the total number of features in million, the labeled attachment score of the test set, and the unlabeled attachment score.
			Algorithm 1: Training ? baseline algorithm ? = {(xi, yi)}Ii=1 // Training data??w = 0,??v = 0 ? = E ? I // passive-aggresive update weight for i = 1 to I tss+e; extract-and-store-features(xi); tes+e; for n = 1 to E // iteration over the training epochs for i = 1 to I // iteration over the training examples k ?
			(n? 1) ? I + i ? = E ? I ? k + 2 // passive-aggressive weight tsr,k; A = read-features-and-calc-arrays(i,??w ) ; ter,k tsp,k; yp = predicte-projective-parse-tree(A);tep,k tsa,k; ya = non-projective-approx.(yp ,A); tea,k update ??w , ??v according to ?(yp, yi) and ? w = v/(E ? I) // average dren ?h,d,g where h, d, g, and s are the indexes of the words included in xi.
			Final