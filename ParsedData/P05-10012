ount of labeled data and have not been shown to improve state-of-the-art performance when a large amount of labeled data is available.
    Our goal has been to develop a general learning framework for reliably using unlabeled data to improve performance irrespective of the amount of labeled data available.
    It is exactly this important and difficult problem that we tackle here.
    This paper presents a novel semi-supervised method that employs a learning framework called structural learning (Ando and Zhang, 2004), which seeks to discover shared predictive structures (i.e. what good classifiers for the task are like) through jointly learning multiple classification problems on unlabeled data.
    That is, we systematically create thousands of problems (called auxiliary problems) relevant to the target task using unlabeled data, and train classifiers from the automatically generated &#8216;training data&#8217;.
    We learn the commonality (or structure) of such many classifiers relevant to the task, and us