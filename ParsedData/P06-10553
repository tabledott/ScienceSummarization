ngths of both manual and automatic approaches while addressing some of their common shortcomings.
    Like Matsuzaki et al. (2005) and Prescher (2005), we induce splits in a fully automatic fashion.
    However, we use a more sophisticated split-and-merge approach that allocates subsymbols adaptively where they are most effective, like a linguist would.
    The grammars recover patterns like those discussed in Klein and Manning (2003), heavily articulating complex and frequent categories like NP and VP while barely splitting rare or simple ones (see Section 3 for an empirical analysis).
    Empirically, hierarchical splitting increases the accuracy and lowers the variance of the learned grammars.
    Another contribution is that, unlike previous work, we investigate smoothed models, allowing us to split grammars more heavily before running into the oversplitting effect discussed in Klein and Manning (2003), where data fragmentation outweighs increased expressivity.
    Our method is capable of learning gramma