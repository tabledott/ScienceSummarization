ple models like n-gram language models (Teahan et al, 2000), another shortcomingof CRF-based segmenters is that it requires signifi cantly longer training time.
			However, training is a one-time process, and testing time is still linear in the length of the input.
	
	
			The contribution of this paper is three-fold.
			First, we apply CRFs to Chinese word segmentation and find that they achieve state-of-the art performance.Second, we propose a probabilistic new word de tection method that is integrated in segmentation, and show it to improve segmentation performance.
			Third, as far as we are aware, this is the first work to comprehensively evaluate on the four benchmark datasets, making a solid baseline for future research on Chinese word segmentation.
			AcknowledgmentsThis work was supported in part by the Center for Intelligent Information Retrieval, in part by The Cen tral Intelligence Agency, the National Security Agencyand National Science Foundation under NSF grant #IIS 0326249, and in part by SPAWA