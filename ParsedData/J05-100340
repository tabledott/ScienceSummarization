xamples.
    The log-likelihood of the training data is Under maximum-likelihood estimation, the parameters a&#175; would be set to maximize the log-likelihood.
    Equivalently, we again talk about minimizing the negative log-likelihood.
    Some manipulation shows that the negative log-likelihood is a function of the margins on training data: Note the similarity of equation (9) to the LogLoss function for classification in equation (4). described in Schapire and Singer (1999).
    It is a special case of the general ranking methods described in Freund et al. (1998), with the ranking &#8220;feedback&#8221;being a simple binary distinction between the highest-scoring parse and the other parses.
    Again, the loss function is a function of the margins on training data: Note the similarity of equation (10) to the ExpLoss function for classification in equation (6).
    It can be shown that ExpLoss&#240;&#175;a&#222; &gt; Error&#240;&#175;a&#222;, so that minimizing ExpLoss&#240;&#175;a&#222; is closely related