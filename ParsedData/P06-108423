t, according to Levinger et al. (1995) approximations, with accuracy of 78.2%, as the baseline tagger, four steps of error reduction can be identified.
    (1) Contextual information: The simplest first-order word-based HMM with uniform initial conditions, achieves error reduction of 17.5% (78.2 &#8211; 82.01).
    (2) Initial conditions: Error reductions in the range: 11.5% &#8211; 37.8% (82.01 &#8211; 84.08 for word model 1, and 81.53 &#8211; 88.5 for morhpeme model 2-) were achieved by initializing the various models with context-free approximations.
    While this observation confirms Elworthy (1994), the impact of error reduction is much less than reported there for English - about 70% (79 &#8211; 94).
    The key difference (beside the unclear characteristic of Elworthy initial condition - since he made use of an annotated corpus) is the much higher quality of the uniform distribution for Hebrew.
    (3) Model order: The partial second-order HMM [2-] produced the best results for both word (85.75%) and 