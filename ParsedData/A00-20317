ented at least once in the denominator.
    For example: in figure 3 we have a small feature tree that has one target feature and four conditioning features.
    Features b and d are independent of each other, but each depends on a; c depends directly only on b.
    The unsmoothed version of the corresponding equation would be which, after cancelling of terms and smoothing, results in Note that strictly speaking the result is not a probability distribution.
    It could be made into one with an appropriate normalisation&#8212;the so-called partition function in the maximumentropy literature.
    However, if the independence assumptions made in the derivation of equation 4 are good ones, the partition function will be close to 1.0.
    We assume this to be the case for our feature trees.
    Now we return the discussion to function tagging.
    There are a number of features that seem tar et feature to condition strongly for one function tag or another; we have assembled them into the feature tree shown in fig