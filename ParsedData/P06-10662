n view of content-independency of the distortion and flat reordering models, several researchers (Och et al., 2004; Tillmann, 2004; Kumar et al., 2005; Koehn et al., 2005) proposed a more powerful model called lexicalized reordering model that is phrase dependent.
    Lexicalized reordering model learns local orientations (monotone or non-monotone) with probabilities for each bilingual phrase from training data.
    During decoding, the model attempts to finding a Viterbi local orientation sequence.
    Performance gains have been reported for systems with lexicalized reordering model.
    However, since reorderings are related to concrete phrases, researchers have to design their systems carefully in order not to cause other problems, e.g. the data sparseness problem.
    Another smart reordering model was proposed by Chiang (2005).
    In his approach, phrases are reorganized into hierarchical ones by reducing subphrases to variables.
    This template-based scheme not only captures the reorderings of phras