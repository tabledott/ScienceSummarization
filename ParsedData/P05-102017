aseline results are shown in rows 1 and 2 of Table 3, where performance is reported in terms of recall, precision, and F-measure.
    As we can see, the N&amp;C system outperforms the Duplicated Soon system by about 2-6% on the three ACE data sets.
    Our approach.
    Recall that our approach uses labeled data to train both the coreference classifiers and the ranking model.
    To ensure a fair comparison of our approach with the baselines, we do not rely on additional labeled data for learning the ranker; instead, we use half of the training texts for training classifiers and the other half for ranking purposes.
    Results using our approach are shown in row 3 of Table 3.
    Our ranking model, when trained to optimize for F-measure using both partition-based features and method-based features, consistently provides substantial gains in F-measure over both baselines.
    In comparison to the stronger baseline (i.e., N&amp;C), F-measure increases by 7.4, 7.2, and 4.6 for the BNEWS, NPAPER, and NWIRE data s