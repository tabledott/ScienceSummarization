that the two words are similar, then we may infer that they have similar mutual information with some other word, w. This inference would be reasonable if we find that on average wi and w2 indeed have similar mutual information values with other words in the lexicon.
    The similarity metric therefore measures the degree of similarity between these mutual information values.
    We first define the similarity between the mutual information values of w1 and w2 relative to a single other word, w. Since cooccurrence pairs are directional, we get two measures, defined by the position of w in the pair.
    The left context similarity of w1 and w2 relative to w, termed simi, (wi, w2, w), is defined as the ratio between the two mutual information values, having the larger value in the denominator: min(/(w, w1), /(w, w2)) max(/(w, w1), /(w, w2)) This way we get a uniform scale between 0 and 1, in which higher values reflect higher similarity.
    If both mutual information values are 0, then simi,(wlw2, w) is define