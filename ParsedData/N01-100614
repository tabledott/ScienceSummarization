 (rather than recomputed) at each iteration, and only for the samples that were affected by the application of the latest rule learned.
    Since the number of affected samples decreases as learning progresses, our algorithm actually speeds up considerably towards the end of the training phase.
    Considering that the number of low-score rules is a considerably higher than the number of high-score rules, this leads to a dramatic reduction in the overall running time.
    This has repercussions on the scalability of the algorithm relative to training data size.
    Since enlarging the training data size results in a longer score distribution tail, our algorithm is expected to achieve an even more substantial relative running time improvement over the original algorithm.
    Section 4 presents experimental results that validate the superior scalability of the FastTBL algorithm.
  
  
    Since the goal of this paper is to compare and contrast system training time and performance, extra measures were taken to e