on individual mentions, the performance decreases.
    Additionally, LabeledLDA&#8217;s performance is poorer when considering mentions as &#8220;documents&#8221;.
    This is likely due to the fact that there isn&#8217;t enough context to effectively learn topics when the &#8220;documents&#8221; are very short (typically fewer than 10 words).
    End to End System: Finally we present the end to end performance on segmentation and classification (T-NER) in Table 12.
    We observe that T-NER again outperforms co-training.
    Moreover, comparing against the Stanford Named Entity Recognizer on the 3 MUC types, T-NER doubles FI score.
  
  
    There has been relatively little previous work on building NLP tools for Twitter or similar text styles.
    Locke and Martin (2009) train a classifier to recognize named entities based on annotated Twitter data, handling the types PERSON, LOCATION, and ORGANIZATION.
    Developed in parallel to our work, Liu et al. (2011) investigate NER on the same 3 types, in addition