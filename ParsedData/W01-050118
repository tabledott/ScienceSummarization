limiting the number of unlabeled examples under consideration with the hope of forcing broader task coverage we achieve essentially the goal accuracy in fewer iterations and with fewer corrections!
    Surprisingly, the error rate of the view classifiers per iteration remains essentially unchanged despite the reduction of the pool of unlabeled examples to choose from.
    We believe the preceding experiment illuminates a fundamental tension in weakly supervised learning, between automatically obtaining reliable training data (usually requiring familiar examples), and adequately covering the learning task (usually requiring unfamiliar examples).
    This tension suggests that combining weakly supervised learning methods with active learning methods might be a fruitful endeavor.
    On one hand, the goal of weakly supervised learning is to bootstrap a classifier from small amounts of labeled data and large amounts of unlabeled data, often by automatically labeling some of the unlabeled data.
    On the other ha