hrase chunking.
    We also discuss a novel capitalization classifier in &#167;2.3.
    The outputs of all these classifiers are used in feature generation for named entity recognition in the next section.
    For all experiments in this section we use a dataset of 800 randomly sampled tweets.
    All results (Tables 2, 4 and 5) represent 4-fold cross-validation experiments on the respective tasks.3 Part of speech tagging is applicable to a wide range of NLP tasks including named entity segmentation and information extraction.
    Prior experiments have suggested that POS tagging has a very strong baseline: assign each word to its most frequent tag and assign each Out of Vocabulary (OOV) word the most common POS tag.
    This baseline obtained a 0.9 accuracy on the Brown corpus (Charniak et al., 1993).
    However, the application of a similar baseline on tweets (see Table 2) obtains a much weaker 0.76, exposing the challenging nature of Twitter data.
    A key reason for this drop in accuracy is that Twitter