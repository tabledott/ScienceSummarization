
    The task of automated assessment of free text focuses on automatically analysing and assessing the quality of writing competence.
    Automated assessment systems exploit textual features in order to measure the overall quality and assign a score to a text.
    The earliest systems used superficial features, such as word and sentence length, as proxies for understanding the text.
    More recent systems have used more sophisticated automated text processing techniques to measure grammaticality, textual coherence, prespecified errors, and so forth.
    Deployment of automated assessment systems gives a number of advantages, such as the reduced workload in marking texts, especially when applied to large-scale assessments.
    Additionally, automated systems guarantee the application of the same marking criteria, thus reducing inconsistency, which may arise when more than one human examiner is employed.
    Often, implementations include feedback with respect to the writers&#8217; writing abilities, thus fa