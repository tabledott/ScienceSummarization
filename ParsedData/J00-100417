ions when no complete derivations are available.
  
  
    Our training method for head transducer models only requires a set of training examples.
    Each example, or bitext, consists of a source language string paired with a target language string.
    In our experiments, the bitexts are transcriptions of spoken English utterances paired with their translations into Spanish or Japanese.
    It is worth emphasizing that we do not necessarily expect the dependency representations produced by the training method to be traditional dependency structures for the two languages.
    Instead, the aim is to produce bilingual (i.e., synchronized, see below) dependency representations that are appropriate to performing the translation task for a specific language pair or specific bilingual corpus.
    For example, headwords in both languages are chosen to force a synchronized alignment (for better or worse) in order to simplify cases involving so-called head-switching.
    This contrasts with one of the traditional ap