).
    In this split, sections from 02 to 21 are used for training, section 23 for testing and sections 1 and 22 as developing set.
    We considered a total of 122,774 and 7,359 arguments (from ARG0 to ARG9, ARGA and ARGM) in training and testing, respectively.
    Their tree structures were extracted from the Penn Treebank.
    It should be noted that the main contribution to the global accuracy is given by ARG0, ARG1 and ARGM.
    From the FrameNet corpus (http://www.icsi .berkeley.edu/&#8764;framenet), we extracted all 24,558 sentences of the 40 Frames selected for the Automatic Labeling of Semantic Roles task of Senseval 3 (www.senseval.org).
    We mapped together the semantic roles having the same name and we considered only the 18 most frequent roles associated with verbal predicates, for a total of 37,948 arguments.
    We randomly selected 30% of sentences for testing and 70% for training.
    Additionally, 30% of training was used as a validationset.
    Note that, since the FrameNet data does not 