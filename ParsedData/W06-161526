Ando (2004), who analyzed a situation with no target domain labeled data.
    Her model estimated co-occurrence counts from source unlabeled data and then used the SVD of this matrix to generate features for a named entity recognizer.
    Our ASO baseline uses unlabeled data from the target domain.
    Since this consistently outperforms unlabeled data from only the source domain, we report only these baseline results.
    To the best of our knowledge, this is the first work to use unlabeled data from both domains to find feature correspondences.
    One important advantage that this work shares with Ando (2004) is that an SCL model can be easily combined with all other domain adaptation techniques (Section 7.2).
    We are simply inducing a feature representation that generalizes well across domains.
    This feature representation can then be used in all the techniques described above.
  
  
    Structural correspondence learning is a marriage of ideas from single domain semi-supervised learning and domain 