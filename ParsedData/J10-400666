rather than on task-specific optimization.
    As a first, important step in this latter direction, however, we conclude the empirical evaluation in Section 6.5 by replicating one experiment using tensor-decomposition-based smoothing, a form of optimization that can only be performed within the tensor-based approach to DSMs.
    In order to maximize coverage of the experimental test sets, they are pre-processed with a mixture of manual and heuristic procedures to assign a POS to the words they contain, lemmatize, convert some multiword forms to single words, and turn some adverbs into adjectives (our models do not contain multiwords or adverbs).
    Nevertheless, some words (or word pairs) are unrecoverable, and in such cases we make a random guess (in cases where we do not have full coverage of a data set, the reported results are averages across repeated experiments, to account for the variability in random guesses).
    In many of the experiments herein, DM is not only compared to the results available in 