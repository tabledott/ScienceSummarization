s that are topically related can appear in the same textual passages and will get high values using this model.
    We see this as an explanation why this model performed better than the context window approach for WordSim353, where annotators were instructed to provide high ratings to related terms.
    On the contrary, the context window approach tends to group together words that are exchangeable in exactly the same context, preserving order.
    Table 2 illustrates a few examples of context collected.
    Therefore, true synonyms and hyponyms/hyperonyms will receive high similarities, whereas terms related topically or based on any other semantic relation (e.g. movie and star) will have lower scores.
    This explains why this method performed better for the RG dataset.
    Section 5.3 confirms these observations.
    Table 3 shows the results for the English-Spanish cross-lingual datasets.
    For RG, MCR16 and the context windows methods drop only 5 percentage points, showing that cross-lingual similari