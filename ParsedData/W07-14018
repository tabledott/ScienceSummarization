and a test set.
    While the length of the hypotheses (h) was the same as in the past datasets, a certain number of texts (t) were longer than in previous datasets, up to a paragraph.
    The longer texts were marked as L, after being selected automatically when exceeding 270 bytes.
    In the test set they were about 17% of the total.
    As in RTE-2, four applications &#8211; namely IE, IR, QA and SUM &#8211; were considered as settings or contexts for the pairs generation (see 2.2 for a detailed description).
    200 pairs were selected for each application in each dataset.
    Although the datasets were supposed to be perfectly balanced, the number of negative examples were slightly higher in both development and test sets (51.50% and 51.25% respectively; this was unintentional).
    Positive entailment examples, where t entailed h, were annotated YES; the negative ones, where entailment did not hold, NO.
    Each pair was annotated with its related task (IE/IR/QA/SUM) and entailment judgment (YES/NO, ob