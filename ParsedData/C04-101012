h.
			We have experimented with two different statemodels, one that incorporates all the features depicted in Figure 2 (Model 1), and one that ex cludes the parts-of-speech of TH, TL, TR, NL (Model 2).
			Models similar to model 2 have been found towork well for datasets with a rich annotation of de pendency types, such as the Swedish dependency treebank derived from Einarsson (1976), where the extra part-of-speech features are largely redundant (Nivre et al, 2004).
			Model 1 can be expected towork better for datasets with less informative dependency annotation, such as dependency trees ex tracted from the Penn Treebank, where the extra part-of-speech features may compensate for the lack of information in arc labels.
			The learning algorithm used is the IB1 algorithm (Aha et al, 1991) with k = 5, i.e. classification basedon 5 nearest neighbors.4 Distances are measured us ing the modified value difference metric (MVDM) (Stanfill and Waltz, 1986; Cost and Salzberg, 1993) for instances with a frequency of at l