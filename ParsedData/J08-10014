 evaluation&#8212;as ranking problems, and present an efficiently learnable model that ranks alternative renderings of the same information based on their degree of local coherence.
    Such a mechanism is particularly appropriate for generation and summarization systems as they can produce multiple text realizations of the same underlying content, either by varying parameter values, or by relaxing constraints that control the generation process.
    A system equipped with a ranking mechanism could compare the quality of the candidate outputs, in much the same way speech recognizers employ language models at the sentence level.
    In the text-ordering task our algorithm has to select a maximally coherent sentence order from a set of candidate permutations.
    In the summary evaluation task, we compare the rankings produced by the model against human coherence judgments elicited for automatically generated summaries.
    In both experiments, our method yields improvements over state-of-the-art models.
    We