rmined from the probabilities.
    Two algorithms are commonly used, known as the Forward-Backward (FB) and Viterbi algorithms.
    FB assigns a probability to every tag on every word, while Viterbi prunes tags which cannot be chosen because their probability is lower than the ones of competing hypotheses, with a corresponding gain in computational ef
  
  
    Part-of-speech tagging is the process of assigning grammatical categories to individual words in a corpus.
    One widely used approach makes use of a statistical technique called a Hidden Markov Model (HMM).
    The model is defined by two collections of parameters: the transition probabilities, which express the probability that a tag follows the preceding one (or two for a second order model); and the lexical probabilities, giving the probability that a word has a given tag without regard to words on either side of it.
    To tag a text, the tags with non-zero probability are hypothesised for each word, and the most probable sequence of tags given t