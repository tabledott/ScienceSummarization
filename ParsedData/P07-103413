rust the labeled instance (xsi , ysi ) for the purpose of learning a classifier for the target domain.
    Small &#945;i means these two probabilities are very different, and therefore we should probably discard the instance (xsi , ysi ) in the learning process.
    Second, again for each (xsi, ysi ) E Ds, we introduce another parameter Qi that ideally is equal to pt(xs i ) ps(xs i ).
    From the approximation in Section 2.3 that uses only Ds, it is clear that such a parameter is useful.
    Next, for each xt,u i E Dt,u, and for each possible label y E Y, we introduce a parameter -yi(y) that indicates how likely we would like to assign y as a tentative label to xt,u iand include (xt,u i , y) as a training example.
    Finally, we introduce three global parameters As, At,l and At,u that are not instance-specific but are associated with Ds, Dt,l and Dt,u, respectively.
    These three parameters allow us to control the contribution of each of the three approximation methods in Section 2.3 when we linearly comb