loped a &#8220;smoothed unigram&#8221; classifier to better capture the variance in word usage across grade levels (Collins-Thompson and Callan, 2004).
    On web text, their classifier outperformed several other measures of semantic difficulty: the fraction of unknown words in the text, the number of distinct types per 100 token passage, the mean log frequency of the text relative to a large corpus, and the Flesch-Kincaid measure.
    The traditional measures performed better on some commercial corpora, but these corpora were calibrated using similar measures, so this is not a fair comparison.
    More importantly, the smoothed unigram measure worked better on the web corpus, especially on short passages.
    The smoothed unigram classifier is also more generalizable, since it can be trained on any collection of data.
    Traditional measures such as Dale-Chall and Lexile are based on static word lists.
    Although the smoothed unigram classifier outperforms other vocabulary-based semantic measures, it does