d than the probability of a determiner is.
    Yet in the current model they are both conditioned on that head, as leftmost constituents of their respective phrases.
    Second, there are advantages to top-down parsing that have not been examined to date, e.g., empty categories.
    A top-down parser, in contrast to a standard bottom-up chart parser, has enough information to predict empty categories only where they are likely to occur.
    By including these nodes (which are in the original annotation of the Penn Treebank), we may be able to bring certain long-distance dependencies into a local focus.
    In addition, as mentioned above, we would like to further test our language model in speech recognition tasks, to see if the perplexity improvement that we have seen can lead to significant reductions in word error rate.
    Other parsing approaches might also be used in the way that we have used a topdown parser.
    Earley and left-corner parsers, as mentioned in the introduction, also have rooted derivat