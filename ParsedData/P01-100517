 Bayes classifiers described above.
    All instances from the remainder of the corpus on which all 10 classifiers agreed were selected, trusting the agreed-upon label.
    The classifiers were then retrained using the labeled seed corpus plus the new training material collected automatically during the previous step.
    In Table 3 we show the results from these unsupervised learning experiments for two confusion sets.
    In both cases we gain from unsupervised training compared to using only the seed corpus, but only up to a point.
    At this point, test set accuracy begins to decline as additional training instances are automatically harvested.
    We are able to attain improvements in accuracy for free using unsupervised learning, but unlike our learning curve experiments using correctly labeled data, accuracy does not continue to improve with additional data.
    Charniak (1996) ran an experiment in which he trained a parser on one million words of parsed data, ran the parser over an additional 30 mill