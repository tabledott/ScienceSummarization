othesis, viz., that the lexicalized models do not cope well with the fact that Negra rules are so flat (see Section 2.2).
    We will focus on the Collins model, as it outperformed the C&amp;R model in Experiment 1.
    An error analysis revealed that many of the errors of the Collins model in Experiment 1 are chunking errors.
    For example, the PP neben den Mitteln des Theaters should be analyzed as (6a).
    But instead the parser produces two constituents as in (6b)): The reason for this problem is that neben is the head of the constituent in (6), and the Collins model uses a crude distance measure together with head-head dependencies to decide if additional constituents should be added to the PP.
    The distance measure is inadequate for finding PPs with high precision.
    The chunking problem is more widespread than PPs.
    The error analysis shows that other constituents, including Ss and VPs, also have the wrong boundary.
    This problem is compounded by the fact that the rules in Negra are subst