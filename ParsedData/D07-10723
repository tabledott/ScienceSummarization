sumptions.
			As a result, many generative approaches to parsing construct refinements of the treebankgrammar which are more suitable for the model ing task.
			Lexical methods split each pre-terminal symbol into many subsymbols, one for each word,and then focus on smoothing sparse lexical statis 688 tics (Collins, 1999; Charniak, 2000).
			Unlexicalized methods refine the grammar in a more conservative fashion, splitting each non-terminal or pre-terminal symbol into a much smaller number of subsymbols (Klein and Manning, 2003; Matsuzaki et al, 2005; Petrov et al, 2006).
			We apply our HDP-PCFG-GRmodel to automatically learn the number of subsym bols for each symbol.
	
	
			At the heart of the HDP-PCFG is the Dirichlet pro cess (DP) mixture model (Antoniak, 1974), which isthe nonparametric Bayesian counterpart to the clas sical finite mixture model.
			In order to build up an understanding of the HDP-PCFG, we first review the Bayesian treatment of the finite mixture model (Section 2.1).
			We then consider t