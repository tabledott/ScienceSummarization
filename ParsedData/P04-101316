ich the current network assigns to that parse, then computing the first derivative of (the negative log of) this probability with respect to each of the network&#8217;s parameters, and then updating the parameters proportionately to this derivative.3 The third neural network combines the advantages of the generative probability model with the advantages of the discriminative optimization criteria.
    The structure of the network and the set of outputs which it computes are exactly the same as the above network for the generative model.
    But the training procedure is designed to maximize the conditional probability of the parses in the training corpus given the sentences in the training corpus.
    The conditional probability for a sentence can be computed from the joint probability of the generative model by normalizing over the set of all parses d&#57739;1,..., d&#57739;m&#57740; for the sentence.
    So, with this approach, we need to maximize this normalized probability, and not the probability compute