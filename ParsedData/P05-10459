ential at position i corresponding to states si&#8722;1 and si.3 Although a full treatment of CRF training is beyond the scope of this paper (our technique assumes the model is already trained), we list the features used by our CRF for the two tasks we address in Table 2.
    During training, we regularized our exponential models with a quadratic prior and used the quasi-Newton method for parameter optimization.
    As is customary, we used the Viterbi algorithm to infer the most likely state sequence in a CRF.
    The clique potentials of the CRF, instantiated for some observation sequence, can be used to easily compute the conditional distribution over states at a position given in Equation 1.
    Recall that at position i we want to condition on the states in the rest of the sequence.
    The state at this position can be influenced by any other state that it shares a clique with; in particular, when the clique size is 2, there are 2 such cliques.
    In this case the Markov blanket of the state (the minim