 also provide the lexical head structure of the parse?
  Then, we extracted using leftmost derivation order tuples of a his- tory (truncated to the definition of a history in the HBG model) and the corresponding rule used in expanding a node.
  Using the resulting data set we built a decision tree by classifying histories to locally minimize the en- tropy of the rule template.
  With a training set of about 9000 sentence-tree pairs, we had about 240,000 tuples and we grew a tree with about 40,000 nodes.
  This required 18 hours on a 25 MIPS RISC-based machine and the resulting decision tree was nearly 100 megabytes.
  Immediate  vs.  Funct iona l  Parents The HBG model employs two types of parents, the im- mediate parent and the functional parent.
  The immedi- ate parent is the constituent that immediately dominates with R: PP i Syn:  PP Sem: Wi th -Data Hi:  l i s t H2 : w i th Sem: Data Hi: l i s t H2: a Syn:  N a Sem: Data Hi:  l i s t H2: * I l i s t Figure 3: Sample representation f "with a list" in HBG