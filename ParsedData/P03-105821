 the accuracy figures of M3 and P2 averaged over the set of all difficult nouns is 0.065.
    That is, eliminating the advantage that manually sense-tagged data have in their sense coverage would reduce the performance gap between the two approaches from 0.140 to 0.065.
    Notice that this reduction is particularly significant for the noun circuit.
    For this noun, the parallel corpora do not have enough training examples for sense 4 and sense 5 of circuit, and these two senses constitute approximately 23% in each of the 10-trial test set.
    We believe that the remaining difference of 0.065 between the two approaches could be attributed to the fact that the training and test examples of the manually sense-tagged corpus, while not coming from the same document, are however still drawn from the same general domain.
    To illustrate, we consider the noun channel where the difference between M3 and P2 is the largest.
    For channel, it turns out that a substantial number of the training and test examples c