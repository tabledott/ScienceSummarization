ds in the current article may be preferable on the grounds of both efficiency and simplicity.
    Even with large values of k in the approach of McCallum (2003) and Riezler and Vasserman (2004) (e.g., k = 1,000), the approach we describe is likely to be at least as efficient as these alternative approaches.
    In terms of simplicity, the methods in McCallum (2003) and Riezler and Vasserman (2004) require selection of a number of free parameters governing the behavior of the algorithm: the value for k, the value for a regularizer constant (used in both McCallum [2003] and Riezler and Vasserman [2004]), and the precision with which the model is optimized at each stage of feature selection (McCallum [2003] describes using &#8220;just a few BFGS iterations&#8221;at each stage).
    In contrast, our method requires a single parameter to be chosen (the value for the e smoothing parameter) and makes a single approximation (that only a single feature is updated at each round of feature selection).
    The latter app