rms of accuracy, we compare to a baseline approach of using the first-best tag sequence as input to the parser.
    The dual decomposition approach gives 88.3 F1 measure in recovering parsetree constituents, compared to 87.9 for the baseline.
  
  
    We have introduced dual-decomposition algorithms for inference in NLP, given formal properties of the algorithms in terms of LP relaxations, and demonstrated their effectiveness on problems that would traditionally be solved using intersections of dynamic programs (Bar-Hillel et al., 1964).
    Given the widespread use of dynamic programming in NLP, there should be many applications for the approach.
    There are several possible extensions of the method we have described.
    We have focused on cases where two models are being combined; the extension to more than two models is straightforward (e.g., see Komodakis et al. (2007)).
    This paper has considered approaches for MAP inference; for closely related methods that compute approximate marginals, see Wain