e report labeled recall (LR) labeled precision (LP), average crossing brackets (CBs), zero crossing brackets (0CB), and two or less crossing brackets (&lt;2CB).
    We also give the coverage (Cov), i.e., the percentage of sentences that the parser was able to parse.
  
  
    The results for all three models and their variants are given in Table 2, for both TnT tags and perfect tags.
    The baseline model achieves 70.56% LR and 66.69% LP with TnT tags.
    Adding grammatical functions reduces both figures slightly, and coverage drops by about 15%.
    The C&amp;R model performs worse than the baseline, at 68.04% LR and 60.07% LP (for TnT tags).
    Adding grammatical function again reduces performance slightly.
    Parameter pooling increases both LR and LP by about 1%.
    The Collins models also performs worse than the baseline, at 67.91% LR and 66.07% LP.
    Performance using perfect tags (an upper bound of model performance) is 2&#8211;3% higher for the baseline and for the C&amp;R model.
    The Collin