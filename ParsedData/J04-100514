riate for coding in discourse and dialogue work.
    In fact, it appears to us that it holds in few if any of the published discourse- or dialogue-tagging efforts for which &#954; has been computed.
    It is, for example, appropriate in situations in which item i may be tagged by different coders than item j (Fleiss 1971).
    However, &#954; assessments for discourse and dialogue tagging are most often performed on the same portion of the data, which has been annotated by each of a small number of annotators (between two and four).
    In fact, in many cases the analysis of systematic disagreements among annotators on the same portion of the data (i.e., of bias) can be used to improve the coding scheme (Wiebe, Bruce, and O&#8217;Hara 1999).
    To use &#954;Co but to guard against bias, Cicchetti and Feinstein (1990) suggest that &#954;Co be supplemented, for each coding category, by two measures of agreement, positive and negative, between the coders.
    This means a total of 2m additional measures, which