 further evidence that the task is challenging.
    This difficulty can be attributed in part to the large branching factor of possible actions at each step &#8212; on average, there are 27.14 choices per action in the Windows domain, and 9.78 in the Crossblock domain.
    In both domains, the learners relying only on environment reward perform well.
    Although the fully supervised approach performs the best, adding just a few annotated training examples to the environment-based learner significantly reduces the performance gap.
    Figure 5 shows the overall tradeoff between annotation effort and system performance for the two domains.
    The ability to make this tradeoff is one of the advantages of our approach.
    The figure also shows that augmenting annotated documents with additional environment-reward documents invariably improves performance.
    The word alignment results from Table 2 indicate that the learners are mapping the correct words to actions for documents that are successfully completed