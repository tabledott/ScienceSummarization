igram and the Senti-features model by 4.02% and 4.29% absolute, respectively.
    We note that this difference is much more pronounced comparing to the two way classification task.
    Once again, our 100 Senti-features perform almost as well as the unigram baseline which has about 13,000 features.
    We also experiment with the combination of models.
    For this classification task the combination of tree kernel with Senti-features outperforms the combination of unigrams with Senti-features by a small margin.
    This is our best performing system for the 3-way classification task, gaining 4.25% over the unigram baseline.
    The learning curve for the 3-way classification task is similar to the curve of the 2-way classification task, and we omit it.
    Table 9 presents classifier accuracy and F1measure when features are added incrementally.
    We start with our baseline unigram model and subsequently add various sets of features.
    First, we add all non-polar features (rows f5, f6, f7, f10 in Table 4)