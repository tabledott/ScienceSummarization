 more forgiving measures of (Collins, 1996) and (Magerman, 1995).
    Table 5 shows that the maximum entropy parser performs better than the parsers presented in (Collins, 1996) and (Magerman, 1995)2, which have the best previously published parsing accuracies on the Wall St. Journal domain.
    It is often advantageous to produce the top N parses instead of just the top 1, since additional information can be used in a secondary model that reorders the top N and hopefully improves the quality of the top ranked parse.
    Suppose there exists a &amp;quot;perfect&amp;quot; reranking scheme that, for each sentence, magically picks the best parse from the top N parses produced by the maximum entropy parser, where the best parse has the highest average precision and recall when compared to the treebank parse.
    The performance of this &amp;quot;perfect&amp;quot; scheme is then an upper bound on the performance of any reranking scheme that might be used to reorder the top N parses.
    Figure 9 shows that the &am