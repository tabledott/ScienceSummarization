eadings of fj by the morpho-syntactic analyzers on the basis of the whole-sentence context fJ1.
    We assume that the probability functions defined above yield zero for all other readings, that is, when Tj V T (fj).
    Under the usual independence assumption, which states that the probability of the translation of words depends only on the identity of the words associated with each other by the word alignment, we get As has been argued in Section 2.2, the number of readings |T (fj) |per word form can be reduced to one for the tasks for which experimental results are reported here.
    The elements in equation (4) are the joint probabilities p(f, T|e) off and the readings T of f given the target language word e. The maximum-entropy principle recommends choosing for p the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy, while requiring p to satisfy constraints which represent facts known from the data.
    These constraints are encoded on the basis of feature fu