y of the distribution given by each single model to the possible tags (classes), since we are only interested in the uncertainty of the final classification (see the discussion in Section 7).
    We consider two alternative selection criteria (for Step 4).
    The simplest is thresholded selection, in which an example is selected for annotation if its vote entropy exceeds some threshold O.
    The other alternative is randomized selection, in which an example is selected for annotation based on the flip of a coin biased according to the vote entropy&#8212;a higher vote entropy entailing a higher probability of selection.
    We define the selection probability as a linear function of vote entropy: p = gD, where g is an entropy gain parameter.
    The selection method we used in our earlier work (Dagan and Engelson, 1995) is randomized sequential selection using this linear selection probability model, with parameters k, t and g. An alternative to sequential selection is batch selection.
    Rather than evalua