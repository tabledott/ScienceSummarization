gan with an uppercase alphabetic character and contained at least one token from an English stop list.3 This fairly strict filter provided a set of approximately 7,000 pairs from which the 30 test items were sampled.
    Participants were asked to provide each pair of items with three ratings, assessing English fluency, Chinese fluency, and adequacy of the translation.
    The choice and wording of the ratings criteria were derived from the human evaluation measures proposed by Dabbadie et al. (2002), with the wording of the translation assessment criterion modified to eliminate references to the direction of translation.
    (See Appendix B.)
    For all three measures, the two judges&#8217; ratings were significantly correlated (p &lt; 0.0001).
    Figure 3 shows additional quantitative results of the assessment, comparing judgments among human-translated, Web-generated, and machine-translated data.
    The ratings indicate that pairs from the Web contain on average somewhere between &#8220;mostly the same 