 the word.
  We may thus imagine generating a Markov se- quence of tagged words as before, and then in- dependently "sense tagging" each word with a disjunct, a Choosing all the disjuncts does not quite specify a parse, llowever, if the disjuncts are sufficiently specific, it specifies at most one parse.
  Some sentences generated in this way are illegal because their disjuncts cannot be simulta- neously satisfied; as in model A, these sentences are said to be removed fiom the population, and the probabilities renormalized.
  A likely parse is therefore one that allows a likely and consistent aln our implementation, the distribution over pos- sible disjuncts is given by a pair of Markov processes, as in model C. set of sells(, tags; its probability in the population is given in (4).
  2.3 Mode l  C: Recurs ive  generat ion The final model we prol)ose is a generat ion model, as opposed l;o the comprehens ion  mo(l- els A and B (and to other comprehension modc, ls such as (l,afferty et al., 1992; Magerman, 1995