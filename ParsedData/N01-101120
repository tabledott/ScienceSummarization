s the number of bigram features selected by the decision tree learner.
    One of our original hypotheses was that accurate decision trees of bigrams will include a relatively small number of features.
    This was motivated by the success of decision stumps in performing disambiguation based on a single bigram feature.
    In these experiments, there were no decision trees that used all of the bigram features identified by the filtering step, and for many words the decision tree learner went on to eliminate most of the candidate features.
    This can be seen by comparing the number of internal nodes with the number of candidate features as shown in columns 4 or 7.1 It is also noteworthy that the bigrams ultimately selected by the decision tree learner for inclusion in the tree do not always include those bigrams ranked most highly by the power divergence statistic or the Dice Coefficient.
    This is to be expected, since the selection of the bigrams from raw text is only mea'For most words the 100 top rank