riants.
			ROUGE-S4 is the best performer but is only significantly better than ROUGE-S0 (bigram), ROUGE-S1, ROUGE-S9 and ROUGE-S*.
			The relatively worse performance of ROUGE-S* might to due to spurious matches such as ?the the?
			or ?the of?.
			Table 6 summarizes the performance of 7 different metrics.
			ROUGE-S4 (dark/green cell) is the best with an ORANGE score of 19.66% that is statistically equivalent to ROUGE-L and ROUGE W-1.1 (gray cells) and is significantly better than BLEUS6, NIST, PER, and WER.
			Among them PER is the worst.
			To examine the length effect of n-best lists on the relative performance of automatic metrics, we use the AlTemp SMT system to generate a 16384 best list and compute ORANGE scores for BLEUS4, PER, WER, ROUGE-L, ROUGE-W-1.2, and ROUGE-S4.
			Only 474 source sentences that have more than 16384 alternative translations are used in this experiment.
			Table 7 shows the results.
			It confirms that when we extend the length of the n best list to 16 times the size of the 102