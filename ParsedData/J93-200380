same as our Model 3.
    They sketch the EM algorithm and show that, once trained, their model can be used to extract word-by-word alignments for pairs of sentences.
    They did not realize that the logarithm of the likelihood for Model 1 is concave and, hence, has a unique local maximum.
    They were also unaware of the trick by which we are able to sum over all alignments when evaluating the counts for Models 1 and 2, and of the trick by which we are able to sum over all alignments when transferring parameters from Model 2 to Model 3.
    As a result, they were unable to handle large vocabularies and so restricted themselves to vocabularies of only 9,000 words.
    Nonetheless, they were able to align phrases in French with the English words that produce them as illustrated in their Figure 3.
    More recently, Gale and Church (1991a) describe an algorithm similar to the one described in Brown et al. (1988).
    Like Brown et al., they consider only the simultaneous appearance of words in pairs of sentenc