or typically represents its co-occurrence with neighboring words.
    The construction of the semantic space depends on the definition of linguistic context (e.g., neighbouring words can be documents or collocations), the number of components used (e.g., the k most frequent words in a corpus), and their values (e.g., as raw co-occurrence frequencies or ratios of probabilities).
    A hypothetical semantic space is illustrated in Figure 1.
    Here, the space has only five dimensions, and the matrix cells denote the co-occurrence of the target words (horse and run) with the context words animal, stable, and so on.
    Let p denote the composition of two vectors u and v, representing a pair of constituents which stand in some syntactic relation R. Let K stand for any additional knowledge or information which is needed to construct the semantics of their composition.
    We define a general class of models for this process of composition as: The expression above allows us to derive models for which p is construc