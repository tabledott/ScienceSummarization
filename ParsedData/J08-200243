of confusions of argument labels with NONE, shown in the NONE column, is larger than the number of confusions of NONE with argument labels, shown in the NONE row.
    This shows that the model generally has higher precision than recall.
    We experimented with the precision&#8211;recall tradeoff but this did not result in an increase in F-Measure.
    From the confusion matrix in Figure 7(c) we can see that the number of confusions between modifier argument labels is higher than the number of confusions between core argument labels.
    This corresponds to the ALL CLS F-Measure of 95.7 versus the CORE CLS F-Measure of 98.0.
    The per-label F-Measures in the last column show that the performance on some very frequent modifier labels is in the low sixties or seventies.
    The confusions between modifier labels and NONE are quite numerous.
    Thus, to improve the performance on CORE arguments, we need to improve recall without lowering precision.
    In particular, when the model is uncertain which of sever