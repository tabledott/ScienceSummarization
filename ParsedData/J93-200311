with the hope of landing on a good one.
    It is important, therefore, that our model for Pr(elf) concentrate its probability as much as possible on wellformed English strings.
    But it is not important that our model for POI e) concentrate its probability on well-formed French strings.
    If we were to reduce the probability of all well-formed French strings by the same factor, spreading the probability thus liberated over ill-formed French strings, there would be no effect on our translations: the argument that maximizes some function f(x) also maximizes cf(x) for any positive constant c. As we shall see below, our translation models are prodigal, spraying probability all over the place, most of it on ill-formed French strings.
    In fact, as we discuss in Section 4.5, two of our models waste much of their probability on things that are not strings at all, having, for example, several different second words but no first word.
    If we were to turn one of these models around to model Pr(elf) directly, 