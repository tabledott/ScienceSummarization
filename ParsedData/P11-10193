EA) (Landauer et al., 2003), IntelliMetric (Elliot, 2003; Rudner et al., 2006) and Project Essay Grade (PEG) (Page, 2003).
    Several of these are now deployed in highstakes assessment of examination scripts.
    Although there are many published analyses of the performance of individual systems, as yet there is no publically available shared dataset for training and testing such systems and comparing their performance.
    As it is likely that the deployment of such systems will increase, standardised and independent evaluation methods are important.
    We make such a dataset of ESOL examination scripts available1 (see Section 2 for more details), describe our novel approach to the task, and provide results for our system on this dataset.
    We address automated assessment as a supervised discriminative machine learning problem and particularly as a rank preference problem (Joachims, 2002).
    Our reasons are twofold: Discriminative classification techniques often outperform non-discriminative ones in th