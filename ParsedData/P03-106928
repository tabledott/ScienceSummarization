 is not as important as temporal coherence for the news articles summaries.
    Recall that the summaries describe events across documents.
    This information is captured more adequately by VDND and not by NL that only keeps a record of the entities in the sentence.
  
  
    In this paper we proposed a data intensive approach to text coherence where constraints on sentence ordering are learned from a corpus of domain-specific texts.
    We experimented with different feature encodings and showed that lexical and syntactic information is important for the ordering task.
    Our results indicate that the model can successfully generate orders for texts taken from the corpus on which it is trained.
    The model also compares favorably with human performance on a single- and multiple document ordering task.
    Our model operates on the surface level rather than the logical form and is therefore suitable for text-to-text generation systems; it acquires ordering constraints automatically, and can be easily por