for the 30 formal test documents is only 88.9%, which is not considered very high by MUC-6 standards.
    For example, our named entity recognizer could not identify the two named entities USAir and Piedmont in the expression USAir and Piedmont but instead treat them as one single named entity.
    Our part-of-speech tagger achieves 96% accuracy, while the accuracy of noun phrase identification is above 90%.
  
  
    One factor that affects the performance of a machine learning approach is the set of features used.
    It is interesting to find out how useful each of our 12 features is in the MUC-6 and MUC-7 coreference tasks.
    One way to do this is to train and test using just one feature at a time.
    Table 3 and Table 4 show the results of the experiment.
    For both MUC-6 and MUC-7, the 3 features that give nonzero recall and precision are ALIAS, STR_MATCH, and APPOSITIVE.
    The 12 features can be divided into unary and binary features.
    The unary features are I_PRONOUN, J_PRONOUN, DEF_NP, and 