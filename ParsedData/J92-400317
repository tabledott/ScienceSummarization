 then the majority of the time involved in computing Ik(i,j) is devoted to computing the sums on the second line of equation (15).
    Each of these sums has approximately V - k terms and so we have reduced the problem of evaluating Ik(i,j) from one of order V2 to one of order V. We can improve this further by keeping track of those pairs 1,m for which pk(1,m) is different from 0.
    We recall from Table 1, for example, that of the 6.799 x 1010 2-grams that might have occurred in the training data, only 14,494,217 actually did occur.
    Thus, in this case, the sums required in equation (15) have, on average, only about 56 non-zero terms instead of 260,741, as we might expect from the size of the vocabulary By examining all pairs, we can find that pair, i &lt;j, for which the loss in average mutual information, Lk (i, j) - Ik(i, j), is least.
    We complete the step by merging Ck(i) and Ck(j) to form a new cluster Ck_i (i).
    If j k, we rename Ck(k) as Ck_i (i) and for 1 i,j, we set Ck-i (1) to Ck(/).
   