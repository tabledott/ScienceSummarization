the selectional preferences of these two case slots (one of many possible similarity metrics) gives a surprisingly low score.
    In order to facilitate more accurate judgments of selectional-preference similarity, CorMet finds clusters of WordNet nodes that, although not as accurate, allow more meaningful comparisons of selectional preferences.
    Clusters are built using the nearest-neighbor clustering algorithm (Jain, Murty, and Flynn 1999).
    A predicate&#8217;s selectional preferences are represented as vectors whose nth element represents the selectional association of the nth WordNet node for that predicate.
    The similarity function used is the dot product of the two selectional-preference vectors.
    Empirically, the level of granularity obtained by running nearest-neighbor clustering twice (i.e., clustering over the sets of nodes constituting selectional preferences, then clustering over the clusters) produces the most conceptually coherent clusters.
    There are typically fewer than 100 seco