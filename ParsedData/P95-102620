onary definition as seeds increases the coverage of the concept space, improving accuracy (94.8%).
    However, spurious words in example sentences can be a source of noise.
    Quick hand tagging of a list of algorithmically-identified salient collocates appears to be worth the effort, due to the increased accuracy (95.5%) and minimal cost.
    Columns 9 and 10 illustrate the effect of adding the probabilistic one-sense-per-discourse constraint to collocation-based models using dictionary entries as training seeds.
    Column 9 shows its effectiveness as a post-hoc constraint.
    Although apparently small in absolute terms, on average this represents a 27% reduction in error rate.11 When applied at each iteration, this process reduces the training noise, yielding the optimal observed accuracy in column 10.
    Comparative performance: Column 5 shows the relative performance of supervised training using the decision list algorithm, applied to the same data and not using any discourse information.
    Unsuper