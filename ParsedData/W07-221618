 the argmax calculation for a single or set of training instances under the current parameter settings.
    The work of McDonald et al. (2005b) showed that it is possible to learn a highly accurate non-projective dependency parser for multiple languages using the Chu-Liu-Edmonds algorithm for unlabeled parsing.
    In min-risk decoding the goal is to find the dependency graph for an input sentence x, that on average has the lowest expected risk, where R is a risk function measuring the error between two graphs.
    Min-risk decoding has been studied for both phrase-structure parsing and dependency parsing (Titov and Henderson, 2006).
    In that work, as is common with many min-risk decoding schemes, T(Gx) is not the entire space of parse structures.
    Instead, this set is usually restricted to a small number of possible trees that have been preselected by some baseline system.
    In this subsection we show that when the risk function is of a specific form, this restriction can be dropped.
    The result i