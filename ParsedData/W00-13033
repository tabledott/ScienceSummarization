ntional statistical learning algorithms, SVMs achieve high generalization even with training data of a very high dimension.
    Furthermore, by optimizing the Kernel function, SVMs can handle non-linear feature spaces, and carry out the training with considering combinations of more than one feature.
    Thanks to such predominant nature, SVMs deliver state-of-the-art performance in realworld applications such as recognition of hand-written letters, or of three dimensional images.
    In the field of natural language processing, SVMs are also applied to text categorization, and are reported to have achieved To maximize this margin, we should minimize In other words, this problem becomes equivalent to solving the following optimization problem: Furthermore, this optimization problem can be rewritten into the dual form problem: Find the Lagrange multipliers ai &gt; 0(i = 1, , /) so that: In this dual form problem, xi with non-zero ai is called a Support Vector.
    For the Support Vectors, w and b can thus be e