incoming sentence matches some existing template, which leads to a strong bias favoring quality over coverage.
    In addition, the construction and generalization of lattices may become computationally expensive when dealing with much larger corpora.
    We can also compare and contrast Barzilay and Lee&#8217;s work and the work from Section 3.3 that seems most closely related: that of Pang, Knight, and Marcu (2003).
    Both take sentences grouped together in a cluster and align them into a lattice using a particular algorithm.
    Pang, Knight, and Marcu have a pre-defined size for all clusters since the input corpus is an 11-way parallel corpus.
    However, Barzilay and Lee have to construct the clusters from scratch because their input corpus has no pre-defined notion of parallelism at the sentence level.
    Both approaches use word lattices to represent and induce paraphrases since a lattice can efficiently and compactly encode n-gram similarities (sets of shared overlapping word sequences) between a 