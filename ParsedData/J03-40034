pproach.
    The models were originally introduced in Collins (1997); the current article1 gives considerably more detail about the models and discusses them in greater depth.
    In Model 1 we show one approach that extends methods from probabilistic context-free grammars (PCFGs) to lexicalized grammars.
    Most importantly, the model has parameters corresponding to dependencies between pairs of headwords.
    We also show how to incorporate a &#8220;distance&#8221; measure into these models, by generalizing the model to a history-based approach.
    The distance measure allows the model to learn a preference for close attachment, or right-branching structures.
    In Model 2, we extend the parser to make the complement/adjunct distinction, which will be important for most applications using the output from the parser.
    Model 2 is also extended to have parameters corresponding directly to probability distributions over subcategorization frames for headwords.
    The new parameters lead to an improvement 