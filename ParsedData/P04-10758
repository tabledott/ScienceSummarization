e hyperplane is computed as follows: where w is the feature vector of the word, ai, yi, si corresponds to the weight, the class and the feature vector of the ith support vector respectively.
    N is the number of the support vectors in current model.
    We select the example with minimal Dist, which indicates that it comes closest to the hyperplane in feature space.
    This example is considered most informative for current model.
    Based on the above informativeness measure for a word, we compute the overall informativeness degree of a named entity NE.
    In this paper, we propose three scoring functions as follows.
    Let NE = w1...wN in which wi is the feature vector of the ith word of NE. where, wi is the feature vector of the ith word in NE.
    In Section 4.3, we will evaluate the effectiveness of these scoring functions.
    In addition to the most informative example, we also prefer the most representative example.
    The representativeness of an example can be evaluated based on how many exam