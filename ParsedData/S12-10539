ne of the task organizers) submitted valid runs.
    Eight teams produced submissions for all the language combinations, while two teams participated only in the SP-EN task.
    In total, 92 runs have been submitted and evaluated (29 for SP-EN, and 21 for each of the other language pairs).
    Despite the novelty and the difficulty of the problem, these numbers demonstrate the interest raised by the task, and the overall success of the initiative.
    Accuracy results are reported in Table 3.
    As can be seen from the table, overall accuracy scores are quite different across language pairs, with the highest result on SP-EN (0.632), which is considerably higher than the highest score on DE-EN (0.558).
    This might be due to the fact that most of the participating systems rely on a &#8220;pivoting&#8221; approach that addresses CLTE by automatically translating T1 in the same language of T2 (see Section 6).
    Regarding the DE-EN dataset, pivoting methods might be penalized by the lower quality of MT outpu