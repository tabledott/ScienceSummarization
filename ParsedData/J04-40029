n employed in this article is as follows.
    We use the symbol Pr(&#183;) to denote general probability distributions with (nearly) no specific assumptions.
    In contrast, for model-based probability distributions, we use the generic symbol p(&#183;).
    This approach has been suggested by Papineni, Roukos, and Ward (1997, 1998) for a natural language understanding task.
    We obtain the following decision rule: Hence, the time-consuming renormalization in equation (3) is not needed in search.
    The overall architecture of the log-linear modeling approach is summarized in Figure 1.
    A standard criterion on a parallel training corpus consisting of S sentence pairs {(fs, es): s = 1,. .
    .
    , S} for log-linear models is the maximum class posterior probability criterion, which can be derived from the maximum-entropy principle: This corresponds to maximizing the equivocation or maximizing the likelihood of the direct-translation model.
    This direct optimization of the posterior probability in Ba