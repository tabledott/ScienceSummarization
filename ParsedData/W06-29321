 their has been a revived interest in parsing models that produce dependency graph representations of sentences, which model words and their arguments through directed edges (Hudson, 1984; Mel'&#711;cuk, 1988).
    This interest has generally come about due to the computationally efficient and flexible nature of dependency graphs and their ability to easily model non-projectivity in freer-word order languages.
    Nivre (2005) gives an introduction to dependency representations of sentences and recent developments in dependency parsing strategies.
    Dependency graphs also encode much of the deep syntactic information needed for further processing.
    This has been shown through their successful use in many standard natural language processing tasks, including machine translation (Ding and Palmer, 2005), sentence compression (McDonald, 2006), and textual inference (Haghighi et al., 2005).
    In this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subseq