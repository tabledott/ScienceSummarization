decrease performance.
    On the other hand, sister annotation of order 1 is much more critical, and provides 4.1% improvement over a simpler model (s = 0, v = 0).
    Manual examinations of compression outputs confirmed this analysis: without sister annotation, deletion of punctuation and function words (determiners, coordinate conjunctions, etc.) is often inaccurate, and compressions clearly lack fluency.
    This annotation is also helpful for phrasal deletions; for instance, we found that PPs are deleted in 31.4% of cases in Ziff-Davis if they do not immediately follow the head constituent, but this percentage drops to 11.1% for PPs that immediately follow the head.
    It seems, however, that increasing sister annotation beyond s &gt; 1 only provide limited improvements.
    In our second evaluation reported in Table 2, we 7We relied on the SRI language modeling (SRILM) toolkit library for all smoothing experiments.
    We used the following order in our deleted interpolation of ph: lexical head, head PO