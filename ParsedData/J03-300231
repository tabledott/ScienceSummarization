e particular languages, and therefore very easily ported to new language pairs.
    With the exception of the use of a bilingual dictionary (in BITS and later versions of PTMiner), these systems require, at most, a set of URL substring patterns for the URL pattern-matching stage (e.g., big5 &#8764; english in the example above; see further discussion in Section 4.3), and a modest amount of monolingual data for training n-gram-based language identifiers (typically 50,000 to 100,000 characters of text per language).
    Word-level translations are worth exploiting when they are available.
    In Section 3 we describe a bitext-matching process using a content-based similarity score grounded in information theory, and in Section 5 we show how structural and content-based criteria can be combined in order to obtain performance superior to that obtained using either method alone.
    5 Many details of this technique are left unspecified in Ma and Liberman (1999), such as the threshold for the similarity score, the 