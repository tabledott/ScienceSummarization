eriment.8 For each argument of each relation we picked the top two topics according to frequency in the 5 Gibbs samples.
    We then discarded any topics which were labeled with 0; this resulted in a set of 236 predictions.
    A few examples are displayed in table 4.
    We evaluated these classes and found the accuracy to be around 0.88.
    We contrast this with Pantel&#8217;s repository,9 the only other released database of selectional preferences to our knowledge.
    We evaluated the same 100 relations from his website and tagged the top 2 classes for each argument and evaluated the accuracy to be roughly 0.55.
    We emphasize that tagging a pair of class-based preferences is a highly subjective task, so these results should be treated as preliminary.
    Still, these early results are promising.
    We wish to undertake a larger scale study soon.
  
  
    We have presented an application of topic modeling to the problem of automatically computing selectional preferences.
    Our method, LDA-SP, learn