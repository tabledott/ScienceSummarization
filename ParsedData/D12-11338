Zhang and Nivre (2011).
    Since joint tagging and parsing increases the size of the search space and is likely to require novel features, we use beam search in combination with structured perceptron learning.
    The beam search algorithm used to derive the best parse y for a sentence x is outlined in Figure 2.
    In addition to the sentence x, it takes as input a weight vector w corresponding to a linear model for scoring transitions out of configurations and two prunw and beam parameters b1 and b2.
    The symbols h.c, h.s and h.f denote, respectively, the configuration, score and feature representation of a hypothesis h; h.c.A denotes the arc set of h.c. ing parameters b1 and b2.
    A parse hypothesis h is represented by a configuration h.c, a score h.s and a feature vector h.f for the transition sequence up to h.c.
    Hypotheses are stored in the list BEAM, which is sorted by descending scores and initialized to hold the hypothesis h0 corresponding to the initial configuration cs(x) with score 0.0 an