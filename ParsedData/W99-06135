ing algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98).
    The AdaBoost algorithm was developed for supervised learning.
    AdaBoost finds a weighted combination of simple (weak) classifiers, where the weights are chosen to minimize a function that bounds the classification error on a set of training examples.
    Roughly speaking, the new algorithm presented in this paper performs a similar search, but instead minimizes a bound on the number of (unlabeled) examples on which two classifiers disagree.
    The algorithm builds two classifiers iteratively: each iteration involves minimization of a continuously differential function which bounds the number of examples on which the two classifiers disagree.
    There has been additional recent work on inducing lexicons or other knowledge sources from large corpora.
    (Brin 98) ,describes a system for extracting (author, book-title) pairs from the World Wide Web using an approach that bootstraps from an initial seed set of examples.
    