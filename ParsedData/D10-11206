nstrates that a small set of language-independent universals can also serve as effective constraints.
    Furthermore, we find that our method outperforms the generalized expectation approach using corpus-specific constraints.
    Learning to Refine Syntactic Categories Recent research has demonstrated the usefulness of automatically refining the granularity of syntactic categories.
    While most of the existing approaches are implemented in the supervised setting (Finkel et al., 2007; Petrov and Klein, 2007), Liang et al. (2007) propose a non-parametric Bayesian model that learns the granularity of PCFG categories in an unsupervised fashion.
    For each non-terminal grammar symbol, the model posits a Hierarchical Dirichlet Process over its refinements (subsymbols) to automatically learn the granularity of syntactic categories.
    As with their work, we also use nonparametric priors for category refinement and employ variational methods for inference.
    However, our goal is to apply category refinement t