/1000) &#8212; we could carry out the reestimation technique described in section 3.4 on only 1 Mwds of training data.
    For convenience we chose to work on the UPenn Treebank corpus.
    The vocabulary sizes were: The training data was split into &amp;quot;development&amp;quot; set &#8212; 929,564wds (sections 00-20) &#8212; and &amp;quot;check set&amp;quot; &#8212; 73,760wds (sections 21-22); the test set size was 82,430wds (sections 23-24).
    The &amp;quot;check&amp;quot; set has been used for estimating the interpolation weights and tuning the search parameters; the &amp;quot;development&amp;quot; set has been used for gathering/estimating counts; the test set has been used strictly for evaluating model performance.
    Table 1 shows the results of the re-estimation technique presented in section 3.4.
    We achieved a reduction in test-data perplexity bringing an improvement over a deleted interpolation trigram model whose perplexity was 167.14 on the same training-test data; the reduction is statist