rench side.3 Then the weight of D hS 1 , S 1 i &#8658; hS 2 X 3 , S 2 X 3 i &#8658; hS 4 X 5 X 3 , S 4 X 5 X 3 i &#8658; hX 6 X 5 X 3 ,X 6 X 5 X 3 i &#8658; hAozhou X 5 X 3 , Australia X 5 X 3 i &#8658; hAozhou shi X 3 , Australia is X 3 i &#8658; hAozhou shi X 7 zhiyi, Australia is one of X 7 i &#8658; hAozhou shi X 8 de X 9 zhiyi, Australia is one of the X 9 that X 8 i &#8658; hAozhou shi yu X 1 you X 2 de X 9 zhiyi, Australia is one of the X 9 that have X 2 with X 1 i is the product of the weights of the rules used in the translation, multiplied by the following extra factors: where plm is the language model, and exp(&#8722;&#955;wp|e|), the word penalty, gives some control over the length of the English output.
    We have separated these factors out from the rule weights for notational convenience, but it is conceptually cleaner (and necessary for polynomial-time decoding) to integrate them into the rule weights, so that the whole model is a weighted synchronous CFG.
    The word penalty is easy; the lan