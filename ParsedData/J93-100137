n general, high-frequency function words like to and the, which are acoustically short, are more predictable than content words like resolve and important, which are longer.
    This is convenient for speech recognition because it means that the language model provides more powerful constraints just when the acoustic model is having the toughest time.
    One suspects that this is not an accident, but rather a natural result of the evolution of speech to fill the human needs for reliable communication in the presence of noise.
    .
    The ideal NLP model would combine the strengths of both the competence approximation and the n-gram approximation.
    One possible solution might be the Inside&#8212; Outside algorithm (Baker 1979; Lan i and Young 1991), a generalization of the Forward&#8212; Backward algorithm that estimates the parameters of a hidden stochastic context-free grammar, rather than a hidden Markov model.
    Four alternatives are proposed in these special issues: (1) Brent (1993), (2) Briscoe a