ted trees are not isomorphic. enfants Our main concern is to develop models that can align and learn from these tree pairs despite the &#8220;mismatches&#8221; in tree structure.
    Many &#8220;mismatches&#8221; are characteristic of a language pair: e.g., preposition insertion (of &#8594; c), multiword locutions (kiss H give a kiss to; misinform H wrongly inform), and head-swapping (float down H descend byfloating).
    Such systematic mismatches should be learned by the model, and used during translation.
    It is even helpful to learn mismatches that merely tend to arise during free translation.
    Knowing that beaucoup d&#8217; is often deleted will help in aligning the rest of the tree.
    When would learned tree-to-tree mappings be useful?
    Obviously, in MT, when one has parsers for both the source and target language.
    Systems for &#8220;deep&#8221; analysis and generation might wish to learn mappings between deep and surface trees (B&#168;ohmov&#180;a et al., 2001) or between syntax and sema