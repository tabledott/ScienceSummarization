labeled bracketing precision and recall respectively.
    The baseline model which was only trained on the 9695 sentences of labeled data performed at 72.23% and 69.12% precision and recall.
    These results show that training a statistical parser using our Co-training method to combine labeled and unlabeled data strongly outperforms training only on the labeled data.
    It is important to note that unlike previous studies, our method of moving towards unsupervised parsing can be directly compared to the output of supervised parsers.
    Unlike previous approaches to unsupervised parsing our method can be trained and tested on the kind of representations and the complexity of sentences that are found in the Penn Treebank.
    In addition, as a byproduct of our representation we obtain more than the phrase structure of each sentence.
    We also produce a more embellished parse in which phenomena such as predicate-argument structure, subcategorization and movement are given a probabilistic treatment.
  

