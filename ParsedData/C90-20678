ry" links: the words activate the concepts to which they are semantically related, and vice versa.
			In addition, "lateral" inhibitory links usually interconnect competing senses of a given word.
			Initially, the nodes corresponding tothe words in the sentence to be analyzed are activated.
			These words activate their neighbors in the next cycle in turn, these neighbors activate their immediate neighbors, and so on.
			After a number of cycles, the network stabilizes in a state in which one sense for each input word is more activated than the others, using a parallel, analog, relaxation process.
			Neural network approaches to WSD seem able to capture most of what cannot be handled by overlap strategies such as Lesk's.
			However, the networks used in experiments o far are hand-coded and thus necessarily very small (at most, a few dozen words and concepts).
			Due to a lack of real-size data, it is not clear that he same neural net models will scale up for realistic application.
			Further, some approaches