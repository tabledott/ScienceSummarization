
  Bootstrapping
  
    disambiguation rivaling supervised methods.
    In Proceedings of the 33rd Annual Meeting of the for Computational pages 189&#8211;196. see that view independence does not imply preindepence, consider an example in which always.
    This is compatible with rule independence, but implies that = 1 and = 0, violating precision independence.
    A
  
  
    The term bootstrapping here refers to a problem setting in which one is given a small set of labeled data and a large set of unlabeled data, and the task is to induce a classifier.
    The plenitude of unlabeled natural language data, and the paucity of labeled data, have made bootstrapping a topic of interest in computational linguistics.
    Current work has been spurred by two papers, (Yarowsky, 1995) and (Blum and Mitchell, 1998).
    Blum and Mitchell propose a conditional independence assumption to account for the efficacy of their algorithm, called co-training, and they give a proof based on that conditional independence assumpti