		?= c c c e e ceP if,0 if,|| 1 )|( Next, we estimate the parameters by iteratively updating them, until they converge (cf., Figure 3).
			Finally, we calculate )(cf E for all Cc ? as:?
			= Ee E efcPcf )()()( (2) In this way, we can transform the frequency vector in English ))(),..,(),(( 21 mefefef into a vector in Chinese ))(),..,(),(( 21 nEEE cfcfcf=D . Prior Probability Estimation At Step 2, we approximately estimate the prior probability )~(cP by using the document frequencies of the translation candidates.
			The data are obtained when we conduct candidate collection (Step 4 in Figure 1).
			Ee Ee Cc ecPef ecPef ceP ecPefcP cePcP cePcP ecP )|()( )|()()|( )|()()(StepM )|()( )|()()|(StepE Figure 3.
			EM Algorithm EM-NBC At Step 2, we use an EM-based Na?ve Bayesian Classifier (EM-NBC) to select the candidates c~ whose posterior probabilities are the largest: ??
			)~|(log)()~(logmaxarg )|~(maxarg ~ ~ ~ ~ ccPcfcP cP Cc E Cc Cc D (3) Equation (3) is based on Bayes?
			rule and the assumption that the data i