mance, calculated as Pearson correlation to the gold standard; this is reported in the &#8220;1-Expert&#8221; column of Table 4.
    Next we train systems using non-expert labels; for each possible subset of n annotators, for n E 11, 2, ... ,10} we train a system, and evaluate by calculating Pearson correlation with the same set of gold standard datasets used in the expert-trained system evaluation.
    Averaging the results of these studies yields the results in Table 4.
    As in Table 2 we calculate the minimum number of non-expert annotations per example k required on average to achieve similar performance to the expert annotations; surprisingly we find that for five of the seven tasks, the average system trained with a single set of non-expert annotations outperforms the average system trained with the labels from a single expert.
    One possible hypothesis for the cause of this non-intuitive result is that individual labelers (including experts) tend to have a strong bias, and since multiple non-expert