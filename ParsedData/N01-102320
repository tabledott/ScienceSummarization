n this paper) that different models can constrain each other by exploiting different &#8216;views&#8217; of the data.
    They also prove some PAC results on learnability.
    They also discuss an application of classifying web pages by using their method of mutually constrained models.
    (Collins and Singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms to AdaBoost which force the classifiers to agree (called CoBoosting).
    (Goldman and Zhou, 2000) provide a variant of Co-Training which is suited to the learning of decision trees where the data is split up into different equivalence classes for each of the models and they use hypothesis testing to determine the agreement between the models.
    In future work we would like to experiment whether some of these ideas could be incorporated into our model.
    In future work we would like to explore use of the entire 1M words of the WSJ Penn Treebank as our labeled data and to use a larger set of unbracketed WSJ data