Paul, 2006), and DARPA evaluates using HTER (Snover et al., 2006).
    The details of these are provided later in the paper.
    Public evaluation campaigns provide a ready source of goldstandard data that non-expert annotations can be compared to.
  
  
    Amazon describes its Mechanical Turk web service1 as artificial artificial intelligence.
    The name and tag line refer to a historical hoax from the 18th century where an automaton appeared to be able to beat human opponents at chess using a clockwork mechanism, but was, in fact, controlled by a person hiding inside the machine.
    The Mechanical Turk web site provides a way to pay people small amounts of money to perform tasks that are simple for humans but difficult for computers.
    Examples of these Human Intelligence Tasks (or HITs) range from labeling images to moderating blog comments to providing feedback on relevance of results for a search query.
    Anyone with an Amazon account can either submit HITs or work on HITs that were submitted by 