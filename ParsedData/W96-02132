nal phrase attachment(Ratnaparkhi et al., 1994), and word morphology(Della Pietra et al., 1995).
    This paper briefly describes the maximum entropy and maximum likelihood properties of the model, features used for POS tagging, and the experiments on the Penn Treebank Wall St. Journal corpus.
    It then discusses the consistency problems discovered during an attempt to use specialized features on the word context.
    Lastly, the results in this paper are compared to those from previous work on POS tagging.
    The Probability Model The probability model is defined over It x T, where fl is the set of possible word and tag contexts, or &amp;quot;histories&amp;quot;, and T is the set of allowable tags.
    The model's probability of a history h together with a tag t is defined as: where ir is a normalization constant, fp, cu,.
    , a} are the positive model parameters and { , fk} are known as &amp;quot;features&amp;quot;, where fj (h, t) E {OM.
    Note that each parameter aj corresponds to a feature fj.
   