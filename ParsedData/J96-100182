r, it is prudent to guard against the introduction of (usually pro-system) bias by asking the evaluators to produce their answers independently of the system's output, as we have argued elsewhere (Hatzivassiloglou and McKeown 1993; Hatzivassiloglou in press).
    However, for the problem at hand, the uniqueness and accessibility of the correct answer greatly alleviates' the danger of introducing bias by letting the evaluators grade the translations produced by Champollion.
    Since the latter method makes more efficient use of the judges, we decided to adopt it for our evaluation.
    Among the three experiments described above, our best results are obtained when the database corpus is also used as the corpus from which XTRACT identifies the source language collocations (experiment Cl /DB1).
    In this case, not counting XTRACT errors, accuracy is rated at 78%.
    It should be noted that the thresholds used by Champollion were determined by experimenting on a separate data set.
    Since determining the th