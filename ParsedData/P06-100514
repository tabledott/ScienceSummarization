ular gender/number class by the proportion of times this noun was labelled as the antecedent for a pronoun of this particular gender/number.
    Since no such corpus exists, researchers have used coarser features learned from smaller sets through supervised learning (Soon et al., 2001; Ng and Cardie, 2002), manually-defined coreference patterns to mine specific kinds of data (Bean and Riloff, 2004; Bergsma, 2005), or accepted the noise inherent in unsupervised schemes (Ge et al., 1998; Cherry and Bergsma, 2005).
    We address the drawbacks of these approaches by using coreferent paths as the assumed resolutions in the bootstrapping.
    Because we can vary the threshold for defining a coreferent path, we can trade-off coverage for precision.
    We now outline two potential uses of bootstrapping with coreferent paths: learning gender/number information (Section 4.1) and augmenting a semantic compatibility model (Section 4.2).
    We bootstrap this data on our automatically-parsed news corpus.
    The corpus 