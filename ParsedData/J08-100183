
    We could not apply the HMM-based content models (Barzilay and Lee 2004) to the readability data set.
    The encyclopedia lemmas are written by different authors and consequently vary considerably in structure and vocabulary choice.
    Recall that these models are suitable for more restricted domains and texts that are more formulaic in nature.
    The different systems were trained and tested on the Britannica corpus using fivefold cross-validation.13 The language models were created anew for every fold using the documents in the training data.
    We use Joachims&#8217; (1998a) SVMlight package for training and testing with all parameters set to their default values.
    Evaluation Metric.
    We measure classification accuracy (i.e., the number of classes assigned correctly by the SVM over the size of the test set).
    We report accuracy averaged over folds.
    A chance baseline (selecting one class at random) yields an accuracy of 50%.
    Our training and test sets have the same number of documen