their output.
    Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and namedentity identification (Collins and Singer, 1999).
    In all of these cases, using unlabeled data has resulted in performance that rivals training solely from labeled data.
    However, these previous approaches were on tasks that involved identifying the right label from a small set of labels (typically 2&#8211;3), and in a relatively small parameter space.
    Compared to these earlier models, a statistical parser has a very large parameter space and the labels that are expected as output are parse trees which have to be built up recursively.
    We discuss previous work in combining labeled and unlabeled data in more detail in Section 7.
    Effectively, by picking confidently labeled data from each model to add to the training data, one model is labeling data for the other model.
    In the representation we use, parsing using a lexi