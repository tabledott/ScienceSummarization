may contain the full description of a named entity (e.g., President of Columbia University Lee Bollinger), while the use of shorter descriptions such as Bollinger or anaphoric expressions in some summary sentences would increase the summary&#8217;s readability (Schiffman, Nenkova, and McKeown 2002; Nenkova and McKeown 2003).
    These constraints can be incorporated into the sentence fusion algorithm, since our alignment-based representation of themes often contains several alternative descriptions of the same object.
    Beyond the problem of referring-expression generation, we found that by selecting appropriate paraphrases of each summary sentence, we can significantly improve the coherence of an output summary.
    An important research direction for future work is to develop a probabilistic text model that can capture properties of well-formed texts, just as a language model captures properties of sentence grammaticality.
    Ideally, such a model would be able to discriminate between cohesive fluent tex