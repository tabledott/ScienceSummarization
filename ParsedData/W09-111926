t interactions at the output level performs comparably to beamsearch or Viterbi, while being considerably more efficient computationally.
    We analyzed several approaches for modeling non-local dependencies and found that none of them clearly outperforms the others across several datasets.
    Our experiments corroborate recently published results indicating that word class models learned on unlabeled text can be an alternative to the traditional semi-supervised learning paradigm.
    NER proves to be a knowledgeintensive task, and it was reassuring to observe that knowledge-driven techniques adapt well across several domains.
    We observed consistent performance gains across several domains, most interestingly in Webpages, where the named entities had less context and were different in nature from the named entities in the training set.
    Our system significantly outperforms the current state of the art and is available to download under a research license.
    Apendix&#8211; wikipedia gazetters &amp; 