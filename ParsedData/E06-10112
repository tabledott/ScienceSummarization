ms require that the score of a dependency tree factors as a sum of the scores of its edges.
    This first-order factorization is very restrictive since it only allows for features to be defined over single attachment decisions.
    Previous work has shown that conditioning on neighboring decisions can lead to significant improvements in accuracy (Yamada and Matsumoto, 2003; Charniak, 2000).
    In this paper we extend the MST parsing framework to incorporate higher-order feature representations of bounded-size connected subgraphs.
    We also present an algorithm for acyclic dependency graphs, that is, dependency graphs in which a word may depend on multiple heads.
    In both cases parsing is in general intractable and we provide novel approximate algorithms to make these cases tractable.
    We evaluate these algorithms within an online learning framework, which has been shown to be robust with respect approximate inference, and describe experiments displaying that these new models lead to state-of-the-art