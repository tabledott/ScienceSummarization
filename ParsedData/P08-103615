m feature f assigned to the aspect topic (r = loc, z = a).
    Exact inference in the MAS model is intractable.
    Following Titov and McDonald (2008) we use a collapsed Gibbs sampling algorithm that was derived for the MG-LDA model based on the Gibbs sampling method proposed for LDA in (Griffiths and Steyvers, 2004).
    Gibbs sampling is an example of a Markov Chain Monte Carlo algorithm (Geman and Geman, 1984).
    It is used to produce a sample from a joint distribution when only conditional distributions of each variable can be efficiently computed.
    In Gibbs sampling, variables are sequentially sampled from their distributions conditioned on all other variables in the model.
    Such a chain of model states converges to a sample from the joint distribution.
    A naive application of this technique to LDA would imply that both assignments of topics to words z and distributions &#952; and &#981; should be sampled.
    However, (Griffiths and Steyvers, 2004) demonstrated that an efficient collapsed Gi