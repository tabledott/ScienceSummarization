Go et al. (2009), (Bermingham and Smeaton, 2010) and Pak and Paroubek (2010).
    Go et al. (2009) use distant learning to acquire sentiment data.
    They use tweets ending in positive emoticons like &#8220;:)&#8221; &#8220;:-)&#8221; as positive and negative emoticons like &#8220;:(&#8221; &#8220;:-(&#8221; as negative.
    They build models using Naive Bayes, MaxEnt and Support Vector Machines (SVM), and they report SVM outperforms other classifiers.
    In terms of feature space, they try a Unigram, Bigram model in conjunction with parts-of-speech (POS) features.
    They note that the unigram model outperforms all other models.
    Specifically, bigrams and POS features do not help.
    Pak and Paroubek (2010) collect data following a similar distant learning paradigm.
    They perform a different classification task though: subjective versus objective.
    For subjective data they collect the tweets ending with emoticons in the same manner as Go et al. (2009).
    For objective data they crawl twitter a