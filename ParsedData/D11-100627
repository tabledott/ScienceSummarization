is useful for two reasons.
    First, it makes the comparison more direct.
    Second, we can generate USR results for all eight languages and not just for the languages that they report.
    Table 4 gives results comparing the models presented in this work to those three systems.
    For this comparison we use sentences of length 10 or less after punctuation has been removed in order to be consistent with reported results.
    The overall trends carry over from the full treebank setting to this reduced sentence length setup: the projected models outperform the direct transfer models and multisource transfer gives higher accuracy than transferring only from English.
    Most previous work has assumed gold part-of-speech tags, but as the code for USR is publicly available we were able to train it using the same projected part-of-speech tags used in our models.
    These results are also given in Table 4 under USR&#8224;.
    Again, we can see that the multisource systems (both direct and projected) significant