r, perfect syntactic trees and perfect discourse segmentation lead to an error reduction of 52.0% (F-score improvement from 49.0% to 75.5%) when using 18 labels, and an error reduction of 45.5% (F-score improvement from 45.6% to 70.3%) when using 110 labels.
    The results in column in Table 3 compare extremely favorable with the results in column in Table 2.
    The discourse parsing model produces unlabeled discourse structure at a performance level similar to human annotators (F-score of 96.2%).
    When using 18 labels, the distance between our discourse parsing model performance level and human annotators performance level is of absolute 1.5% (75.5% versus 77%).
    When using 110 labels, the distance is of absolute 1.6% (70.3% versus 71.9%).
    Our evaluation shows that our discourse model is sophisticated enough to match near-human levels of performance.
  
  
    In this paper, we have introduced a discourse parsing model that uses syntactic and lexical features to estimate the adequacy of sentence-