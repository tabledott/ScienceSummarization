rves.
    It turned out that for the size of a training set smaller than 1000 examples, learning is rather unreliable and dependent on the quality of the chosen quadruples.
    For a bigger training set, the accuracy grows with its size until a certain maximum accuracy level is reached.
    This level is different for different prepositions and we hypothesise that it can be broken only when a wider sentential or discourse context is used.
    Accuracy/Size 0 500 1000 1500 2000 2500 3000 3500 Training corpus size Our algorithm also provides a qualification certainty based on the heterogeneity of the decision tree leaves.
    The tree leaves are heterogeneous for two reasons: 1) the tree expansion is terminated when a node contains more than 77% of examples belonging to the same class, or, 2) when there are examples in the node that cannot be further divided because the tree has reached the bottom of the WordNet hierarchy.
    The Table 2 shows that the incorrect attachments usually occur with a lower certainty