n feature selection, using a combination of backward and forward selection starting from the base model described in section 2.2, and parameter optimization for the SVM learner, using grid search for an optimal combination of the kernel parameters -y and r, the penalty parameter C and the termination criterion c, as well as the splitting feature s and the frequency threshold t. Feature selection and parameter optimization have to some extent been interleaved, but the amount of work done varies between languages.
    The main optimization criterion has been labeled attachment score on held-out data, using ten-fold cross-validation for all data sets with 100k tokens or less, and an 80-20 split into training and devtest sets for larger datasets.
    The number of features in the optimized models varies from 16 (Turkish) to 30 (Spanish), but the models use all fields available for a given language, except that FORM is not used for Turkish (only LEMMA).
    The SVM parameters fall into the following ranges: &#947;