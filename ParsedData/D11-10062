on (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010).
    Grammar induction systems have seen large advances in quality, but parsing accuracies still significantly lag behind those of supervised systems.
    Furthermore, they are often trained and evaluated under idealized conditions, e.g., only on short sentences or assuming the existence of gold-standard part-ofspeech (POS) tags.1 The reason for these assumptions is clear.
    Unsupervised grammar induction is difficult given the complexity of the analysis space.
    These assumptions help to give the model traction.
    The study of unsupervised grammar induction has many merits.
    Most notably, it increases our understanding of how computers (and possibly humans) learn in the absence of any explicit feedback.
    However, the gold POS tag assumption weakens any conclusions that can be drawn, as part-of