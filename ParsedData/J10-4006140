 the best in relational tasks and other semantic challenges.
    The final experiment of Section 6 briefly explored an interesting aspect of the tensor-based formalism, namely, the possibility of improving performance on some tasks by working directly on the tensor (in this case, applying tensor rank reduction for smoothing purposes) rather than on the matrices derived from it.
    Besides this pilot study, we did not carry out any task-specific optimization of TypeDM, which achieves its very good performance using exactly the same underlying parameter configuration (e.g., dependency paths, weighting function) across the different spaces and tasks.
    Parameter tuning is an important aspect in DSM development, with an often dramatic impact of parameter variation (Bullinaria and Levy 2007; Erk and Pad&#180;o 2009).
    We leave the exploration of parameter space in DM for future research.
    Its importance notwithstanding, however, we regard this as a rather secondary aspect, if compared with the good perfor