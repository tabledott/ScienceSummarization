nt performance differences in Figure 3 are suggestive, but not statistically significant.
    Removing stop words seemed to hurt overall performance slightly&#8212;it is not shown here.
    Stemming, on the other hand, produced a small but fairly consistent improvement.
    We compared these results to perfect stemming, which made little difference, leading us to conclude that our automated stemming module worked well enough.
    Name identification provided consistent gains.
    The Alembic name tagger was developed for newswire text and used here with no modifications.
    We created hand-tagged named entity data, which allowed us to measure the performance of Alembic: the accuracy (Fmeasure) was 76.5; see Chinchor and Sundheim (1993) for a description of the standard MUC scoring metric.
    This also allowed us to simulate perfect tagging, and we were able to determine how much we might gain by improving the name tagging by tuning it to this domain.
    As the results indicate, there would be little gain f