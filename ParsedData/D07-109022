et +ldcnews +webnews +web Figure 3: Number of n-grams (sum of unigrams to 5-grams) for varying amounts of training data.
			target: The English side of Arabic-English parallel data provided by LDC5 (237 million tokens).
			ldcnews: This is a concatenation of several English news data sets provided by LDC6 (5 billion tokens).
			webnews: Data collected over several years, up toDecember 2005, from web pages containing predominantly English news articles (31 billion to kens).web: General web data, which was collected in Jan uary 2006 (2 trillion tokens).
			For testing we use the ?NIST?
			part of the 2006 Arabic-English NIST MT evaluation set, which is not included in the training data listed above7.
			It consists of 1797 sentences of newswire, broadcastnews and newsgroup texts with 4 reference translations each.
			The test set is used to calculate transla tion BLEU scores.
			The English side of the set is also used to calculate perplexities and n-gram coverage.
			7.2 Size of the Language Models.
			We meas