nt is infinitely less likely than chance.
			We conclude that it is quite likely that fisheries and p~ches are translations of one another, much more so than fisheries and lections.
			5.
			Significance.
			Unfortunately, mutual information is often unreliable when the counts are small.
			For example, there are lots of infrequent words.
			If we pick a pair of these words at random, there is a very large chance that they would receive a large mutual information value by chance.
			For example, let e be an English word that appeared just once and le t fbe a French word that appeared just once.
			Then, there a non-trivial chance (-~) that e andf will appear is in the same piece, as shown in Table 7.
			If this should happen, the mutual information estimate would be very large, i.e., logK, and probably misleading.
			Table 7: f e 1 0 0 9 In order to avoid this problem, we use a t-score to filter out insignificant mutual information values.
			prob ( Vf, Vp ) - prob (Vf) prob ( Vp ) t= 1 prob(Vf,gp) Using the 