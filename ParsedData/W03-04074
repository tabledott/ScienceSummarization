need to create taggers from small amounts of labelled material.
    However, our experiments are relevant for languages for which there is little or no annotated data.
    We only perform the experiments in English for convenience.
    Our experiments can also be seen as a vehicle for exploring aspects of cotraining.
  
  
    Given two (or more) &#8220;views&#8221; (as described in Blum and Mitchell (1998)) of a classification task, co-training can be informally described as follows: The intuition behind the algorithm is that each classifier is providing extra, informative labelled data for the other classifier(s).
    Blum and Mitchell (1998) derive PAClike guarantees on learning by assuming that the two views are individually sufficient for classification and the two views are conditionally independent given the class.
    Collins and Singer (1999) present a variant of the Blum and Mitchell algorithm, which directly maximises an objective function that is based on the level of agreement between the classif