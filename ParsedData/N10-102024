n+Topic model to be far more interpretable.
    Additionally we compare the likelihood of these models on held out test data in Figure 6.
    Note that the Bayesian methods produce models with much higher likelihood.10 For the EM models, likelihood tends to decrease on held out test data as we increase the number of hidden states, due to overfitting.
  
  
    We have presented an approach that allows the unsupervised induction of dialogue structure from naturally-occurring open-topic conversational data.
    By visualizing the learned models, coherent patterns emerge from a stew of data that human readers find difficult to follow.
    We have extended a conversation sequence model to separate topic and dialogue words, resulting in an interpretable set of automatically generated dialogue acts.
    These discovered acts have interesting differences from those found in other domains, and reflect Twitter&#8217;s nature as a micro-blog.
    We have introduced the task of conversation ordering as an intrinsic meas