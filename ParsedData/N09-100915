on used by Cohen et al. (2008) is the special case where N = K, each Ln = 1, each `k = Nk, and each Jk = {Ik,1}.
    The covariance among arbitrary &#952;k,i is not defined directly; it is implied by the definition of the normal experts &#951;n,In,j, for each In,j E Jk.
    We note that a SLN can be represented as a PLN by relying on the distributivity of the covariance operator, and merging all the partition structure into one (perhaps sparse) covariance matrix.
    However, if we are interested in keeping a factored structure on the covariance matrices which generate the grammar weights, we cannot represent every SLN as a PLN.
    It is convenient to think of each &#951;i,j as a weight associated with a unique event&#8217;s probability, a certain outcome of a certain multinomial in the probabilistic grammar.
    By letting different &#951;i,j covary with each other, we loosen the relationships among &#952;k,j and permit the model&#8212;at least in principle&#8212; to learn patterns from the data.
    Def.
 