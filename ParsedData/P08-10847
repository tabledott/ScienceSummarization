es.
    An example of such a property is the distribution of part-of-speech bigrams.
    Hana et al., (2004) demonstrate that adding such statistics from an annotated Czech corpus improves the performance of a Russian part-of-speech tagger over a fully unsupervised version.
    The approach presented here differs from previous work in two significant ways.
    First, we do not assume supervised data in any of the languages.
    Second, we learn a single multilingual model, rather than asymmetrically handling one language at a time.
    This design allows us to capitalize on structural regularities across languages for the mutual benefit of each language.
    Unsupervised morphology is an active area of research (Schone and Jurafsky, 2000; Goldsmith, 2001; Adler and Elhadad, 2006; Creutz and Lagus, 2007; Dasgupta and Ng, 2007).
    Most existing algorithms derive morpheme lexicons by identifying recurring patterns in string distribution.
    The goal is to optimize the compactness of the data representation by