cale from 1 to 5, and the importance of the short sentence, or how well the compressed version retained the important words from the original, also on a scale from 1 to 5.
    The short sentences were randomly shuffled across test cases.
    The results in Table 1 show compression rates, as well as average grammar and importance scores across judges.
    There are two main ideas to take away from these results.
    First, we can get good compressions without paired training data.
    Second, we achieved a good boost by adding our additional constraints in two of the three versions.
    Note that importance is a somewhat arbitrary distinction, since according to our judges, all of the computer-generated versions do as well in importance as the human-generated versions.
    In Figure 1, we give four examples of most compression techniques in order to show the range of performance that each technique spans.
    In the first two examples, we give only the versions with constraints, because there is little or no d