he verb and its subject, whereas multiplicative models consider a subset, namely non-zero components.
    The resulting vector is sparser but expresses more succinctly the meaning of the predicate-argument structure, and thus allows semantic similarity to be modelled more accurately.
    Further research is needed to gain a deeper understanding of vector composition, both in terms of modeling a wider range of structures (e.g., adjectivenoun, noun-noun) and also in terms of exploring the space of models more fully.
    We anticipate that more substantial correlations can be achieved by implementing more sophisticated models from within the framework outlined here.
    In particular, the general class of multiplicative models (see equation (4)) appears to be a fruitful area to explore.
    Future directions include constraining the number of free parameters in linguistically plausible ways and scaling to larger datasets.
    The applications of the framework discussed here are many and varied both for cognitive