
  Training Tree Transducers
  
    Many probabilistic models for natural language are now written in terms of hierarchical tree structure.
    Tree-based modeling still lacks many of the standard tools taken for granted in (finitestate) string-based modeling.
    The theory of tree transducer automata provides a possible framework to draw on, as it has been worked out in an extensive literature.
    We motivate the use of tree transducers for natural language and address the training problem for probabilistic tree-totree and tree-to-string transducers.
  
  
    Much of natural language work over the past decade has employed probabilistic finite-state transducers (FSTs) operating on strings.
    This has occurred somewhat under the influence of speech recognition, where transducing acoustic sequences to word sequences is neatly captured by left-to-right stateful substitution.
    Many conceptual tools exist, such as Viterbi decoding (Viterbi, 1967) and forward-backward training (Baum and Eagon, 1967), as wel