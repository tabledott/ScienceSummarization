 performs very similarly to the more sophisticated IB.
    Being based on pairwise similarities, it shows better performance than IB on the pairwise measure.
    The IB is, however, slightly better according to the global measure (2% with K = 42).
    The fact that the NN method performs better than the IB with similar K values (NN K = 24 vs. IB K = 25) seems to suggest that the JS divergence provides a better model for the predominant class than the compression model of the IB.
    However, it is likely that the IB performance suffered due to our choice of test data.
    As the method is global, it performs better when the target classes are represented by a high number of verbs.
    In our experiment, many semantic classes were represented by two verbs only (section 2).
    Nevertheless, the IB method has the clear advantage that it allows for more clusters to be produced.
    At best it classified half of the verbs correctly according to their predominant sense (mPUR = 50%).
    Although this leaves room f