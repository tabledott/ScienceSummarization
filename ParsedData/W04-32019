eature vectors of the correct parse and mistaken parses: This is the precise sense in which mistakes with large &#945; contribute more strongly to the model.
  
  
    There is a major problem with both the primal and the dual formulations above: since each potential mistake must be ruled out, the number of variables or constraints is proportional to |G(x)|, the number of possible parse trees.
    Even in grammars without unary chains or empty elements, the number of parses is generally exponential in the length of the sentence, so we cannot expect to solve the above problem without any assumptions about the feature-vector representation `b and loss function L. For that matter, for arbitrary representations, to find the best parse given a weight vector, we would have no choice but to enumerate all trees and score them.
    However, our grammars and representations are generally structured to enable efficient inference.
    For example, we usually assign scores to local parts of the parse such as PCFG producti