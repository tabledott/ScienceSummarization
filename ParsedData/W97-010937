ion or simply some noisy or incorrectly disambiguated examples were involved in its creation15.
    Examples, which did not reach the bottom of the decision tree and were assigned the majority class of the node from which there was no appropriate branch to follow, were all classified with certainty between 0.5 and 1.0.
    The decision with certainly 1.0 is always based on a homogenous leaf.
    It does not exhibit the highest accuracy because many of the homogenous leaves are formed from only very few examples and many of these are erroneous.
    As Figure 3 shows, each preposition has a different saturation accuracy which cannot be surpassed unless a wider sentential context is used.
    We believe, however, that a bigger corpus would provide better word-sense disambiguation which in turn would allow to increase the homogeneity limit for the termination of the tree expansion.
    Heterogeneous nodes, which force the expansion of the decision tree to unnecessary extent, are caused by I) examples with an erro