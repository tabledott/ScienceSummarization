.
    These are characterised by much more semantic information, and the relationships between lexical items are very important, making sparse data a real problem.
    All the same, it should be noted that the performance is still far better than the baselines.
    The feature tree given in figure 4 is by no means the only feature tree we could have used.
    Indeed, we tried a number of different trees on the development corpus; this tree gave among the best overall results, with no category performing too badly.
    However, there is no reason to use only one feature tree for all four categories; the best results can be got by using a separate tree for each one.
    One can thus achieve slight (one to three point) gains in each category.
    The overall performance, given in table 3, appears promising.
    With a tagging accuracy of about 87%, various information retrieval and knowledge base applications can reasonably expect to extract useful information.
    The performance given in the first row is (like