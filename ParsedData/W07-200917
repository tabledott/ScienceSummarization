xed the substitutes from the human annotators with those of the systems.
			Three fresh annotators7 were given the test sentence and asked to categorise the randomly ordered substitutes as good, reasonable or bad.
			We take the majority verdict for each substitute, but if there is one reasonable and one good verdict, thenwe categorise the substitute as reasonable.
			The per centage of substitutes for systems (sys) and original annotators (origA) categorised as good, reasonableand bad by the post hoc annotators are shown in ta ble 8.
			We see the substitutes from the humans have a higher proportion of good or reasonable responsesby the post hoc annotators compared to the substi tutes from the systems.
	
	
			We think this task is an interesting one in which to evaluate automatic approaches of capturing lexical meaning.
			There is an inherent variation in the task because several substitutes may be possible for a given context.
			This makes the task hard and scoring is less straightforward than a task whic