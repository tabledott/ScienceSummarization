chieved fast decoding, while ensuring high quality. argmax best length argmax LM where is decomposed into
  
  
    We carried out experiments to compare the performance of three different methods to build phrase translation probability tables.
    We also investigate a number of variations.
    We report most experimental results on a GermanEnglish translation task, since we had sufficient resources available for this language pair.
    We confirm the major points in experiments on additional language pairs.
    As the first method, we learn phrase alignments from a corpus that has been word-aligned by a training toolkit for a word-based translation model: the Giza++ [Och and Ney, 2000] toolkit for the IBM models [Brown et al., 1993].
    The extraction heuristic is similar to the one used in the alignment template work by Och et al. [1999].
    A number of researchers have proposed to focus on the translation of phrases that have a linguistic motivation [Yamada and Knight, 2001; Imamura, 2002].
    They onl