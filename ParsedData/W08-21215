 BBN corpus shares lexical content with the Penn Treebank, we generated the BBN tags using a 2-fold cross-validation procedure.
    We separate the evaluation measures into two groups: (i) official measures, which were used for the ranking of participating systems, and (ii) additional unofficial measures, which provide further insight into the performance of the participating systems.
    The official evaluation measures consist of three different scores: (i) syntactic dependencies are scored using the labeled attachment score (LAS), (ii) semantic dependencies are evaluated using a labeled Fi score, and (iii) the overall task is scored with a macro average of the two previous scores.
    We describe all these scoring measures next.
    The LAS score is defined similarly as in the previous two shared tasks, as the percentage of to
  
  
    kens for which a system has predicted the correct HEAD and DEPREL columns (see Table 1).
    Same as before, our scorer also computes the unlabeled attachment score (UAS), 