ng model to a new domain.
    In order to overcome this difficulty, active learning (sample selection) has been studied in more and more NLP applications such as POS tagging (Engelson and Dagan 1999), information extraction (Thompson et al. 1999), text classification (Lewis and Catlett 1994; McCallum and Nigam 1998; Schohn and Cohn 2000; Tong and Koller 2000; Brinker 2003), statistical parsing (Thompson et al.
    1999; Tang et al. 2002; Steedman et al.
    2003), noun phrase chunking (Ngai and Yarowsky 2000), etc.
    Active learning is based on the assumption that a small number of annotated examples and a large number of unannotated examples are available.
    This assumption is valid in most NLP tasks.
    Different from supervised learning in which the entire corpus are labeled manually, active learning is to select the most useful example for labeling and add the labeled example to training set to retrain model.
    This procedure is repeated until the model achieves a certain level of performance.
    