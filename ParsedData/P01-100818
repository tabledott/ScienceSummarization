 words can match only each other, and not any other word in the aligned sentences.
    For example, &#8220;tried&#8221; from the first sentence in Figure 1 does not correspond to any other word in the second sentence but &#8220;tried&#8221;.
    Based on this observation, we can derive negative examples such as word =tried, word =Emma and word =tried, word =console.
    Given a pair of identical words from two sentences of length and , the algorithm produces one positive ex3To the best of our knowledge all existing statistical parsers are trained on WSJ or similar type of corpora.
    In the experiments we conducted, their performance significantly degraded on our corpus &#8212; literary texts. ample and negative examples.
    Training of the contextual classifier Using this initial seed, we record contexts around positive and negative paraphrasing examples.
    From all the extracted contexts we must identify the ones which are strong predictors of their category.
    Following (Collins and Singer, 1999), fi