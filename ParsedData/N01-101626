t.
    The edit detector reduces the misclassification rate on edited words from the null-model (marking everything as not edited) rate of 5.9% to 2.2%.
    To evaluate our parsing results we have introduced a new evaluation metric, relaxed edited labeled precision/recall.
    The purpose of this metric is to make evaluation of a parse tree relatively indifferent to the exact tree position of EDITED nodes, in much the same way that the previous metric, relaxed labeled precision/recall, make it indifferent to the attachment of punctuation.
    By this metric the parser achieved 85.3% precision and 86.5% recall.
    There is, of course, great room for improvement, both in stand-alone edit detectors, and their combination with parsers.
    Also of interest are models that compute the joint probabilities of the edit detection and parsing decisions &#8212; that is, do both in a single integrated statistical process.
  

