the word, hopefully capturing useful syntactic and semantic properties.
    Using these representations, we construct several compositional models, based on addition, multiplication, and recursive neural networks.
    We assess the effectiveness of these models using two evaluation protocols.
    The first one involves modeling similarity judgments for short phrases gathered in human experiments (Mitchell and Lapata, 2010).
    The second one is paraphrase detection, i.e., the task of examining two sentences and determining whether they have the same meaning (Socher et al., 2011a).
    We find that shallow approaches are as good as more computationally intensive alternatives.
    They achieve considerable semantic expressivity without any learning, sophisticated linguistic processing, or access to very large corpora.
    Our contributions in this work are three-fold: an empirical comparison of a broad range of compositional models, some of which are introduced here for the first time; the use of an evaluation