C(descr(A, B)) ?
  IC(comm(A, B)) (18) where descr(A, B) is a proposition describing what A and B are.
  Given these assumptions and definitions and the apparatus of information theory, Lin proved the following: Similarity Theorem: The similarity between A and B is measured by the ratio between the amount of information needed to state their commonality and the information needed to fully describe what they are: simL(A, B) = log p(comm(A, B)) log p(descr(A, B)) (19) His measure of similarity between two concepts in a taxonomy is a corollary of this theorem: simL(c1, c2) = 2 ?
  log p(lso(c1, c2)) log p(c1) + log p(c2) (20) where the probabilities p(c) are determined in a manner analogous to Resnik?s p(c) (equation (9)).
  Evaluation Methods How can we reason about and evaluate computational measures of semantic related- ness?
  Three kinds of approaches are prevalent in the literature.
  The first kind (Wei 1993; Lin 1998b) is a (chiefly) theoretical examination of a pro- posed measure for those mathematical 