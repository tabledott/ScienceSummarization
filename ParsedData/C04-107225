or 6 automatic evaluation metrics (16384-best list).
			references, we can easily identify the confusion set of the references and propose new features to improve automatic metrics.
			One caveat of the ORANGE method is that what if machine translations are as good as reference translations?
			To rule out this scenario, we can sample instances where machine translations are ranked higher than human translations.
			We then check the portion of the cases where machine translations are as good as the human translations.
			If the portion is small then the ORANGE method can be confidently applied.
			We conjecture that this is the case for the currently available machine translation systems.
			However, we plan to conduct the sampling procedure to verify this is indeed the case.
	

