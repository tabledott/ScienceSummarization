-speech are also a form of syntactic analysis, only shallower.
    Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages.
    This point has been made by studies that transfer parsers to new languages by projecting syntax across word alignments extracted from parallel corpora (Hwa et al., 2005; Ganchev et al., 2009; Smith and Eisner, 2009).
    Although again, most of these studies also assume the existence of POS tags.
    In this work we present a method for creating dependency parsers for languages for which no labeled training data is available.
    First, we train a source side English parser that, crucially, is delexicalized so that its predictions rely soley on the part-of-speech tags of the input sentence, in the same vein as Zeman and Resnik (2008).
    We empirically show that directly transferring delexicalized models (i.e. parsing a foreign language POS sequence with an English parser) already outperforms state-of-the-art unsu