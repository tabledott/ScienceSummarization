he entire English training set (204K), and the entire German set (207K), tested on either the development set or test set.
    ASO-semi significantly improves both precision and recall in all the six configurations, resulting in improved F-measures over the supervised baseline by +2.62% to +10.10%.
    Co- and self-training, at their oracle performance, improve recall but often degrade precision; consequently, their F-measure improvements are relatively low:&#8212;0.05% to +1.63%.
    Comparison with top systems As shown in Figure 5, ASO-semi achieves higher performance than the top systems on both English and German data.
    Most of the top systems boost performance by external hand-crafted resources such as: large gazetteers4; a large amount (2 million words) of labeled data manually annotated with finer-grained named entities (FIJZ03); and rule-based post processing (KSNM03).
    Hence, we feel that our results, obtained by using unlabeled data as the only additional resource, are encouraging.
  
  
    N