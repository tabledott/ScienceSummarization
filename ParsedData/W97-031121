similar to the translation produced by A than to the translation produced by B.
    In the present experiment, the translation method was always bag-of-words translation, but using different translation models.
    The similarity of two texts was measured in terms of word precision and word recall in aligned sentence pairs, ignoring word order.
    I compared the 6 base translation models induced in 6 iterations of the algorithm in Section 5.5 The first model is numbered 0, to indicate that it did not recognize any NCCs.
    The 6 translation models were evaluated on the test bitext (E, F) using the following BiBLE algorithm: The BiBLE algorithm compared the 6 models in both directions of translation.
    The results are detailed in Figures 4 and 5.
    Figure 6 shows F-measures that are standard in the information retrieval literature: The absolute recall and precision values in these figures are quite low, but this is not a reflection of the quality of the translation models.
    Rather, it is an expected o