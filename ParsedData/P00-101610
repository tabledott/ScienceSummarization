sts of 10 iterations, during which the annotators were allowed to make use of the original 100 sentences as a reference corpus.
    After completing all 10 iterations, they were asked to annotate a further 100 consecutive sentences drawn randomly from the test set.
    The purpose of this final annotation was to judge how well annotators tag sentences drawn with the true distribution from the test corpus, as we shall see in section 5.
    On average, the annotators took 17 minutes to annotate each set of 50 sentences, ranging from 8 to 30 minutes.
    The average amount of time the server took to run the active learning algorithm and select the next batch of sentences was approximately 3 minutes, a rest break for the annotators.
    The analysis of the results is presented in section 5.
  
  
    In previous work, Brill &amp; Ngai (1999) showed that under certain circumstances, it is possible for humans writing rules to perform as well as a stateof-the-art machine learning system for base noun phrase chunking