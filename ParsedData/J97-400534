 old field assigns them equal probability, counter to the empirical distribution).
    By contrast, the feature B distinguishes the set {xi, x2} from {x3, x4}.
    The empirical probability of the former is 1/3+1/6 = 1/2 and the empirical probability of the latter is also 1/2.
    The old field models these probabilities exactly correctly, so making the distinction does not permit us to improve on the old field.
    As a result, the best weight we can choose for B is 1, which is equivalent to not having the feature B at all.
    DD&amp;L show that there is a unique weight ,a that maximizes the score for a new feature f (provided that the score for f is not constant for all weights).
    Writing qo for the distribution that results from assigning weight 13 to feature f, j is the solution to the equation Intuitively, we choose the weight such that the expectation of f under the resulting new field is equal to its empirical expectation.
    Solving equation (2) for 3 is easy if L(G) is small enough to enumerate.