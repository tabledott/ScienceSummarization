ve length m or if e(') does not have length /, then the corresponding count is zero.
    As with the As in earlier equations, the Its here serve simply to remind us that the alignment probabilities must be normalized.
    Model 2 shares with Model 1 the important property that the sums in Equations (12) and (23) can be obtained efficiently.
    We can rewrite Equation (21) as Equation (27) has a double sum rather than the product of two single sums, as in Equation (17), because in Equation (27) i and j are tied together through the alignment probabilities.
    Model 1 is the special case of Model 2 in which a(ilj , m, 1) is held fixed at (1+ 1)-1.
    Therefore, any set of parameters for Model 1 can be reinterpreted as a set of parameters for Model 2.
    Taking as our initial estimates of the parameters for Model 2 the parameter values that result from training Model 1 is equivalent to computing the probabilities of all alignments as if we were dealing with Model 1, but then collecting the counts as if we we