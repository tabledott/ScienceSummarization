al, be the same length as the long sentence.
    We achieve compression by weighting to give shorter sentences more likelihood.
    In fact, what is really required is some model that takes &#8220;utility&#8221; into account, using a utility model in which shorter sentences are more useful.
    Our term giving preference to shorter sentences can be thought of as a crude approximation to such a utility.
    However, this is clearly an area for future research.
  
  
    We have created a supervised version of the noisychannel model with some improvements over the K&amp;M model.
    In particular, we learned that adding an additional rule type improved compression, and that enforcing some deletion constraints improves grammaticality.
    We also show that it is possible to perform an unsupervised version of the compression task, which performs remarkably well.
    Our semisupervised version, which we hoped would have good compression rates and grammaticality, had good grammaticality but lower compression than d