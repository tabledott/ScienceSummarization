us), the other one for testing (10%).
    The procedure was repeated 10 times with different. partitionings.
    The tagger rates 90% of all assignments as reliable and carries them out fully automatically.
    Accuracy for these cases is 97%.
    Most errors are due to wrong identification of the subject and different kinds of objects in sentences and VPs.
    Accuracy of the unreliable 10% of assignments is 75%, i.e., the annotator has to alter the choice in 1 of 4 cases when asked for confirmation.
    Overall accuracy of the tagger is 95%.
    Owing to the partial automation, the average annotation efficiency improves by 25% (from around 4 minutes to 3 minutes per sentence).
  
  
    As the annotation scheme described in this paper focusses on annotating argument structure rather than constituent trees, it differs from existing treebanks in several aspects.
    These differences can be illustrated by a comparison with the Penn Treebank annotation scheme.
    The following features of our formalism are th