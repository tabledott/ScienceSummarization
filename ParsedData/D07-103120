onverged and were mixing well (Robert and Casella, 2004).
			Just as with EM, we experimented with a variety of annealing regimes, but were unable to find any which significantly improved accuracy or posterior likelihood.We also experimented with evaluating state se quences found using maximum posterior decoding(i.e., model parameters are estimated from the posterior sample, and used to perform maximum posterior decoding) rather than the samples from the pos terior produced by the Gibbs sampler.
			We found that the maximum posterior decoding sequences usually scored higher than the posterior samples, but the scores converged after the first thousand iterations.Since the posterior samples are produced as a byproduct of Gibbs sampling while maximum poste rior decoding requires an additional time consuming step that does not have much impact on scores, we used the posterior samples to produce the results in Table 1.In contrast to MCMC, Variational Bayesian in ference attempts to find the function Q(y, ?, ?) tha