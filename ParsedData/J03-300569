uristic method for obtaining bigram counts from the Web.
    Using four different types of evaluation, we demonstrated that this simple heuristic method is sufficient to obtain valid frequency estimates.
    It seems that the large amount of data available outweighs the problems associated with using the Web as a corpus (such as the fact that it is noisy and unbalanced).
    A number of questions arise for future research: (1) Are Web frequencies suitable for probabilistic modeling, in particular since Web counts are not perfectly normalized, as Zhu and Rosenfeld (2001) have shown?
    (2) How can existing smoothing methods benefit from Web counts?
    (3) How do the results reported in this article carry over to languages other than English (for which a much smaller amount of Web data are available)?
    (4) What is the effect of the noise introduced by our heuristic approach?
    The last question could be assessed by reproducing our results using a snapshot of the Web, from which argument relations can be 