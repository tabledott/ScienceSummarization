r or not transcribed word boundaries are also move segment boundaries.
    On average, the coders marked move boundaries roughly every 5.7 words, so that there were roughly 4.7 times as many word boundaries that were not marked as move boundaries as word boundaries that were.
    The second measure, similar to information retrieval metrics, is the actual agreement reached measuring pairwise over all locations where any coder marked a boundary.
    That is, the measure considers each place where any coder marked a boundary and averages the ratio of the number of pairs of coders who agreed about that location over the total number of coder pairs.
    Note that it would not be possible to define &amp;quot;unit&amp;quot; in the same way for use in kappa because then it would not be possible for the coders to agree on a nonboundary classification.
    Pairwise percent agreement is the best measure to use in assessing segmentation tasks when there is no reasonable independent definition of units to use as the basis