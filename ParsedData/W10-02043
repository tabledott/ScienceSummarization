obtain annotations of high quality.
    Several checks must be placed to ensure that random and erroneous annotations are discouraged, rejected, and re-annotated.
    In this paper, we show how we compiled a moderate-sized English emotion lexicon by manual annotation through Amazon&#8217;s Mechanical Turk service.
    This dataset, which we will call EmoLez, is many times as large as the only other known emotion lexicon, WordNet Affect Lexicon.
    More importantly, the terms in this lexicon are carefully chosen to include some of the most frequent nouns, verbs, adjectives, and adverbs.
    Beyond unigrams, it has a large number of commonly used bigrams.
    We also include some words from the General Inquirer and some from WordNet Affect Lexicon, to allow comparison of annotations between the various resources.
    We perform an extensive analysis of the annotations to answer several questions that have not been properly addressed so far.
    For instance, how hard is it for humans to annotate words with the