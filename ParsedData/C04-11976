 possible false argument candidates, while still maintaining high recall.
			The sec ond phase focuses on identifying the types of thoseargument candidates.
			Since the number of candi dates is much fewer, the second phase is able to use slightly complicated features to facilitate learning a better classifier.
			This section first introduces the learning system we use and then describes how we learn the classifiers in these two phases.
			3.1 SNoW Learning Architecture.
			The learning algorithm used is a variation of the Winnow update rule incorporated in SNoW (Roth, 1998; Roth and Yih, 2002), a multi-class classifier that is specifically tailored for large scale learningtasks.
			SNoW learns a sparse network of linear functions, in which the targets (argument border predic tions or argument type predictions, in this case) arerepresented as linear functions over a common fea ture space.
			It incorporates several improvements over the basic Winnow multiplicative update rule.
			In particular, a regularizat