mar (SCFG) translation system (Chiang, 2007), a model which has yielded state-of-the-art results on many translation tasks.
    We present two main contributions.
    First, we develop a log-linear model of translation which is globally trained on a significant number of parallel sentences.
    This model maximises the conditional likelihood of the data, p(e|f), where e and f are the English and foreign sentences, respectively.
    Our estimation method is theoretically sound, avoiding the biases of the heuristic relative frequency estimates length and the average number of derivations (on a log scale) for each reference sentence in our training corpus.
    (Koehn et al., 2003).
    Second, within this framework, we model the derivation, d, as a latent variable, p(e, d1f), which is marginalised out in training and decoding.
    We show empirically that this treatment results in significant improvements over a maximum-derivation model.
    The paper is structured as follows.
    In Section 2 we list the challe