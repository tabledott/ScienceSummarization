 of a classifier.
    For instance, the following corresponds to the annotation &#8220;Number of glucocorticoid receptorsPROTEIN in Support Vector Machines (SVMs) (Cortes and Vapnik, 1995) are powerful methods for learning a classifier, which have been applied successfully to many NLP tasks such as base phrase chunking (Kudo and Matsumoto, 2000) and part-of-speech tagging (Nakagawa et al., 2001).
    The SVM constructs a binary classifier that outputs +1 or &#8722;1 given a sample vector x E Rn.
    The decision is based on the separating hyperplane as follows.
    The class for an input x, c(x), is determined by seeing which side of the space separated by the hyperplane, w &#183; x + b = 0, the input lies on.
    Given a set of labeled training samples {(y1, x1), &#183;&#183;&#183; , (yL, xL)}, xi &#8712; Rn, yi &#8712; {+1, &#8722;1}, the SVM training tries to find the optimal hyperplane, i.e., the hyperplane with the maximum margin.
    Margin is defined as the distance between the hyperplane and the train