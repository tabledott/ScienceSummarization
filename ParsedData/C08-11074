r a baseline infer ence that does not use entailment rules at all .
	
	
			This section reviews relevant distributional simi larity measures, both symmetric and directional, which were applied for either lexical similarity or unsupervised entailment rule learning.
			Distributional similarity measures follow the Distributional Hypothesis, which states that words that occur in the same contexts tend to have similar meanings (Harris, 1954).
			Various measures wereproposed in the literature for assessing such simi larity between two words, u and v. Given a word q, its set of features F q and feature weights w q (f) for f ? F q , a common symmetric similarity measure is Lin similarity (Lin, 1998a): Lin(u, v) = ? f?F u ?F v [w u (f) + w v (f)] ? f?F u w u (f) + ? f?F v w v (f) where the weight of each feature is the pointwise mutual information (pmi) between the word and the feature: w q (f) = log[ Pr(f |q) Pr(f) ].
			Weeds and Weir (2003) proposed to measure thesymmetric similarity between two words by av eragi