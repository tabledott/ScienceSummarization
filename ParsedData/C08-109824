 sim ilar for test and development data.
			The differences between the two taggers are significant.
			10 tagger default refined ref.+lexicon TnT 83.45 84.11 89.14 our tagger 85.00 85.92 91.07 Table 4: Tagging accuracies on test data.
			By far the most frequent tagging error was the confusion of nominative and accusative case.
			If 10 726 sentences were better tagged by TnT (i.e. with few errors), 1450 sentences were better tagged by our tagger.
			The resulting score of a binomial test is below 0.001.
			782 this error is not counted, the tagging accuracy on the development data rises from 92.17% to 94.27%.
			Our tagger is quite fast, although not as fast asthe TnT tagger.
			With a context size of 3 (10), it annotates 7000 (2000) tokens per second on a com puter with an Athlon X2 4600 CPU.
			The training with a context size of 10 took about 4 minutes.
			5.2 Czech Academic Corpus.
			We also evaluated our tagger on the Czech Aca demic corpus (Hladk?a et al, 2007) which contains 652.131 tokens and about