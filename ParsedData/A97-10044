pproach to the problem.
    His performance on I he Brown corpus is 99.8%, using a model learned from a. corpus of 25 million words.
    Liberman and Church suggest in (Liberma.n and Church, 1992) that a. system could be quickly built to divide newswire text into sentences with a nearly negligible error rate, but do not actually build such a system.
  
  
    We present two systems for identifying sentence boundaries.
    One is targeted at high performance and uses some knowledge about the structure of English financial newspaper text which may not be applicable to text from other genres or in other languages.
    The other system uses no domain-specific knowledge and is aimed at being portable across English text genres and Roman alphabet languages.
    Potential sentence boundaries are identified by scanning the text for sequences of characters separated by whitespace (tokens) containing one of the symbols !, . or ?.
    We use information about the token containing the potential sentence boundary, as well