s set of unlabeled data.
    Instead, a smaller data pool is maintained, fed with randomly selected instances from the larger set.3 Second, the JOB tagging task is a ternary, rather than a binary, classification.
    Furthermore, the distribution of labels in the training data is more unbalanced than the distribution of positive and negative examples in the web page task: namely, 53.9% of examples are labeled I, 44.0% 0, and 2.1% B.
    Since it is impractical to add, say, 27 I, 22 0, and 1 B, to the labeled data at each step of co-training, instead, instances are selected by first choosing a label 1 at random according to the label distribution, then adding the instance 3This standard modification was introduced by Blum and Mitchell (1998) in an effort to cover the underlying distribution of unlabeled instances; however, Nigam and Ghani (2000) found it to be unnecessary in their experiments. train classifier h1 on view V1 of L train classifier h2 on view V2 of L transfer randomly selected examples from U to 