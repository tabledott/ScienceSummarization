pts in the WordNet taxonomy, and the depth of the least common subsumer (LCS), and combines these figures into a similarity score: The measure introduced by Resnik (Resnik, 1995) returns the information content (IC) of the LCS of two concepts: where IC is defined as: and P(c) is the probability of encountering an instance of concept c in a large corpus.
    The next measure we use in our experiments is the metric introduced by Lin (Lin, 1998), which builds on Resnik&#8217;s measure of similarity, and adds a normalization factor consisting of the information content of the two input concepts: Finally, the last similarity metric we consider is Jiang &amp; Conrath (Jiang and Conrath, 1997), which returns a score determined by: In addition to the semantic similarity of words, we also want to take into account the specificity of words, so that we can give a higher weight to a semantic matching identified between two very specific words (e.g. collie and sheepdog), and give less importance to the similarity score me