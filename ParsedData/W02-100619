S, and name entities.
    KUNLP used Classification Information Model, an entropy-based learning algorithm, with local, topical, and bigram contexts and their POS.
    In SENSEVAL-1, hopkins used hierarchical decision lists with features similar to those used by JHU in SENSEVAL-2. ets-pu used a Naive Bayes classifier with topical and local words and their POS. tilburg used a k-nearest neighbor algorithm with features similar to those used by (Ng and Lee, 1996). tilburg also used dictionary examples as additional training data.
  
  
    Based on our experimental results, there appears to be no single, universally best knowledge source.
    Instead, knowledge sources and learning algorithms interact and influence each other.
    For example, local collocations contribute the most for SVM, while parts-of-speech (POS) contribute the most for NB.
    NB even outperforms SVM if only POS is used.
    In addition, different learning algorithms benefit differently from feature selection.
    SVM performs best without