 sentence-level predictions by using the performance on a larger data set as a prior.
  
  
    As in previous editions of this workshop we carried out an extensive manual and automatic evaluation of machine translation performance for translating from European languages into English, rics when their system-level ranks are treated as sentence-level scores.
    Oracle shows the consistency of using the system-level human ranks that are given in Table 6. rics when their system-level ranks are treated as sentence-level scores.
    Oracle shows the consistency of using the system-level human ranks that are given in Table 6. and vice versa.
    The number of participants remained stable compared to last year&#8217;s WMT workshop, with 22 groups from 20 institutions participating in WMT09.
    This year&#8217;s evaluation also included 7 commercial rule-based MT systems and Google&#8217;s online statistical machine translation system.
    Compared to previous years, we have simplified the evaluation conditions by r