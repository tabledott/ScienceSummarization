
    The term is the log probability of the sequence of vowels in the word according to a fourgram model over vowel sequences learned from the data.
    The final accuracy we achieve is shown in the fifth row of the same table.
    As a comparison, the best accuracy achieved by Jiang et al. (1997) on NETalk using a similar proportion of training and test set sizes was 65:8%.
    Their system uses more sources of information, such as phones in the left context as features in the decision tree.
    They also achieve a large performance gain by combining multiple decision trees trained on separate portions of the training data.
    The accuracy of our letter-tophone model is comparable to state of the art systems.
    Further improvements in this component may lead to higher spelling correction accuracy.
    Our combined error model gives the probability PCMB(wjr) where w is the misspelling and r is a word in the dictionary.
    The spelling correction algorithm selects for a misspelling w the word r in the dict