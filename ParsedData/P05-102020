is point would require enlarging our set of candidate partitions.
    So, we apply a perfect ranking model, which uses an oracle to choose the best candidate partition for each test text.
    Results in row 7 of Table 3 indicate that our ranking model performs at about 1-3% below the perfect ranker, suggesting that we can further improve coreference performance by improving the ranking model.
    Baseline systems.
    In contrast to the MUC results, the B-CUBED results for the two baseline systems are mixed (see rows 1 and 2 of Table 4).
    Specifically, while there is no clear winner for the NWIRE data set, N&amp;C performs better on BNEWS but worse on NPAPER than the Duplicated Soon system.
    Our approach.
    From row 3 of Table 4, we see that our approach achieves small but consistent improvements in F-measure over both baseline systems.
    In comparison to the better baseline, F-measure increases by 0.1, 1.1, and 2.0 for the BNEWS, NPAPER, and NWIRE data sets, respectively.
    Feature contribution.
