r, we have described experiments comparing the performance of a number of different algorithms for estimating the parameters of a conditional ME model.
    The results show that variants of iterative scaling, the algorithms which are most widely used in the literature, perform quite poorly when compared to general function optimization algorithms such as conjugate gradient and variable metric methods.
    And, more specifically, for the NLP classification tasks considered, the limited memory variable metric algorithm of Benson and Mor&#180;e (2001) outperforms the other choices by a substantial margin.
    This conclusion has obvious consequences for the field.
    ME modeling is a commonly used machine learning technique, and the application of improved parameter estimation algorithms will it practical to construct larger, more complex models.
    And, since the parameters of individual models can be estimated quite quickly, this will further open up the possibility for more sophisticated model and feature s