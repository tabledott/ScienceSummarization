CTB segmentation and character-based, we performed a grid search in the range between &#955;0 = 0 (maximumlikelihood estimate) and &#955;0 = 32 (a value that is large enough to produce only positive predictions).
    For each &#955;0 value, we ran an entire MT training and testing cycle, i.e., we re-segmented the entire training data, ran GIZA++, acquired phrasal translations that abide to this new segmentation, and ran MERT and evaluations on segmented data using the same 4Note that character-per-token averages provided in the table consider each non-Chinese word (e.g., foreign names, numbers) as one character, since our segmentation post-processing prevents these tokens from being segmented. tive bias values (&#955;0 = &#8722;2) slightly improves segmentation performance.
    We also notice that raising &#955;0 yields relatively consistent improvements in MT performance, yet causes segmentation performance (F measure) to be increasingly worse.
    While the latter finding is not particularly surprising, it 