ditioned by the tag that precedes it and by the one that follows it, and the probability of an emitted word is conditioned by its tag and the tag that follows it2.
    In all experiments, we use the backoff smoothing method of (Thede and Harper, 1999), with additive smoothing (Chen, 1996) for the lexical probabilities.
    We investigate methods to approximate the initial parameters of the p(t|w) distribution, from which we obtain p(w|t) by marginalization and Bayesian inversion.
    We also experiment with constraining the p(t|t_1, t+1) distribution.
    General syntagmatic constraints We set linguistically motivated constraints on the p(t|t_1, t+1) distribution.
    In our setting, these are used to force the probability of some events to 0 (e.g., &#8220;Hebrew verbs can not be followed by the of preposition&#8221;).
    Morphology-based p(t|w) approximation Levinger et al. (1995) developed a context-free method for acquiring morpho-lexical probabilities (p(t|w)) from an untagged corpus.
    The method is b