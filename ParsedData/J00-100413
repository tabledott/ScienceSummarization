ations involved.
    When applying a dependency transduction model to language translation, we choose the target string obtained by flattening the target tree of the lowest-cost dependency derivation that also generates the source string.
    We have not yet indicated what weights to use for head transducer transitions.
    The definition of head transducers as such does not constrain these.
    However, for a dependency transduction model to be a statistical model for generating pairs of strings, we assign transition weights that are derived from conditional probabilities.
    Several Head transducer converts the sequences of left and right dependents (wi wk_1) and (wk+i w,i) of w into left and right dependents (vi vj_i) and (v,&#177;1 vp) of V. probabilistic parameterizations can be used for this purpose including the following for a transition with headwords w and v and dependent words w' and v': P(qcw' , , a, 131w,v,q).
    Here q and q' are the from-state and to-state for the transition and a and 13 are 