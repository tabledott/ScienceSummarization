
  Immediate-Head Parsing For Language Models
  
    We present two language models based upon an &#8220;immediate-head&#8221; parser &#8212; our name for a parser that conditions events below a constituent head of While all of the most accurate statistical parsers are of the immediate-head variety, no previous grammatical language model uses this technology.
    The perplexity for both of these models significantly improve upon the trigram model base-line as well as the best previous grammarbased language model.
    For the better of our two models these improvements are 24% and 14% respectively.
    We also suggest that improvement of the underlying parser should significantly improve the model&#8217;s perplexity and that even in the near term there is a lot of potential for improvement in immediatehead language models. are what we will call parsers in that all of the properties of the immedescendants of a constituent assigned probabilities that are conditioned on the lexical of For example, in Figure 1 the