 it has been shown to correlate with human judgments of translation quality.
    Papineni et al. (2002) showed that Bleu correlated with human judgments in its rankings of five Chinese-to-English machine translation systems, and in its ability to distinguish between human and machine translations.
    Bleu&#8217;s correlation with human judgments has been further tested in the annual NIST Machine Translation Evaluation exercise wherein Bleu&#8217;s rankings of Arabic-to-English and Chinese-to-English systems is verified by manual evaluation.
    In the next section we discuss theoretical reasons why Bleu may not always correlate with human judgments.
  
  
    While Bleu attempts to capture allowable variation in translation, it goes much further than it should.
    In order to allow some amount of variant order in phrases, Bleu places no explicit constraints on the order that matching n-grams occur in.
    To allow variation in word choice in translation Bleu uses multiple reference translations, but puts ve