e IBM Model 1 score.
    We attribute its success that it addresses the weakness of the baseline system to omit content words and that it improves word selection by employing a triggering effect.
    We hypothesize that this allows for better use of context in, for example, choosing among senses of the source language word.
    A major goal of this work was to find out if we can exploit annotated data such as treebanks for Chinese and English and make use of state-of-the-art deep or shallow parsers to improve MT quality.
    Unfortunately, none of the implemented syntactic features achieved a statistically significant improvement in the BLEU score.
    Potential reasons for this might be: tive to the grammaticality of MT output.
    This could not only make it difficult to see an improvement in the system&#8217;s output, but also potentially mislead the BLEU-based optimization of the feature weights.
    A significantly larger corpus for discriminative training and for evaluation would yield much smaller conf