eight on the edge between nodes I and Q and that on the edge between J and Q.
    In other words: In vector space, average link starts by assigning each vector to a single cluster.
    The centroid of each cluster is found by calculating the average of all the context vectors that make up the cluster.
    At each iteration, average link selects the pair of clusters whose centroids are closest with respect to their cosines.
    The selected pair of clusters is merged and a centroid is computed for this newly created cluster.
    Partitional algorithms divide an entire set of instances into a predetermined number of clusters (K) without going through a series of pairwise comparisons.
    As such these methods are somewhat faster than hierarchical algorithms.
    For example, the well known K-means algorithm is partitional.
    In vector space, each instance is represented by a context vector.
    K-means initially selects K random vectors to serve as centroids of these initial K clusters.
    It then assigns ev