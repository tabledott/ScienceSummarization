nobserved cooccurrences that are likely to occur in a new piece of text and those that are not These distinctions ought to be made using the data that do occur in the corpus.
    Thus, beyond its own practical importance, the sparse data problem provides an informative touchstone for theories on generalization and analogy in linguistic data.
    The literature suggests two major approaches for solving the sparse data problem: smoothing and class based methods.
    Smoothing methods estimate the probability of unobserved cooccurrences using frequency information (Good, 1953; Katz, 1987; Jelinek and Mercer, 1985; Church and Gale, 1991).
    Church and Gale (Church and Gale, 1991) show, that for unobserved bigrams, the estimates of several smoothing methods closely agree with the probability that is expected using the frequencies of the two words and assuming that their occurrence is independent ((Church and Gale, 1991), figure 5).
    Furthermore, using held out data they show that this is the probability that 