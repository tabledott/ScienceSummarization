bsequent attachments has the probability: Note that assuming each tree is lexicalized by one word the derivation D corresponds to a sentence of n + 1 words.
    In the next section we show how to exploit this notion of tag dictionary to the problem of statistical parsing.
  
  
    Many supervised methods of learning from a Treebank have been studied.
    The question we want to pursue in this paper is whether unlabeled data can be used to improve the performance of a statistical parser and at the same time reduce the amount of labeled training data necessary for good performance.
    We will assume the data that is input to our method will have the following characteristics: The pair of probabilistic models can be exploited to bootstrap new information from unlabeled data.
    Since both of these steps ultimately have to agree with each other, we can utilize an iterative method called CoTraining that attempts to increase agreement between a pair of statistical models by exploiting mutual constraints between 