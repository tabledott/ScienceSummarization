t very satisfactory because one of the goals of our work is precisely to avoid the problems of data sparseness by grouping words into classes.
    It turns out that the problem is avoided by our clustering technique, since it does not need to compute the KL distance between individual word distributions, but only between a word distribution and average distributions, the current cluster centroids, which are guaranteed to be nonzero whenever the word distributions are.
    This is a useful advantage of our method compared with agglomerative clustering techniques that need to compare individual objects being considered for grouping.
  
  
    In general, we are interested in how to organize a set of linguistic objects such as words according to the contexts in which they occur, for instance grammatical constructions or n-grams.
    We will show elsewhere that the theoretical analysis outlined here applies to that more general problem, but for now we will only address the more specific problem in which the objec