B gives a break down of the correlations for each of the lan6Tables 8 and 9 exclude the Spanish-English News Task, since it had a negative correlation with most of the automatic metrics.
    See Tables 19 and 20. guage pairs and test sets.
    Tables 10 and 11 report the consistency of the automatic evaluation metrics with human judgments on a sentence-by-sentence basis, rather than on the system level.
    For the translations into English the ULC metric (which itself combines many other metrics) had the strongest correlation with human judgments, correctly predicting the human ranking of a each pair of system translations of a sentence more than half the time.
    This is dramatically higher than the chance baseline, which is not .5, since it must correctly rank a list of systems rather than a pair.
    For the reverse direction meteor-ranking performs very strongly.
    The svn-rank which had the lowest overall correlation at the system level does the best at consistently predicting the translations of syn