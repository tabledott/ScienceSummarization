.
  
  
    A key aim in natural language processing is to learn a mapping from natural language sentences to formal representations of their meaning.
    Recent work has addressed this problem by learning semantic parsers given sentences paired with logical meaning representations (Thompson &amp; Mooney, 2002; Kate et al., 2005; Kate &amp; Mooney, 2006; Wong &amp; Mooney, 2006, 2007; Zettlemoyer &amp; Collins, 2005, 2007; Lu et al., 2008).
    For example, the training data might consist of English sentences paired with lambda-calculus meaning representations: Given pairs like this, the goal is to learn to map new, unseen, sentences to their corresponding meaning.
    Previous approaches to this problem have been tailored to specific natural languages, specific meaning representations, or both.
    Here, we develop an approach that can learn to map any natural language to a wide variety of logical representations of linguistic meaning.
    In addition to data like the above, this approach can also learn from