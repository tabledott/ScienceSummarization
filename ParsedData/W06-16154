ow how to use SCL to transfer a PoS tagger from the Wall Street Journal (financial news) to MEDLINE (biomedical abstracts), which use very different vocabularies, and we demonstrate not only improved PoS accuracy but also improved end-to-end parsing accuracy while using the improved tagger.
    An important but rarely-explored setting in domain adaptation is when we have no labeled training data for the target domain.
    We first demonstrate that in this situation SCL significantly improves performance over both supervised and semi-supervised taggers.
    In the case when some in-domain labeled training data is available, we show how to use SCL together with the classifier combination techniques of Florian et al. (2004) to achieve even greater performance.
    In the next section, we describe a motivating example involving financial news and biomedical data.
    Section 3 describes the structural correspondence learning algorithm.
    Sections 6 and 7 report results on adapting from the Wall Street Journal t