y is concerned.
    In general, it can at most be said to stay close to the real stacking systems, except for the cleanest data set, LOB, where it is clearly being outperformed.
    This is a fundamental change from our earlier experiments, where TagPair was significantly better than MBL and Decision Trees.
    Our explanation at the time, that the stacked systems suffered from a lack of training data, appears to be correct.
    A closer investigation below shows at which amount of training data the crossover point in quality occurs (for LOB).
    Another unresolved issue from the earlier experiments is the effect of making word or context information available to the stacked classifiers.
    With LOB and a single 114K tune set (van Halteren, Zavrel, and Daelemans 1998), both MBL and Decision Trees degraded significantly when adding context, and MBL degraded when adding the word.'
    With the increased amount of training material, addition of the context generally leads to better results.
    For MBL, there 