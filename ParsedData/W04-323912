1992) have a similar strategy; constructing an optimal hypothesis that maximizes the smallest margin between the positive and negative examples.
    We here describe a connection between our Boosting algorithm and SVMs with tree kernel (Collins and Duffy, 2002; Kashima and Koyanagi, 2002).
    Tree kernel is one of the convolution kernels, and implicitly maps the example represented in a labeled ordered tree into all subtree spaces.
    The implicit mapping defined by tree kernel is given as: &#934;(x)=(I(t1 &#8838; x), ... , I(t|F |&#8838; x)), where tj&#8712;F, x &#8712; X and I(&#183;) is the indicator function 1.
    The final hypothesis of SVMs with tree kernel can be given by Similarly, the final hypothesis of our boosting algorithm can be reformulated as a linear classifier: 1Strictly speaking, tree kernel uses the cardinality of each substructure.
    However, it makes little difference since a given tree is often sparse in NLP and the cardinality of substructures will be approximated by their existen