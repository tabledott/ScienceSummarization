tively relaxes the constraints on the ME model, which allows the model to use low frequency features without overfitting.
    Achieving optimal performance with Gaussian smoothing and without cutoffs demonstrates that low frequency features can contribute to good performance.
  
  
    We would like to thank Joshua Goodman, Miles Osborne, Andrew Smith, Hanna Wallach, Tara Murphy and the anonymous reviewers for their comments on drafts of this paper.
    This research is supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.
  
  
    Kamal Nigam, John Lafferty, and Andrew McCallum.
    1999.
    Using maximum entropy for text classification.
    In Proceedings of the IJCAI-99 Workshop on Machine Learning for Information Filtering, pages 61-67, Stockholm, Sweden.
    Adwait Ratnaparkhi.
    1996.
    A maximum entropy part-ofspeech tagger.
    In Proceedings of the EMNLP Conference, pages 133-142, Philadelphia, PA. Adwait Ratnapark