s output is fed to a classifier.
    The simple semantic space may not take word order or sentence structure into account, but nevertheless achieves considerable semantic expressivity: it is on par with the third-order tensor without having access to as much data (3 billion words) or a syntactically parsed corpus.
    What do these findings tell us about the future of compositional models for distributional semantics?
    The problem of finding the right methods of vector composition cannot be pursued independent of the choice of lexical representation.
    Having tested many model combinations, we argue that in a good model of distributive semantics representation and composition must go hand in hand, i.e., they must be mutually learned.
    Acknowledgments We are grateful to Jeff Mitchell for his help with the re-implementation of his models.
    Thanks to Frank Keller and Micha Elsner for their input on earlier versions of this work and to Richard Socher for technical assistance.
    We acknowledge the sup