ical probability (e.g. without context, man is more probably a noun than a verb), and its contextual probability (e.g. after a pronoun, man is more probably a verb than a noun, as in they man the boats).
    Several approaches have been proposed to construct automatic taggers.
    Most work on statistical methods has used n-gram models or Hidden Markov Model-based taggers (e.g.
    Church, 1988; DeRose, 1988; Cutting et al. 1992; Merialdo, 1994, etc.).
    In these approaches, a tag sequence is chosen for a sentence that maximizes the product of lexical and contextual probabilities as estimated from a tagged corpus.
    In rule-based approaches, words are assigned a tag based on a set of rules and a lexicon.
    These rules can either be hand-crafted (Garside et al., 1987; Klein &amp; Simmons, 1963; Green 8.6 Rubin, 1971), or learned, as in Hindle (1989) or the transformation-based error-driven approach of Brill (1992).
    In a memory-based approach, a set of cases is kept in memory.
    Each case consists o