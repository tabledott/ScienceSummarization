and yields surprising gains in accuracy, at both the aggregate and sentence level.
  
  
    Information-extraction (IE), the process of generating relational data from natural-language text, continues to gain attention.
    Many researchers dream of creating a large repository of high-quality extracted tuples, arguing that such a knowledge base could benefit many important tasks such as question answering and summarization.
    Most approaches to IE use supervised learning of relation-specific examples, which can achieve high precision and recall.
    Unfortunately, however, fully supervised methods are limited by the availability of training data and are unlikely to scale to the thousands of relations found on the Web.
    A more promising approach, often called &#8220;weak&#8221; or &#8220;distant&#8221; supervision, creates its own training data by heuristically matching the contents of a database to corresponding text (Craven and Kumlien, 1999).
    For example, suppose that r(e1, e2) = Founded(Jobs,Appl