luding the following: Random: ignoring pCRU probabilities, randomly select generation rules.
    N-gram: ignoring pCRU probabilities, generate set of alternatives and select the most likely according to a given n-gram language model.
    Greedy: select the most likely among each set of candidate generation rules.
    Greedy roulette: select rules with likelihood proportional to their pCRU probability.
    The greedy modes are deterministic and therefore considerably cheaper in computational terms than the equivalent n-gram method (Belz, 2005).
  
  
    The main goal of our experiments was to determine how well a variety of automatic evaluation metrics correlated with human judgments of text quality in NLG.
    A secondary goal was to determine if there were types of NLG systems for which the correlation of automatic and human evaluation was particularly good or bad.
    Data: We extracted from each forecast in the SUMTIME corpus the first description of wind (at 10m height) from every morning forecast (the t