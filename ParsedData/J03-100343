an use this graph as our initial value of bestGraph.
    One of the important open questions in natural language generation is how the common rule-based approaches to generation can be combined with recent insights from statistical natural language processing (see, e.g., Langkilde and Knight [1998] and Malouf [2000] for partial answers).
    The approach proposed in this article makes it possible to combine graph reformulations of well-known rule-based generation algorithms with stochastic cost functions (the result resembles a Markov model).
    Such a cost function could be derived from a sufficiently large corpus.
    For instance, as a first approximation we could define the costs of adding an edge e in terms of the probability P(e) that e occurs in a distinguishing description (estimated by counting occurrences): Thus, properties that occur frequently are cheap; properties that are relatively rare are expensive.
    In this way, we would probably derive that polish owczarek nizinny sheepdog indeed costs 