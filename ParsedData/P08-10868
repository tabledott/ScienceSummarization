eeding another cluster, B denoting the number of distinct bigrams in the training corpus, and I denoting the number of iterations, the worst case complexity of the algorithm is in: When using large corpora with large numbers of bigrams the number of required updates can increase towards the quadratic upper bound as Npre c and Nsuc c approach Nc.
    For a more detailed description and further analysis of the complexity, the reader is referred to (Martin et al., 1998).
  
  
    Modifying the exchange algorithm in order to optimize the log likelihood of a predictive class bigram model, leads to substantial performance improvements, similar to those previously reported for another type of one-sided class model in (Whittaker and Woodland, 2001).
    We use a predictive class bigram model as given in Eq.
    (2), for which the maximum-likelihood probability estimates for the n-grams are given by their relative frequencies: where N(w) again denotes the number of occurrences of the word w in the training corpus and