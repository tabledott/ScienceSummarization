ke names of companies, and events.
    Details about these experiments can be found in (Bagga 98b).
  
  
    As a novel research problem, cross document coreference provides an different perspective from related phenomenon like named entity recognition and within document coreference.
    Our system takes summaries about an entity of interest and uses various information retrieval metrics to rank the similarity of the summaries.
    We found it quite challenging to arrive at a scoring metric that satisfied our intuitions about what was good system output v.s. bad, but we have developed a scoring algorithm that is an improvement for this class of data over other within document coreference scoring algorithms.
    Our results are quite encouraging with potential performance being as good as 84.6% (F-Measure).
  
  
    The first author was supported in part by a Fellowship from IBM Corporation, and in part by the Institute for Research in Cognitive Science at the University of Pennsylvania.
  

