ring items with less than 2 non NIL and non NAME responses and a few witherroneous PoS tags.
			The words included were se lected either manually (70 words) from examinationof a variety of lexical resources and corpora or au tomatically (131) using information in these lexical resources.
			Words were selected from those having a number of different meanings, each with at least onesynonym.
			Since typically the distribution of mean ings of a word is strongly skewed (Kilgarriff, 2004), for the test set we randomly selected 20 words ineach PoS for which we manually selected the sen tences 2 (we refer to these words as MAN) whilst forthe remaining words (RAND) the sentences were se lected randomly.
			2.2 Inter Annotator Agreement.
			Since we have sets of substitutes for each item andannotator, pairwise agreement was calculated between each pair of sets (p1, p2 ? P ) from each pos sible pairing (P ) as ? p1,p2?P p1?p2 p1?p2 |P | 1Full instructions given to the annotators are posted at http://www.informatics.su