For this reason, we allowed in the training data only one message from the same user.
			As we show later, this boosts the classification performance, mainlybecause it removes tweets labeled as subjective by the data sources but are in fact objec tive; 3.
			Top opinion words: to clean the objective.
			training set, we remove from this set tweets that contain the top-n opinion words in the subjectivity training set, e.g., words as cool, suck, awesome etc. As we show in Section 4, this process is in fact able to remove certain noisy in the training data,leading to a better performing subjectivity classi fier.
			To illustrate which of the proposed features are more effective for this task, the top-5 features in terms of information gain, based on our trainingdata, are: positive polarity, link, strong subjec tive, upper case and verbs.
			Three of them aremeta-information (positive polarity, strong sub jective and verbs) and the other two are tweet syntax features (link and upper case).
			Here is a typical ex