when it comes to the translation of a particular test set, the question is whether all of the available training data are relevant to the translation task or not.
    Moreover, working with large amounts of training data requires more computational power.
    So if we can identify a subset of training data which are relevant to the current task and use only this to re-train the models, we can reduce computational complexity significantly.
    We propose to Filter the training data, either bilingual or monolingual text, to identify the parts 2006 NIST evaluation (see Table 2).
    We used the LDC segmenter for Chinese.
    The multiple translation corpora multi-p3 and multi-p4 were used as development corpora.
    Evaluation was performed on the 2004 and 2006 test sets.
    Note that the training data consists mainly of written text, whereas the test sets comprise three and four different genres: editorials, newswire and political speeches in the 2004 test set, and broadcast conversations, broadcast news, news