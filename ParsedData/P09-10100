
  Reinforcement Learning for Mapping Instructions to Actions
  
    In this paper, we present a reinforcement learning approach for mapping natural language instructions to sequences of executable actions.
    We assume access to a reward function that defines the quality of the executed actions.
    During training, the learner repeatedly constructs action sequences for a set of documents, executes those actions, and observes the resulting reward.
    We use a policy gradient algorithm to estimate the parameters of a log-linear model for action selection.
    We apply our method to interpret instructions in two domains &#8212; Windows troubleshooting guides and game tutorials.
    Our results demonstrate that this method can rival supervised learning techniques while requiring few or no annotated training exam
  
  
    The problem of interpreting instructions written in natural language has been widely studied since the early days of artificial intelligence (Winograd, 1972; Di Eugenio, 1992).
    Mapping i