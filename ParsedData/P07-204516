tion on a large set of transcription hypotheses generated by the speech recognizers and by combining scores of acoustic models, language models, and translation models.
    Recently, approaches have been proposed for improving translation quality through the processing of multiple input hypotheses.
    We have implemented in Moses confusion network decoding as discussed in (Bertoldi and Federico 2005), and developed a simpler translation model and a more efficient implementation of the search algorithm.
    Remarkably, the confusion network decoder resulted in an extension of the standard text decoder.
    5 Efficient Data Structures for Translation Model and Language Models With the availability of ever-increasing amounts of training data, it has become a challenge for machine translation systems to cope with the resulting strain on computational resources.
    Instead of simply buying larger machines with, say, 12 GB of main memory, the implementation of more efficient data structures in Moses makes it poss