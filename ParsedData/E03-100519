
    As usual, all trees were stripped off their semantic tags, co-reference information and quotation marks.
    Without loss of generality, all trees were converted to binary branching (and were reconverted to n-ary trees after parsing).
    We employed the same unknown (category) word model as in Bod (2001), based on statistics on word-endings, hyphenation and capitalization in combination with Good-Turing (Bod 1998: 85 87).
    We used &amp;quot;evalb&amp;quot;4 to compute the standard PARSEVAL scores for our results (Manning &amp; Schiitze 1999).
    We focused on the Labeled Precision (LP) and Labeled Recall (LR) scores, as these are commonly used to rank parsing systems.
    Our first experimental goal was to compare the two PCFG-reductions in Section 2.2, which we will refer to resp. as Bod01 and Bon99.
    Table 1 gives the results of these experiments and compares them with some other statistical parsers (resp.
    Collins 1996, Charniak 1997, Collins 1999 and Charniak 2000).
    While the PCFG redu