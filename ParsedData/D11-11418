gger, obtaining a 26% reduction in error.
    In addition we include 40K tokens of annotated IRC chat data (Forsythand and Martell, 2007), which is similar in style.
    Like Twitter, IRC data contains many misspelled/abbreviated words, and also more pronouns, and interjections, but fewer determiners than news.
    Finally, we also leverage 50K POS-labeled tokens from the Penn Treebank (Marcus et al., 1994).
    Overall T-POS trained on 102K tokens (12K from Twitter, 40K from IRC and 50K from PTB) results in a 41% error reduction over the Stanford tagger, obtaining an accuracy of 0.883.
    Table 3 lists gains on some of the most common error types, for example, T-POS dramatically reduces error on interjections and verbs that are incorrectly classified as nouns by the Stanford tagger.
    Shallow parsing, or chunking is the task of identifying non-recursive phrases, such as noun phrases, verb phrases, and prepositional phrases in text.
    Accurate shallow parsing of tweets could benefit several applications 