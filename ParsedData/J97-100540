r of 11x21x4 (.31).
    The detailed formula for a then simplifies to: This gives a = .42, meaning that the observed case of one agreement out of two potential agreements on boundaries in our example is not quite halfway between chance and perfect agreement.
    Consider a case where two subjects had 12 responses each (j = 12), each subject responded with 1 half the time (ni = no -=- 12), and wherever one put a 1, the other did not (M = 12).
    The data contains the maximum number of disagreements, yet a = &#8212;0.92, or somewhat less than &#8212;1, meaning that a small proportion of the observed disagreement would have arisen by chance.
    Table 2 presents the reliability results from a comparison of boundaries found by two distinct partitions of subjects' responses on four narratives.
    An a of .80 using two partitions of seven subjects would represent very good reproducibility, with values above .67 being somewhat good (Krippendorff 1980).
    Note that reliability on narrative 7 (.73) is good despite