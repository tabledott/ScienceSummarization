parameters of the maximum entropy model learned from the source domain as the means of a Gaussian prior when training a new model on the target data.
    Florian et al. (2004) first train a NE tagger on the source domain, and then use the tagger&#8217;s predictions as features for training and testing on the target domain.
    The only work we are aware of that directly modmore weights are put on the target instances in the objective function than in standard bootstrapping. els the different distributions in the source and the target domains is by Daum&#180;e III and Marcu (2006).
    They assume a &#8220;truly source domain&#8221; distribution, a &#8220;truly target domain&#8221; distribution, and a &#8220;general domain&#8221; distribution.
    The source (target) domain data is generated from a mixture of the &#8220;truly source (target) domain&#8221; distribution and the &#8220;general domain&#8221; distribution.
    In contrast, we do not assume such a mixture model.
    None of the above methods would w