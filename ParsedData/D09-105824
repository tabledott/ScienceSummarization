 around 300 separate processes.
    Note that once the generative models have been estimated, decoding with the model, or training the model on labeled data, is relatively inexpensive, essentially taking the same amount of computation as standard dependency-parsing approaches.
    Finally, Table 5 displays the final results on test data.
    There results are obtained using the best setting in terms of the development data performance.
    Note that the English dependency parsing results shown in the table were achieved using 3.72 billion tokens of unlabeled data.
    The improvements on test data are similar to those observed on the development data.
    To determine statistical significance, we tested the difference of parent-prediction error-rates at the sentence level using a paired Wilcoxon signed rank test.
    All eight comparisons shown in Table 5 are significant with p &lt; 0.01.
  
  
    Table 6 shows the performance of a number of state-of-the-art approaches on the English and Czech data sets.
   