e previous experiment.
    In terms of relevance, the asterisk in figure 12 marks sentences that the human judge found particularly relevant in the overall context (cf. the full set in figure 5).
    Six out of all 15 sentences, and 6 out of the 10 sentences that received the correct rhetorical status, were judged relevant in the example.
    Table 12 reports the figure for the entire corpus by comparing the system&#8217;s output of correctly classified rhetorical categories to human judgment.
    In all cases, the results are far above the nontrivial baseline.
    On AIM, CONTRAST, and BASIS sentences, our system achieves very high precision values of 96%, 70%, and 71%.
    Recall is lower at 70%, 24%, and 39%, but low recall is less of a problem in our final task.
    Therefore, the main bottleneck is correct rhetorical classification.
    Once that is accomplished, the selected categories show high agreement with human judgment and should therefore represent good material for further processing steps.
    