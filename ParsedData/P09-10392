an ILP, but efficient formulations remain an open problem.
    Our formulations offer the following comparative advantages: from data.
    In particular, our formulations handle higher-order arc interactions (like siblings and grandparents), model word valency, and can learn to favor nearly-projective parses.
    We evaluate the performance of the new parsers on standard parsing tasks in seven languages.
    The techniques that we present are also compatible with scenarios where expert knowledge is available, for example in the form of hard or soft firstorder logic constraints (Richardson and Domingos, 2006; Chang et al., 2008).
  
  
    A dependency tree is a lightweight syntactic representation that attempts to capture functional relationships between words.
    Lately, this formalism has been used as an alternative to phrase-based parsing for a variety of tasks, ranging from machine translation (Ding and Palmer, 2005) to relation extraction (Culotta and Sorensen, 2004) and question answering (Wang et al.,