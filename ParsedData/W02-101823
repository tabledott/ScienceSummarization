 how source words are mapped into target words and how target words are re-ordered to yield well-formed target sentences.
    A variety of methods are used to account for the re-ordering stage: word-based (Brown et al., 1993), templatebased (Och et al., 1999), and syntax-based (Yamada and Knight, 2001), to name just a few.
    Although these models use different generative processes to explain how translated words are re-ordered in a target language, at the lexical level they are quite similar; all these models assume that source words are individually translated into target words.1 We suspect that MT researchers have so far chosen to automatically learn translation lexicons defined only over words for primarily pragmatic reasons.
    Large scale bilingual corpora with vocabularies in the range of hundreds of thousands yield very large translation lexicons.
    Tuning the probabilities associated with these large lexicons is a difficult enough task to deter one from trying to scale up to learning phrase-based