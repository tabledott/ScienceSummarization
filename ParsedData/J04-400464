 model.
    Surprisingly, this resulted in only a 0.45% absolute reduction in F-measure (3.3% relative increase in error).
    Unfortunately, this result was not entirely conclusive, in that Gildea was able to reimplement Collins&#8217; baseline model only partially, and the performance of his partial reimplementation was not quite as good as that of Collins&#8217; parser.35 Training on Sections 02&#8211;21, we have duplicated Gildea&#8217;s bigram-removal experiment, except that our chosen test set is Section 00 instead of Section 23 and our chosen model is the more widely used Model 2.
    Using the mode that most closely emulates Collins&#8217; Model 2, with bigrams, our engine obtains a recall of 89.89% and a precision of 90.14% on sentences of length &#8804; 40 words (see Table 8, Model Mtw,tw).
    Without bigrams, performance drops only to 89.49% on recall, 89.95% on precision&#8212; an exceedingly small drop in performance (see Table 8, Model Mtw,t).
    In an additional experiment, we have examined t