cent work on training using outer bounds (see, e.g., (Taskar et al., 2003; Finley and Joachims, 2008; Kulesza and Pereira, 2008; Martins et al., 2009)).
    Note, however, that the LP relaxation optimized by dual decomposition is significantly tighter than Z.
    Thus, an alternative approach would be to use the dual decomposition algorithm for inference during training.
  
  
    We report results on a number of data sets.
    For comparison to Martins et al. (2009), we perform experiments for Danish, Dutch, Portuguese, Slovene, Swedish and Turkish data from the CoNLL-X shared task (Buchholz and Marsi, 2006), and English data from the CoNLL-2008 shared task (Surdeanu et al., 2008).
    We use the official training/test splits for these data sets, and the same evaluation methodology as Martins et al. (2009).
    For comparison to Smith and Eisner (2008), we also report results on Danish and Dutch using their alternate training/test split.
    Finally, we report results on the English WSJ treebank, and the Pra