rs to translations commissioned by the Linguistics Data Consortium.
    For the Chinese, French, Spanish, and German translations we used the the MultipleTranslation Chinese Corpus.3 This corpus has 11 reference human translations for each Chinese source sentence.
    We had bilingual graduate students translate the first 50 English sentences of that corpus into French, German and Spanish, so that we could re-use the multiple English reference translations.
    The Urdu sentences were taken from the NIST MT Eval 2008 Urdu-English Test Set4 which includes three distinct English translations for every Urdu source sentence.
    Figure 4 shows the Turker&#8217;s translation quality in terms of the Bleu metric.
    To establish an upper bound on expected quality, we determined what the Bleu score would be for a professional translator when measured against other professionals.
    We calculated a Bleu score for each of the 11 LDC translators using the other 10 translators as the reference set.
    The average Bleu