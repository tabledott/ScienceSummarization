 in which complexity is most relevant (e.g., &#8220;typical&#8221; or worst-case complexity, cf. footnote 3).
    Far from aiming to speak the last word on these issues, the material discussed here does shed some light on them.
    For example, even a fast algorithm can require a large number of calculations, in which case a solution may never be found; in the case of GRE, this happens when the set of distractors or the set of properties becomes extremely large (Section 3.2).
    Conversely, a complex algorithm can be safe to use if the domain is small (or if key calculations can be performed offline; e.g., Bateman 1999).
    This may be achieved by putting a bound on the size of the search space, and this may be justifiable on empirical grounds (see the discussion of D&amp;RBoolean in Section 4.3).
    One might, on the other hand, argue that bounding does not eliminate the disadvantages of an otherwise intractable algorithm, because the true nature of an algorithm is best revealed &#8220;by considering how 