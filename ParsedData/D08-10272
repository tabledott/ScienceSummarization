age annotations.
    We chose five natural language understanding tasks that we felt would be sufficiently natural and learnable for non-experts, and for which we had gold standard labels from expert labelers, as well as (in some cases) expert labeler agreement information.
    The tasks are: affect recognition, word similarity, recognizing textual entailment, event temporal ordering, and word sense disambiguation.
    For each task, we used AMT to annotate data and measured the quality of the annotations by comparing them with the gold standard (expert) labels on the same data.
    Further, we compare machine learning classifiers trained on expert annotations vs. non-expert annotations.
    In the next sections of the paper we introduce the five tasks and the evaluation metrics, and offer methodological insights, including a technique for bias correction that improves annotation quality.2
  
  
    The idea of collecting annotations from volunteer contributors has been used for a variety of tasks.
    Luis v