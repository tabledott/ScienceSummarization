amp;quot;1&amp;quot; in both variables over the probability that such an event would have if the two variables were independent, and thus provides a measure of the departure from independence.
    The Dice coefficient, on the other hand, combines the conditional probabilities p(X==1 I Y=1) and p(Y=1 I X=1) with equal weights in a single number.
    This can be shown by replacing p(X=1, Y=1) on the right side of equation (1):3 As is evident from the above equation, the Dice coefficient depends only on the conditional probabilities of seeing a &amp;quot;1&amp;quot; for one of the variables after seeing a &amp;quot;1&amp;quot; for the other variable, and not on the marginal probabilities of &amp;quot;1&amp;quot;s for the two variables.
    In contrast, both the average and the specific mutual information depend on both the conditional and the marginal probabilities.
    For S/(X, Y) in particular, we have To select among the three measures, we first observe that for our application, 1-1 matches (paired samples w