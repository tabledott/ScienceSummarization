get word, t: P(r I h, pt, gov, position, voice, t) where r indicates semantic role, h head word, and pt phrase type.
    It would be possible to calculate this distribution directly from the training data by counting the number of times each role appears with a combination of features and dividing by the total number of times the combination of features appears: #(r, h, pt,gov, position, voice, t) P(r  |h, pt, gov, position, voice, t) = #(h, pt,gov, position, voice, t) In many cases, however, we will never have seen a particular combination of features in the training data, and in others we will have seen the combination only a small number of times, providing a poor estimate of the probability.
    The small number of training sentences for each target word and the large number of values that the head word feature in particular can take (any word in the language) contribute to the sparsity of the data.
    Although we expect our features to interact in various ways, we cannot train directly on the full featu