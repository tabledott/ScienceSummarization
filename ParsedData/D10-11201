ely studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing.
    In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010).
    In this paper, we present an alternative grammar induction approach that exploits these structural correspondences by declaratively encoding a small set of universal dependency rules.
    As input to the model, we assume a corpus annotated with coarse syntactic categories (i.e., high-level part-ofspeech tags) and a set of universal rules defined over these categories, such as those in Table 1.
    These rules incorporate the definitional properties of syntactic categories in terms of their interdependencies and thus are universal across languages.
    They can potentially help disambiguat