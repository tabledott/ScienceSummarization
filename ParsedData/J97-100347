ve been chosen.
    This seems problematic, since the initial comparisons are between very large text segments: the first boundary is chosen by comparing the entire text to the right and left of the initial position.
    The algorithm is evaluated only in terms of how well it distinguishes entire articles from one another when concatenated into one file.
    The precision/recall tradeoffs varied widely: on 660 Wall Street Journal articles, if the algorithm is allowed to be off by up to three sentences, it achieves precision of .80 with recall of .30, and precision of .30 with recall of .92.
  
  
    The TextTiling algorithm for discovering subtopic structure using term repetition has three main parts: Each is discussed in turn below.
    The methods for lexical score determination were outlined in Section 4, but more detail is presented here.
    Tokenization refers to the division of the input text into individual lexical units, and is sensitive to the format of the input text.
    For example, if the docum