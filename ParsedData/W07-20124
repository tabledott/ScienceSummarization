
			The predominant feature of this corpus is a high number of entities in each document set, due to the fact that the ambiguous names were extracted from the most common names in the US Census.
			This corpus did not completely match task specifications because it did not consider documents with internal ambiguity, nor it did consider non-person entities; but it was, however, a cost-effective way of releasing data toplay around with.
			During the first weeks after releasing this trial data to potential participants, some annotation mistakes were noticed.
			We preferred, how ever, to leave the corpus ?as is? and concentrate our efforts in producing clean training and test datasets, rather than investing time in improving trial data.
			2.1.2 Training data In order to provide different ambiguity scenarios, we selected person names from different sources: US Census.
			We reused the Web03 corpus (Mann, 2006), which contains 32 names randomly picked from the US Census, and was well suited for the task.
			Wiki