ij = e&#8727;i , and initialize &#945;ij = 0 for all other values of j.
    Then, repeatedly choose a sentence i and a pair of hypotheses j, j0, and let where where we set C = 0.01.
    The first term means that we want w0 to be close to w, and second term (the generalized hinge loss) means that we want w0 to score e&#8727;i higher than each eij by a margin at least as wide as the loss `ij.
    When training is finished, the weight vectors from all iterations are averaged together.
    (If multiple where the function clip[x,y](z) gives the closest number to z in the interval [x, y].
    Assuming BLEU as the evaluation criterion, the loss `ij of ei j relative to e&#8727;i should be related somehow to the difference between their BLEU scores.
    However, BLEU was not designed to be used on individual sentences; in general, the highest-BLEU translation of a sentence depends on what the other sentences in the test set are.
    Sentence-level approximations to BLEU exist (Lin and Och, 2004; Liang et al., 2006), b