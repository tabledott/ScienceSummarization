ith previous p(oi = M|ei, f ai ,ai?1,ai) 1 ,4 and is 0.223 0.672 0.942 2 , and also 0.201 0.560 0.948 Swap with previous p(oi = S|ei, f ai ,ai?1,ai) 3 ?){ of china 0.303 0.617 0.651 4 ??
			, he said 0.003 0.030 0.395 Monotone with next p(oi = M|ei, f ai ,ai+1,ai) 5 ???
			, he pointed out that 0.601 0.770 0.991 6 l , however , 0.517 0.728 0.968 Swap with next p(oi = S|ei, f ai ,ai+1,ai) 7 {0 the development of 0.145 0.831 0.900 8 {? at the invitation of 0.272 0.834 0.925 Table 2: Monotone and swap probabilities for specific phrases according to the three models (word, phrase, and hierarchical).
			To ensure probabilities are representative, we only selected phrase pairs that occur at least 100 times in the training data.
			probability mass to D. Conversely, the hierarchical model counts considerably less discontinuous cases, and is the only model that accounts for the fact that real data is predominantly monotone.Since D is a rather uninformative default cat egory that gives no clue how a particular phrases