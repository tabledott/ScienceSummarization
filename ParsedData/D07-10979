 beneficial to projectivize the train ing data without trying to recover non-projective dependencies in the parser output.
			This was also the setting that was used for Arabic in the dry run and final test.
			7The names Top and Next refer to the token on top of the stack S and the first token in the remaining input I, respectively.
			selection.
			The total number of features in the tuned models varies from 18 (Turkish) to 56 (Hungarian)but is typically between 20 and 30.
			This feature se lection process constituted the major development effort for the Single Malt parser and also gave the greatest improvements in parsing accuracy, but since feature selection was to some extent interleaved with learning algorithm optimization, we only report the cumulative effect of both together in table 1.
			2.3 Learning Algorithm.
			MaltParser supports several learning algorithms butthe best results have so far been obtained with sup port vector machines, using the LIBSVM package (Chang and Lin, 2001).
			We use a qu