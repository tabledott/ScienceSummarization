at allows for efficiently constructing and representing the unsmoothed error surface over all sentence hypotheses that are represented in a phrase lattice.
    The proposed algorithm was used to train the feature function weights of a log-linear model for a statistical machine translation system under the Minimum Error Rate Training (MERT) criterion.
    Lattice MERT was shown analytically and experimentally to be superior over N-best MERT, resulting in significantly faster convergence speed and a reduced number of decoding steps.
    While the approach was used to optimize the model parameters of a single machine translation system, there are many other applications in which this framework can be useful, too.
    One possible usecase is the computation of consensus translations from the outputs of multiple machine translation systems where this framework allows us to estimate the system prior weights directly on confusion networks (Rosti et al., 2007; Macherey and Och, 2007).
    It is also straightforward t