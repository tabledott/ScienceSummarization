ence, optionally combining relation mentions (Zhou et al., 2005; Zhou et al., 2007; Surdeanu and Ciaramita, 2007).
    Supervised relation extraction suffers from a number of problems, however.
    Labeled training data is expensive to produce and thus limited in quantity.
    Also, because the relations are labeled on a particular corpus, the resulting classifiers tend to be biased toward that text domain.
    An alternative approach, purely unsupervised information extraction, extracts strings of words between entities in large amounts of text, and clusters and simplifies these word strings to produce relation-strings (Shinyama and Sekine, 2006; Banko et al., 2007).
    Unsupervised approaches can use very large amounts of data and extract very large numbers of relations, but the resulting relations may not be easy to map to relations needed for a particular knowledge base.
    A third approach has been to use a very small number of seed instances or patterns to do bootstrap learning (Brin, 1998; Riloff and