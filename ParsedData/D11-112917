er than count how many times it has occurred close to their corresponding matrices: it is the lexical tokens that form the context, not their meaning.
    Each relational word P with grammatical type 7r and m adjoint types &#945;1, &#945;2, &#183; &#183; &#183; , &#945;m is encoded as an (r &#215; ... &#215; r) matrix with m dimensions.
    Since our vector space N has a fixed basis, each such maaccording to the procedure described in Figure 4.
    Linear algebraically, this procedure corresponds to computing the following Type-logical examples of relational words are verbs, adjectives, and adverbs.
    A transitive verb is represented as a 2 dimensional matrix since its type is nrsnl with two adjoint types nr and nl.
    The corresponding vector of this matrix is lational word &#8216;P&#8217; and its arguments w1, w2, &#183; &#183; &#183; , wm, occurring in the same order as described in P&#8217;s grammatical type 7r.
    Refer to these sequences as &#8216;P&#8217;-relations.
    Suppose there are k of them.