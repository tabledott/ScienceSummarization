classification error rate can be further improved to 2.1%.
    For the other language pairs, the results are similar except that the absolute values of the classification error rates are higher.
    We observe the following: These are desirable properties of an appropriate reordering model.
    The main point is that these are fulfilled not only on the training data, but on unseen test data.
    There seems to be no overfitting problem.
    In Table 5, we present the results for four orientation classes.
    The final error rates are a factor 2-4 larger than for two orientation classes.
    Despite that we observe the same tendencies as for two orientation classes.
    Again, using more features always helps to improve the performance.
    For the translation experiments on the BTEC task, we report the two accuracy measures BLEU (Papineni et al., 2002) and NIST (Doddington, 2002) as well as the two error rates: word error rate (WER) and position-independent word error rate (PER).
    These criteria are comput