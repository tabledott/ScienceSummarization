 .
    In our running example, for ENABLEMENT-NS , .
    The two sub-spans of are and , and only the dominance relationship holds across these spans; the other dominance relationship in , , does not influence the choice for the relation label of .
    The conditional probabilities involved in equation (4) are estimated from the training corpus using maximum likelihood estimation.
    A simple interpolation method is used for smoothing to accommodate data sparseness.
    The counts for the dependency sets are also smoothed using symbolic names for the edu identifiers and accounting only for the distance between them.
    Our discourse parser implements a classical bottom-up algorithm.
    The parser searches through the space of all legal discourse parse trees and uses a dynamic programming algorithm.
    If two constituents are derived for the same discourse span, then the constituent for which the model assigns a lower probability can be safely discarded.
    Figure 5 shows a discourse structure created in a