ecision 'Note that in a decision tree, the leaf distribution is not affected by the order in which questions are asked.
    Asking about Pi, followed by h2 yields the same future distribution as asking about h2 followed by h1. tree can be defined as an interpolated n-grain model where the Ai function is defined as: 1 if hki hk, hk_ is a leaf, Ai (hki hk, &#8226; &#8226; &#8226; hk,.)
    = o otherwise.
    The point of showing the equivalence between ngram models and decision-tree models is to make clear that the power of decision-tree models is not in their expressiveness, but instead in how they can be automatically acquired for very large modeling problems.
    As n grows, the parameter space for an n-gram model grows exponentially, and it quickly becomes computationally infeasible to estimate the smoothed model using deleted interpolation.
    Also, as n grows large, the likelihood that the deleted interpolation process will converge to an optimal or even near-optimal parameter setting becomes vanishingly