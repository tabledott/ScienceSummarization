unigram, bigram, and trigram language models in three versions of his system, which we refer to as n-gram Segmentation (NGS).
    Despite their rather different generative structure, the MBDP and NGS segmentation accuracies are very similar.
    Moreover, the segmentation accuracy of the NGS unigram, bigram, and trigram models hardly differ, suggesting that contextual dependencies are irrelevant to word segmentation.
    However, the segmentations produced by both these methods depend crucially on properties of the search procedures they employ.
    We show this by exhibiting for each model a segmentation that is less accurate but more probable under that model.
    In this paper, we present an alternative framework for word segmentation based on the Dirichlet process, a distribution used in nonparametric Bayesian statistics.
    This framework allows us to develop extensible models that are amenable to standard inference procedures.
    We present two such models incorporating unigram and bigram word depende