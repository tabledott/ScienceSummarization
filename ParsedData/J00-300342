 U, and can be treated as a constant for the purpose of DA classification.
    A quantity proportional to the required likelihood can therefore be obtained either by dividing the posterior tree probability by the prior P(Ui),6 or by training the tree on a uniform prior distribution of DA types.
    We chose the second approach, downsampling our training data to equate DA proportions.
    This also counteracts a common problem with tree classifiers trained on very skewed distributions of target classes, i.e., that low-frequency classes are not modeled in sufficient detail because the majority class dominates the tree-growing objective function. tion of prosody with other knowledge sources, we trained a single tree to discriminate among the five most frequent DA types (STATEMENT, BACKCHANNEL, OPINION, ABANDONED, and AGREEMENT, totaling 79% of the data) and an Other category comprising all remaining DA types.
    The decision tree was trained on a downsampled training subset containing equal proportions of these