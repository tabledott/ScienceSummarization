, we projected the tagset to the coarser set of 17 that they used in their experiments.
    On 24K tokens, our PROTO+SIM model scored 82.2%.
    When Smith and Eisner (2005) limit their tagging dictionary to words which occur at least twice, their best performing neighborhood model achieves 79.5%.
    While these numbers seem close, for comparison, their tagging dictionary contained information about the allowable tags for 2,125 word types (out of 5,406 types) and the their system must only choose, on average, between 4.4 tags for a word.
    Our prototype list, however, contains information about only 116 word types and our tagger must on average choose between 16.9 tags, a much harder task.
    When Smith and Eisner (2005) include tagging dictionary entries for all words in the first half of their 24K tokens, giving tagging knowledge for 3,362 word types, they do achieve a higher accuracy of 88.1%.
    We also tested our POS induction system on the Chinese POS data in the Chinese Treebank (Ircs, 2002).
    