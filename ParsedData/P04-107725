come by.
    Fortunately, we have access to eight MT systems&#8217; outputs, their human assessment data, and the reference translations from 2003 NIST Chinese MT evaluation (NIST 2002a).
    There were 919 sentence segments in the corpus.
    We first computed averages of the adequacy and fluency scores of each system assigned by human evaluators.
    For the input of automatic evaluation methods, we created three evaluation sets from the MT outputs: into lower case, i.e. no case information was used.
    This set was used to examine whether human assessments were affected by case information since not all MT systems generate properly cased output. lower case and stemmed using the Porter stemmer (Porter 1980).
    Since ROUGE computed similarity on surface word level, stemmed version allowed ROUGE to perform more lenient matches.
    To accommodate multiple references, we use a Jackknifing procedure.
    Given N references, we compute the best score over N sets of N-1 references.
    The final score is the a