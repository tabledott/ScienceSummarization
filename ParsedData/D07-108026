 with 10-oracle and 10 best constraints and the approximated BLEU lossfunction significantly outperformed the baseline sys tem in the open test.
			The development data is almost doubled in this setting.
			The MERT approach seems to be confused with the slightly larger data and with the mixed domains from different epochs.
	
	
			In this work, the translation model consisting of millions of features are successfully integrated.
			In or der to avoid poor overfitting, features are limited to word-based features, but are designed to reflect the structures inside hierarchical phrases.
			One of the benefit of MIRA is its flexibility.
			We may includeas many constraints as possible, like m-oracle con straints in our experiments.
			Although we describedexperiments on the hierarchical phrase-based trans lation, the online training algorithm is applicable toany translation systems, such as phrase-based trans lations and syntax-based translations.
			Online discriminative training has already been studied by Tillm