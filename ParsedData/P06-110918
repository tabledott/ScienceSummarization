edure rather than using their (smoothed) relative frequencies (as in U-DOP).
    Note that UML-DOP achieves these improved results with fewer subtrees than U-DOP, due to UML-DOP's more drastic pruning of subtrees.
    It is also noteworthy that UMLDOP, like U-DOP, does not employ a separate class for non-constituents, so-called distituents, while CCM and CCM+DMV do.
    (Interestingly, the top 10 most frequently learned constituents by UMLDOP were exactly the same as by U-DOP -- see the relevant table in Bod 2006).
    We were also interested in testing UML-DOP on longer sentences.
    We therefore included all WSJ sentences up to 40 words after removing empty elements and punctuation (WSJ40) and again sampled 200,000 subtrees for each depth, using the same method as before.
    Furthermore, we compared UML-DOP against a supervised binarized PCFG, i.e. a treebank PCFG whose simple relative frequency estimator corresponds to maximum likelihood (Chi and Geman 1998), and which we shall refer to as &amp;quot;ML-P