-best MBR decoding, which is used in many state-of-the-art research translation systems.
    Moreover, we see gains on three different language pairs.
    There are two potential reasons why Lattice MBR decoding could outperform N-best MBR: a larger hypothesis space from which translations could be selected or a larger evidence space for computing the expected loss.
    Our experiments show that the main improvement comes from the larger evidence space: a larger set of translations in the lattice provides a better estimate of the expected BLEU score.
    In other words, the lattice provides a better posterior distribution over translation hypotheses relative to an Nbest list.
    This is a novel insight into the workings of MBR decoding.
    We believe this could be possibly employed when designing discriminative training approaches for machine translation.
    More generally, we have found a component in machine translation where the posterior distribution over hypotheses plays a crucial role.
    We have sh