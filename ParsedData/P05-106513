eneral tags.
    Motivated by our goal of representing syntax, we used part-of-speech (POS) tags as labeled by a maximum entropy tagger (Ratnaparkhi, 1996).
    These tags allow the model to represent patterns in the text at a higher level than that of individual words, using sequences of POS tags to capture rough syntactic information.
    The resulting vocabulary consisted of 276 words and 56 POS tags.
    Support vector machines (SVMs) are a machine learning technique used in a variety of text classification problems.
    SVMs are based on the principle of structural risk minimization.
    Viewing the data as points in a high-dimensional feature space, the goal is to fit a hyperplane between the positive and negative examples so as to maximize the distance between the data points and the plane.
    SVMs were introduced by Vapnik (1995) and were popularized in the area of text classification by Joachims (1998a).
    The unit of classification in this work is a single article.
    Our SVM classifiers for rea