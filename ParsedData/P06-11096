G-reduction of DOP1 whose size is linear rather than exponential in the size of the training set (Goodman 2003).
    Moreover, Collins and Duffy (2002) show how a tree kernel can be applied to DOP1's all-subtrees representation.
    The currently most successful version of DOP1 uses a PCFG-reduction of the model with an n-best parsing algorithm (Bod 2003).
  
  
    U-DOP extends DOP1 to unsupervised parsing (Bod 2006).
    Its key idea is to assign all unlabeled binary trees to a set of sentences and to next use (in principle) all subtrees from these binary trees to parse new sentences.
    U-DOP thus proposes one of the richest possible models in bootstrapping trees.
    Previous models like Klein and Manning's (2002, 2005) CCM model limit the dependencies to &amp;quot;contiguous subsequences of a sentence&amp;quot;.
    This means that CCM neglects dependencies that are non-contiguous such as between more and than in &amp;quot;BA carried more people than cargo&amp;quot;.
    Instead, UDOP's all-subtrees ap