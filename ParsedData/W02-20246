sted of a cascade of five learners each of which performed 10,000 boosting rounds (Spanish test set: F,3=1=71.49; Dutch test set: F,3=1=60.93) Malouf (2002) tested different models with the shared task data: a statistical baseline model, a Hidden Markov Model and maximum entropy models with different features.
    The latter proved to perform best.
    The maximum entropy models benefited from extra feature which encoded capitalization information, positional information and information about the current word being part of a person name earlier in the text.
    However, incorporating a list of person names in the training process did not help (Spanish test set: F,3=1=73.66; Dutch test set: F,3=1=68.08) Jansche (2002) employed a first-order Markov model as a named entity recognizer.
    His system used two separate passes, one for extracting entity boundaries and one for classifying entities.
    He evaluated different features in both subprocesses.
    The categorization process was trained separately from th