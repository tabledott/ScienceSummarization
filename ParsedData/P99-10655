 (Model 3); estimation techniques that smooth various levels of back-off (in particular using POS tags as word-classes, allowing the model to learn generalizations about POS classes of words).
    Search for the highest probability tree for a sentence is achieved using a CKY-style parsing algorithm.
  
  
    Many statistical parsing methods developed for English use lexicalized trees as a representation (e.g., (Jelinek et al. 94; Magerman 95; Ratnaparkhi 97; Charniak 97; Collins 96; Collins 97)); several (e.g., (Eisner 96; Collins 96; Collins 97; Charniak 97)) emphasize the use of parameters associated with dependencies between pairs of words.
    The Czech PDT contains dependency annotations, but no tree structures.
    For parsing Czech we considered a strategy of converting dependency structures in training data to lexicalized trees, then running the parsing algorithms originally developed for English.
    A key point is that the mapping from lexicalized trees to dependency structures is many-to-one.
    