,000 tokens per second (including file I/O) on a Pentium 500 running Linux.
    The speed mainly depends on the percentage of unknown words and on the average ambiguity rate.
  
  
    We evaluate the tagger's performance under several aspects.
    First of all, we determine the tagging accuracy averaged over ten iterations.
    The overall accuracy, as well as separate accuracies for known and unknown words are measured.
    Second, learning curves are presented, that indicate the performance when using training corpora of different sizes, starting with as few as 1,000 tokens and ranging to the size of the entire corpus (minus the test set).
    An important characteristic of statistical taggers is that they not only assign tags to words but also probabilities in order to rank different assignments.
    We distinguish reliable from unreliable assignments by the quotient of the best and second best assignmentsl .
    All assignments for which this quotient is larger than some threshold are regarded as reliabl