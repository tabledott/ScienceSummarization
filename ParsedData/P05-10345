to a target sentence.
    As such, it does not use a target language model during decoding, relying instead on MLE channel probabilities and heuristics such as pattern size.
    Recently Aue et al. (04) incorporated an LF-based language model (LM) into the system for a small quality boost.
    A key disadvantage of this approach and related work (Ding &amp; Palmer, 02) is that it requires a parser in both languages, which severely limits the language pairs that can be addressed.
  
  
    In this paper we propose a novel dependency treebased approach to phrasal SMT which uses treebased &#8216;phrases&#8217; and a tree-based ordering model in combination with conventional SMT models to produce state-of-the-art translations.
    Our system employs a source-language dependency parser, a target language word segmentation component, and an unsupervised word alignment component to learn treelet translations from a parallel sentence-aligned corpus.
    We begin by parsing the source text to obtain dependency trees a