location-contains instances among our high-confidence results. human evaluation.
    Our sample size was 100.
    Each predicted relation instance was labeled as true or false by between 1 and 3 labelers on Mechanical Turk.
    We assigned the truth or falsehood of each relation according to the majority vote of the labels; in the case of a tie (one vote each way) we assigned the relation as true or false with equal probability.
    The evaluation of the syntactic, lexical, and combination of features at a recall of 100 and 1000 instances is presented in Table 5.
    At a recall of 100 instances, the combination of lexical and syntactic features has the best performance for a majority of the relations, while at a recall level of 1000 instances the results are mixed.
    No feature set strongly outperforms any of the others across all relations.
  
  
    Our results show that the distant supervision algorithm is able to extract high-precision patterns for a reasonably large number of relations.
    The held-o