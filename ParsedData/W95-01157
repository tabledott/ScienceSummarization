ds in the text that also appear in the lexicon.
    Measuring precision is much more difficult, because it is unclear what a &amp;quot;correct&amp;quot; lexicon entry is &#8212; different translations are appropriate for different contexts, and, in most cases, more than one translation is correct.
    This is why evaluation of translation has eluded automation efforts until now.
    The large number of quantitative lexicon evaluations required for the present study made it infeasible to rely on evaluation by human judges.
    The only existing automatic lexicon evaluation method that I am aware of is the perplexity comparisons used by Brown et al. in the framework of their Model 1 [Bro93].
    Lexicon perplexity indicates how &amp;quot;sure&amp;quot; a translation lexicon is about its contents.
    It does not, however, directly measure the quality of those contents.
    BiBLE is a family of algorithms, based on the observation that translation pair.s2 tend to appear in corresponding sentences in an aligned b