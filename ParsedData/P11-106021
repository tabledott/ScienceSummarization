e weights are zero, so the beam search is essentially unguided.
    We find that only for a small fraction of training examples do the K-best sets contain any trees yielding the correct answer (29% for DCS on GEO).
    However, training on just these examples is enough to improve the parameters, and this 29% increases to 66% and then to 95% over the next few iterations.
    This bootstrapping behavior occurs naturally: The &#8220;easy&#8221; examples are processed first, where easy is defined by the ability of the current model to generate the correct answer using any tree. with scope variation.
    Think of DCS as a higher-level Our system learns lexical associations between programming language tailored to natural language, words and predicates.
    For example, area (by virtue which results in programs (DCS trees) which are of being a noun) triggers many predicates: city, much simpler than the logically-equivalent lambda state, area, etc.
    Inspecting the final parameters calculus formulae.
    (DCS on G