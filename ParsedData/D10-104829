ion that incorporates documentlevel information, which is typically exploited only by more complex, joint learning models.
    Our sieve architecture applies a battery of deterministic coreference models one at a time from highest to lowest precision, where each model builds on the previous model&#8217;s cluster output.
    Despite its simplicity, our approach outperforms or performs comparably to the state of the art on several corpora.
    An additional benefit of the sieve framework is its modularity: new features or models can be inserted in the system with limited understanding of the other features already deployed.
    Our code is publicly released5 and can be used both as a stand-alone coreference system and as a platform for the development of future systems.
    The strong performance of our system suggests the use of sieves in other NLP tasks for which a variety of very high-precision features can be designed and non-local features can be shared; likely candidates include relation and event extract