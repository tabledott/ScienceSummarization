ent sections we examine several disambiguation algorithms.
    Their techniques, accuracies, and efficiencies are analyzed.
    After presenting the research carried out to date, a discussion of VOLSUNGA' s application to the Brown Corpus will follow.
    The Brown Corpus, described in Kucera and Francis (1967), is a collection of 500 carefully distributed samples of English text, totalling just over one million words.
    It has been used as a standard sample in many studies of English.
    Generous advice, encouragement, and assistance from Henry Kucera and W. Nelson Francis in this research is gratefully acknowledged.
  
  
    The problem of lexical category ambiguity has been little examined in the literature of computational linguistics and artificial intelligence, though it pervades English to an astonishing degree.
    About 11.5% of types (vocabulary), and over 40% of tokens (running words) in English prose are categorically ambiguous (as measured via the Brown Corpus).
    The vocabulary breaks down