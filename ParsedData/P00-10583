, which is built out of elementary trees and is interpreted as encoding constituency, but a derivation tree, which records how the various elementary trees were combined together and is commonly intepreted as encoding dependency.
    The ability of probabilistic LTAG to model bilexical dependencies was noted early on by (Resnik, 1992).
    It turns out that there are other pieces of contextual information that need to be explicitly accounted for in a CFG by grammar transformations but come for free in a TAG.
    We discuss a few such cases in Section 3.
    In Sections 4 and 5 we describe an experiment to test the parsing accuracy of a probabilistic TAG extracted automatically from the Penn Treebank.
    We find that the automatically-extracted grammar gives an improvement over the EM-based induction method of (Hwa, 1998), and that the parser performs comparably to lexicalized PCFG parsers, though certainly with room for improvement.
    We emphasize that TAG is attractive not because it can do things that CF