!$# . One common way to avoid such situations is to compare + u ) values and to choose the class index v of the largest + u ) . The consistency problem is solved by the Viterbi search.
			Since SVMs do not output probabilities, we use the SVM+sigmoid method (Platt, 2000).
			That is, we use a sigmoid function wxG? J*y#zI#{!
			|l}~ {G to map + u ) to a probability-like value.
			The output of the Viterbi search is adjusted by a postprocessor for wrong word boundaries.
			The adjustment rules are also statistically determined (Isozaki, 2001).
			1.3 Comparison of NE recognizers.
			We use a fixed value ?* #Q9Q . F-measures are not very sensitive to  unless  is too small.
			Whenwe used 1,038,986 training vectors, GENERAL?s F measure was 89.64% for ?*?Q?# and 90.03% for 6*?#Q9Q . We employ the quadratic kernel ( F *Y? ) because it gives the best results.
			Polynomial kernels of degree 1, 2, and 3 resulted in 83.03%, 88.31%, F-measure (%) ? ?
			RG+DT ? ?
			ME ? ?
			SVM 0 20 40 60 80 100 120 CRL data ??