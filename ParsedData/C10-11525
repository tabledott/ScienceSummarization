ildren and adults who are learning English lan guage?.
			The authors are requested to ?use easy words and short sentences?
			to compose articles.
			We processed the dataset as follows: Article Pairing 65,133 articles from SimpleWikipedia3 and Wikipedia4 were paired by fol lowing the ?language link?
			using the dump filesin Wikimedia.5 Administration articles were fur ther removed.
			Plain Text Extraction We use JWPL (Zesch etal., 2008) to extract plain texts from Wikipedia ar ticles by removing specific Wiki tags.
			Pre-processing including sentence boundary detection and tokenization with the Stanford 1http://simple.wikipedia.org 2http://en.wikipedia.org 3As of Aug 17th, 2009 4As of Aug 22nd, 2009 5http://download.wikimedia.org Parser package (Klein and Manning, 2003), and lemmatization with the TreeTagger (Schmid, 1994).
			Monolingual Sentence Alignment As we need a parallel dataset algned at the sentence level,we further applied monolingual sentence align ment on the article pairs.
			In order to ac