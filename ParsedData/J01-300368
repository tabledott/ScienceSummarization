ibution of a feature to classification is not predictable from the apparent discriminability of its numeric values across the classes.
    This observation emphasizes the importance of an experimental method to evaluating our approach to verb classification.
  
  
    In order to evaluate the performance of the algorithm in practice, we need to compare it to the accuracy of classification performed by an expert, which gives a realistic upper bound for the task.
    The lively theoretical debate on class membership of verbs, and the complex nature of the linguistic information necessary to accomplish this task, led us to believe that the task is difficult and not likely to be performed at 100% accuracy even by experts, and is also likely to show differences in classification between experts.
    We report here the results of two experiments which measure expert accuracy in classifying our verbs (compared to Levin's classification as the gold standard), as well as inter-expert agreement.
    (See also Merlo and