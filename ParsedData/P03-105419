h higher than community wisdom has thought possible.
    We describe several simple, linguistically motivated annotations which do much to close the gap between a vanilla PCFG and state-of-the-art lexicalized models.
    Specifically, we construct an unlexicalized PCFG which outperforms the lexicalized PCFGs of Magerman (1995) and Collins (1996) (though not more recent models, such as Charniak (1997) or Collins (1999)).
    One benefit of this result is a much-strengthened lower bound on the capacity of an unlexicalized PCFG.
    To the extent that no such strong baseline has been provided, the community has tended to greatly overestimate the beneficial effect of lexicalization in probabilistic parsing, rather than looking critically at where lexicalized probabilities are both needed to make the right decision and available in the training data.
    Secondly, this result affirms the value of linguistic analysis for feature discovery.
    The result has other uses and advantages: an unlexicalized PCFG is easie