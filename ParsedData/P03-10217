escent methods to perform optimization.
    The objective function has many different local optima.
    The optimization algorithm must handle this.
    In addition, even if we manage to solve the optimization problem, we might face the problem of overfitting the training data.
    In Section 5, we describe an efficient optimization algorithm.
    To be able to compute a gradient and to make the objective function smoother, we can use the following error criterion which is essentially a smoothed error count, with a parameter to adjust the smoothness: In the following, we assume that we can measure the number of errors in sentence by comparing it with a reference sentenceusing a function E .
    However, the following exposition can be easily adapted to accuracy metrics and to metrics that make use of multiple references.
    We assume that the number of errors for a set of sentences is obtained by summing the errors for the individual sentences: .
    Our goal is to obtain a minimal error count on a represent