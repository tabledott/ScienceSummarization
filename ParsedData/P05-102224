al. (2002) is just the negative log conditional likelihood of the best parses Y+(s) relative to the n-best parser output Y(s): The partial derivatives of this loss function, which are required by the numerical estimation procedure, are: In the experiments reported here, we used a Gaussian or quadratic regularizer R(w) = cPmj=1 w2j, where c is an adjustable parameter that controls the amount of regularization, chosen to optimize the reranker&#8217;s f-score on the development set (section 24 of the treebank).
    We used the Limited Memory Variable Metric optimization algorithm from the PETSc/TAO optimization toolkit (Benson et al., 2004) to find the optimal feature weights &#952;&#710; because this method seems substantially faster than comparable methods (Malouf, 2002).
    The PETSc/TAO toolkit provides a variety of other optimization algorithms and flags for controlling convergence, but preliminary experiments on the Collins&#8217; trees with different algorithms and early stopping did not show any perform