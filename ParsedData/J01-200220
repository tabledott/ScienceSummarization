selected by parameters of the system.
    For the Tags version, the similarity metric used is Overlap (a count of the number of matching feature values between a test and a training item) and k is kept at 1.
    For the other two versions (Tags+Word and Tags+Context), a value of k = 3 is used, and each overlapping feature is weighted by its Information Gain (Daelemans, Van den Bosch, and Weijters 1997).
    The Information Gain of a feature is defined as the difference between the entropy of the a priori class distribution and the conditional entropy of the classes given the value of the feature.'
    The second machine learning method, maximum entropy modeling, implemented in the Maccent system (Dehaspe 1997), does the classification task by selecting the most probable class given a maximum entropy mode1.6 This type of model represents examples of the task (Cases) as sets of binary indicator features, for the task at hand conjunctions of a particular tag and a particular set of feature values.
    The model 