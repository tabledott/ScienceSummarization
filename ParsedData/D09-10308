-item basis.
    Figure 1 shows that these weighting mechanisms perform similarly well.
    For this task, deriving weights from agreement with other non-experts is as effective as deriving weights from experts.
    Moreover, by weighting the votes of five Turkers, non-expert judgments perform at the upper bound of expert-expert correlation.
    All correlate more strongly than Bleu. we are able to achieve the same rate of agreement with experts as they achieve with each other.
    Correlation when ranking systems In addition to measuring agreement with experts at the sentence-level, we also compare non-expert system-level rankings with experts.
    Following Callison-Burch et al. (2008), we assigned a score to each of the 11 MT systems based on how often its translations were judged to be better than or equal to any other system.
    These scores were used to rank systems and we measured Spearman&#8217;s &#961; against the system-level ranking produced by experts.
    Figure 3 shows how well the non-expert r