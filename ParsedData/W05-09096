 measure for the level of grammaticality (or word order) can better account for the importance of grammaticality as a factor in the MT metric, and result in better correlation with human judgments of translation quality* Lack of Explicit Word-matching Between Translation and Reference: N-gram counts don't require an explicit word-to-word matching, but this can result in counting incorrect &amp;quot;matches&amp;quot;, particularly for common function words* Use of Geometric Averaging of N-grams: Geometric averaging results in a score of &amp;quot;zero&amp;quot; whenever one of the component n-gram scores is zero* Consequently, BLEU scores at the sentence (or segment) level can be meaningless* Although BLEU was intended to be used only for aggregate counts over an entire test-set (and not at the sentence level), scores at the sentence level can be useful indicators of the quality of the metric* In experiments we conducted, a modified version of BLEU that uses equal-weight arithmetic averaging of n-gram scores w