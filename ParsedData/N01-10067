action of the possible rules are randomly selected for estimation at each iteration.
    The &#181;-TBL system described in Lager (1999) attempts to cut down on training time with a more efficient Prolog implementation and an implementation of &amp;quot;lazy&amp;quot; learning.
    The application of a transformation-based learning can be considerably sped-up if the rules are compiled in a finite-state transducer, as described in Roche and Schabes (1995).
  
  
    The approach presented here builds on the same foundation as the one in (Ramshaw and Marcus, 1994): instead of regenerating the rules each time, they are stored into memory, together with the two values good (r) and bad (r).
    The following notations will be used throughout this section: t, and t, = T[s]g the samples on which the rule applies and changes them to the correct classification; therefore, good(r) = jG(r)j. t, and C[s] = T [s]g the samples on which the rule applies and changes the classification from correct to incorrect; similarly, ba