ondition in Nivre and Nilsson (2005).
    Feature models.
    Rows represent tokens defined relative to the current configuration (L[i] = ith element of list/stack L of length n; hd(x) = head of x; ld(x) = leftmost dependent of x; rd(x) = rightmost dependent of x).
    Columns represent attributes of tokens (Form = word form; Lem = lemma; CPoS = coarse part-of-speech; FPoS = fine part-of-speech; Feats = morphosyntactic features; Dep = dependency label).
    Filled cells represent features used by one or more algorithms (All = all algorithms; S = arc-standard, stack-based; E = arc-eager, stack-based; N = non-projective, list-based; P = projective, list-based).
    All parsers were trained using the freely available MaltParser system,6 which provides implementations of all the algorithms described in Sections 4 and 5.
    MaltParser also incorporates the LIBSVM library for support vector machines (Chang and Lin 2001), which was used to train classifiers for predicting the next transition.
    Training data for 