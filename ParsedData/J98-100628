g by using monosemous words and collocations&#8212;on the assumption that, if a word has only one sense in WordNet, it is monosemous.
    Schtitze (1995) developed a statistical topical approach to word sense identification that provides its own automatically extracted training examples.
    For each occurrence t of a polysemous word in a corpus, a context vector is constructed by summing all the vectors that represent the co-occurrence patterns of the open-class words in t's context (i.e., topical information is expressed as a kind of second-order co-occurrence).
    These context vectors are clustered, and the centroid of each cluster is used to represent a &amp;quot;sense.&amp;quot; When given a new occurrence of the word, a vector of the words in its context is constructed, and this vector is compared to the sense representations to find the closest match.
    Schulze has used the method to disambiguate pseudowords, homographs, and polysemous words.
    Performance varies depending, in part, on the number