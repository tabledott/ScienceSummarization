10,000word corpus of common English spelling errors, paired with their correct spelling.
    We used 80% of this corpus for training and 20% for evaluation.
    Our dictionary contained approximately 200,000 entries, including all words in the test set.
    The results in this section are obtained with a language model that assigns uniform probability to all words in the dictionary.
    In Table 1 we show K-best results for different maximum context window sizes, without using positional information.
    For instance, the 2-best accuracy is the percentage of time the correct answer is one of the top two answers returned by the system.
    Note that a maximum window of zero corresponds to the set of single character insertion, deletion and substitution edits, weighted with their probabilities.
    We see that, up to a point, additional context provides us with more accurate spelling correction and beyond that, additional context neither helps nor hurts.
    In Table 1, the row labelled CG shows the results whe