few exceptions such as these &amp;quot;garden paths,&amp;quot; Marcus assumes, there is almost always a unique &amp;quot;best&amp;quot; interpretation which Can be found with very limited resources.
    The proposed stochastic approach is largely compatible with this; the proposed approach 1.
    From an information theory point of view, one can quantity ambiguity in bits.
    In the case of the Brown Tagged Corpus, the lexical entropy, the conditional entropy of the part of speech given the word is about 0.25 bits per part of speech.
    This is considerably smaller than the contextual entropy, the conditional entropy of the part of speech given the next two parts of speech.
    This entropy is estimated to be about 2 bits per part of speech. assumes that it is almost always sufficient to assign each word a unique &amp;quot;best&amp;quot; part of speech (and this can be accomplished with a very efficient linear time dynamic programming algorithm).
    After reading introductory discussions of &amp;quot;Flyin