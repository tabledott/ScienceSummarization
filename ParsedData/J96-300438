 flu, the Good-Turing estimate just discussed gives us an estimate of p(unseen(111) I 1)&#8212;the probability of observing a previously unseen instance of a construction in ft given that we know that we have a construction in ft This GoodTuring estimate of p(unseen(#9) In can then be used in the normal way to define the probability of finding a novel instance of a construction in flu in a text: p(unseen(111)) = p(unseen(f1) Ifl) p(H).
    Here p(1V1) is just the probability of any construction in IT as estimated from the frequency of such constructions in the corpus.
    Finally, assuming a simple bigram backoff model, we can derive the probability estimate for the particular unseen word Malt as the product of the probability estimate for mEI, and the probability estimate just derived for unseen plurals in p(tIfifi) p(*)1)p(unseen(111)).
    The cost estimate, cost(t)71 fl), is computed in the obvious way by summing the negative log probabilities of ma and fi.
    Figure 5 shows how this model is implemented