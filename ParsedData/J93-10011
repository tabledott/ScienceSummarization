ky and Papert 1969).
    Perhaps the most immediate reason for this empirical renaissance is the availability of massive quantities of data: more text is available than ever before.
    Just ten years ago, the one-million word Brown Corpus (Francis and Ku'&amp;ra, 1982) was considered large, but even then, there were much larger corpora such as the Birmingham Corpus (Sinclair et al. 1987; Sinclair 1987).
    Today, many locations have samples of text running into the hundreds of millions or even billions of words.
    Collections of this magnitude are becoming widely available, thanks to data collection efforts such as the Association for Computational Linguistics' Data Collection Initiative (ACL/DCI), the European Corpus Initiative (ECI), ICAME, the British National Corpus (BNC), the Linguistic Data Consortium (LDC), the Consortium for Lexical Research (CLR), Electronic Dictionary Research (EDR), and standardization efforts such as the Text Encoding Initiative (TED.'
    The data-intensive approach to langua