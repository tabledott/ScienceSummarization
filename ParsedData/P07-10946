t where P(w|0) = &amp; P(w, t|0).
    Sometimes, a non-uniform prior distribution over 0 is introduced, in which case 0&#65533; is the maximum a posteriori (MAP) solution for 0: The values of the latent variables are then taken to be those that maximize P(t|w, &#65533;0).
    In contrast, the Bayesian approach we advocate in this paper seeks to identify a distribution over latent variables directly, without ever fixing particular values for the model parameters.
    The distribution over latent variables given the observed data is obtained by integrating over all possible values of 0: This distribution can be used in various ways, including choosing the MAP assignment to the latent variables, or estimating expected values for them.
    To see why integrating over possible parameter values can be useful when inducing latent structure, consider the following example.
    We are given a coin, which may be biased (t = 1) or fair (t = 0), each with probability .5.
    Let 0 be the probability of heads.
    If the 