robability estimates computed from single derivations, and demonstrate that it is critical to account for many derivations for each sentence pair.
			We also usereal examples to show that our probability mod els estimated from a large number of derivations favor phrasal re-orderings that are linguistically well motivated.
			An empirical evaluation against a state-of-the-art SMT system similar to (Och and Ney, 2004) indicates positive prospects.
			Finally, we show that our contextually richer rules provide a 3.63 BLEU point increase over those of (Galley et al, 2004).
	
	
			We assume we are given a source-language (e.g.,French) sentence f , a target-language (e.g., En glish) parse tree pi, whose yield e is a translation of f , and a word alignment a between f and e.Our aim is to gain insight into the process of transforming pi into f and to discover grammatically grounded translation rules.
			For this, we need a formalism that is expressive enough to deal with cases of syntactic divergence between source a