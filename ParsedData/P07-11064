rtance of word-based features for CWS.
    Furtherfor decoding. more, our approach provides an example of the poSeveral discriminatively trained models have re- tential of search-based discriminative training methcently been applied to the CWS problem.
    Exam- ods for NLP tasks.
    ples include Xue (2003), Peng et al. (2004) and Shi 2 The Perceptron Training Algorithm and Wang (2007); these use maximum entropy (ME) We formulate the CWS problem as finding a mapping and conditional random field (CRF) models (Ratna- from an input sentence x E X to an output sentence parkhi, 1998; Lafferty et al., 2001).
    An advantage y E Y , where X is the set of possible raw sentences of these models is their flexibility in allowing knowl- and Y is the set of possible segmented sentences. edge from various sources to be encoded as features.
    Given an input sentence x, the correct output segContextual information plays an important role in mentation F(x) satisfies: word segmentation decisions; especially useful is in- F