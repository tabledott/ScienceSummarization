w ways: (1) direction (forward or backward); (2) learner (MaxEnt or SVM); and (3) search strategy (best-first or deterministic).
			Of those differences, the first one is particularly inter esting in single-stack shift-reduce models, as ours.
			In these models, the context to each side of a (po tential) dependency differs in a fundamental way.
			To one side, we have tokens that have already been processed and are already in subtrees, and to the other side we simply have a look-ahead of the re maining input sentence.
			This way, the context of the same dependency in a forward parser may differ significantly from the context of the same de pendency in a backward parser.
			Interestingly, the accuracy scores of the MaxEnt backward models were found to be generally just below the accuracy of their corresponding forward models when tested on development data, with two exceptions: Hunga rian and Turkish.
			In Hungarian, the accuracy scores produced by the forward and backward MaxEnt LR models were not significa