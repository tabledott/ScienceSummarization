 given).
    The method we used to retrieve Web counts is based on very simple heuristics; it is thus inevitable that the counts generated will contain a certain amount of noise.
    In this section we discuss a number of potential sources of such noise.
    An obvious limitation of our method is that it relies on the page counts returned by the search engines; we do not download the pages themselves for further processing.
    Note that many of the bigrams in our sample are very frequent (up to 106 matches; see the &#8220;Max&#8221; columns in Table 6), hence the effort involved in downloading all pages would be immense (though methods for downloading a representative sample could probably be devised).
    Our approach estimates Web frequencies based not on bigram counts directly, but on page counts.
    In other words, it ignores the fact that a bigram can occur more than once on a given Web page.
    This approximation is justified, as Zhu and Rosenfeld (2001) demonstrated for unigrams, bigrams, and trigra