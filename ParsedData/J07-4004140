, by taking the lexical categories chosen by the parser as gold-standard training data.
    If enough unlabeled data is parsed, then the large volume can overcome the noise in the data (Steedman et al. 2002; Prins and van Noord 2003).
    We plan to investigate this idea in the context of our own parsing system.
  
  
    This article has shown how to estimate a log-linear parsing model for an automatically extracted CCG grammar, on a very large scale.
    The techniques that we have developed, including the use of a supertagger to limit the size of the charts and the use of parallel estimation, could be applied to log-linear parsing models using other grammar formalisms.
    Despite memory requirements of up to 25 GB we have shown how a parallelized version of the estimation process can limit the estimation time to under three hours, resulting in a practical framework for parser development.
    One of the problems with modeling approaches which require very long estimation times is that it is difficult to t