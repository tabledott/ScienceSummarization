hat the large majority of cases of disagreement were due to negligence on behalf of one or other of the annotators (i.e. cases of clear hedging that were missed), and that the cases of genuine disagreement were actually quite rare.
    New labelings were then created with the negligent disagreements corrected, resulting in significantly higher agreement scores.
    Values for the original and negligence-corrected labelings are reported in Table 1.
    Annotator conferral violates the fundamental assumption of annotator independence, and so the latter agreement scores do not represent the true level of agreement; however, it is reasonable to conclude that the actual agreement is approximately lower bounded by the initial values and upper bounded by the latter values.
    In fact even the lower bound is well within the range usually accepted as representing &#8216;good&#8217; agreement, and thus we are confident in accepting human labeling as a gold-standard for the hedge classification task.
    For our experi