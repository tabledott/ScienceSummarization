es.
    It is better able to use diverse information than Markov Models, requires less supporting techniques than SDT, and unlike TBL, can be used in a probabilistic framework.
    However, the POS tagging accuracy on the Penn Wall St. Journal corpus is roughly the same for all these modelling techniques.
    The convergence of the accuracy rate implies that either all these techniques are missing the right predictors in their representation to get the &amp;quot;residue&amp;quot;, or more likely, that any corpus based algorithm on the Penn Treebank Wall St. Journal corpus will not perform much higher than 96.5% due to consistency problems.
  
  
    The Maximum Entropy model is an extremely flexible technique for linguistic modelling, since it can use a virtually unrestricted and rich feature set in the framework of a probability model.
    The implementation in this paper is a state-of-the-art POS tagger, as evidenced by the 96.6% accuracy on the unseen Test set, shown in Table 11.
    The model with special