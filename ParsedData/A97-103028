other, where there was sufficient evidence, such as Mr. Hills, to make a firmer decision.
  
  
    An evaluation of an earlier version of Nominator, was performed on 88 Wall Street Journal documents (NIST 1993) that had been set aside for testing.
    We chose the Wall Street Journal corpus because it follows standard stylistic conventions, especially capitalization, which is essential for Nominator to work.
    Nominator's performance deteriorates if other conventions are not consistently followed.
    A linguist manually identified 2426 occurrences of proper names, which reduced to 1354 unique tokens.
    Of these, Nominator correctly identified the boundaries of 91% (1230/1354).
    The precision rate was 92% for the 1409 names Nominator identified (1230/1409).
    In terms of semantic disambiguation, Nominator failed to assign an entity type to 21% of the names it identified.
    This high percentage is due to a decision not to assign a type if the confidence measure is too low.
    The payoff of this ch