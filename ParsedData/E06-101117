uctured outputs Collins (2002).
    Online learning algorithms have been shown to be robust even with approximate rather than exact inference in problems such as word alignment (Moore, 2005), sequence analysis (Daum&#180;e and Marcu, 2005; McDonald et al., 2005a) and phrase-structure parsing (Collins and Roark, 2004).
    This robustness to approximations comes from the fact that the online framework sets weights with respect to inference.
    In other words, the learning method sees common errors due to where y' = arg maxy, s(xt, y'; w(i)) approximate inference and adjusts weights to correct for them.
    The work of Daum&#180;e and Marcu (2005) formalizes this intuition by presenting an online learning framework in which parameter updates are made directly with respect to errors in the inference algorithm.
    We show in the next section that this robustness extends to approximate dependency parsing.
  
  
    The score of adjacent edges relies on the definition of a feature representation f(i, k, j).
    A