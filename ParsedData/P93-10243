ation tendencies into associations of words to certain hidden senses classes and associations between the classes themselves.
    While it may be worth basing such a model on preexisting sense classes (Resnik, 1992), in the work described here we look at how to derive the classes directly from distributional data.
    More specifically, we model senses as probabilistic concepts or clusters c with corresponding cluster membership probabilities p(clw) for each word w. Most other class-based modeling techniques for natural language rely instead on &amp;quot;hard&amp;quot; Boolean classes (Brown et al., 1990).
    Class construction is then combinatorially very demanding and depends on frequency counts for joint events involving particular words, a potentially unreliable source of information as noted above.
    Our approach avoids both problems.
    In what follows, we will consider two major word classes, V and N., for the verbs and nouns in our experiments, and a single relation between them, in our experiment