e estimated after translating in-domain texts with the baseline.
    By optimizing the interpolation of these models on a development set the BLEU score was improved from 22.60% to 28.10% on a test set.
  
  
    A well-known problem of Statistical Machine Translation (SMT) is that performance quickly degrades as soon as testing conditions deviate from training conditions.
    The very simple reason is that the underlying statistical models always tend to closely approximate the empirical distributions of the training data, which typically consist of bilingual texts and monolingual target-language texts.
    The former provide a means to learn likely translations pairs, the latter to form correct sentences with translated words.
    Besides the general difficulties of language translation, which we do not consider here, there are two aspects that make machine learning of this task particularly hard.
    First, human language has intrinsically very sparse statistics at the surface level, hence gaining complete