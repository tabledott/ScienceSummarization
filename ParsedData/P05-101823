nce was assessed in the same way for information ordering and summary evaluation.
    Given a set of pairwise rankings, we measure accuracy as the ratio of correct predictions made by the model over the size of the test set.
    In this setup, random prediction results in an accuracy of 50%.
  
  
    The evaluation of our coherence model was driven by two questions: (1) How does the proposed model compare to existing methods for coherence assessment that make use of distinct representations?
    (2) What is the contribution of linguistic knowledge to the model&#8217;s performance?
    Table 4 summarizes the accuracy of various configurations of our model for the ordering and coherence assessment tasks.
    We first compared a linguistically rich grid model that incorporates coreference resolution, expressive syntactic information, and a salience-based feature space (Coreference+Syntax+Salience) against the LSA baseline (LSA).
    As can be seen in Table 4, the grid model outperforms the baseline in both orde