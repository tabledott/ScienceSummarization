-short translations.
    BLEU is an accuracy measure, while the others are error measures. m-WER (multireference word error rate): For each test sentence there is a set of reference translations.
    For each translation hypothesis, the edit distance (number of substitutions, deletions, and insertions) to the most similar reference is calculated.
    SSER (subjective sentence error rate): Each translated sentence is judged by a human examiner according to an error scale from 0.0 (semantically and syntactically correct) to 1.0 (completely wrong).
    ISER (information item semantic error rate): The test sentences are segmented into information items; for each of these items, the translation candidates are assigned either &#8220;OK&#8221; or an error class.
    If the intended information is conveyed, the translation of an information item is considered correct, even if there are slight syntactic errors which do not seriously deteriorate the intelligibility.
    For evaluating the SSER and the ISER, we have use