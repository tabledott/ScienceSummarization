E effort between the top-quality quantiles and the overall quality is 0.95 on average.
    We would like to emphasize here that the DeltaAvg metric does not have any a-priori range for its values.
    The upperbound, for instance, is test-dependent, and therefore an &#8220;Oracle Effort&#8221; score is useful for understanding the performance level of real systemsubmissions.
    The &#8220;Oracle HTER&#8221; DeltaAvg score of 0.77 is a more realistic upperbound for the current set.
    Since the HTER metric is considered a good approximation for the effort required in postediting, ranking the test set based on the HTER scores (from lowest HTER to highest HTER) provides a good oracle comparison point.
    The oracle based on (H)BLEU gives a lower DeltaAvg score, which can be interpreted to mean that the BLEU metric provides a lower correlation to post-editing effort compared to HTER.
    We also note here that there is room for improvement between the highestscoring submission (at DeltaAvg 0.63) and the &#8220