ility of inter-reviewer agreement expected by chance, 0.97.0.97+ (1 &#8212;0.97)- (1-0.97) --- 0.9418, by referring to the kappa statistic [Cohen 1960; Carletta 1996].
    The kappa statistic is defined as where PA is the probability that two reviewers agree in practice, and Po is the probability that they would agree solely by chance.
    In our case, PA = 0.976, Po = 0.9418, and K = 0.5876, indicating that the observed agreement by the reviewers is indeed significant.2 If Po is estimated from the particular sample used in this experiment rather than from our entire corpus, it would be only 0.9, producing a value of 0.76 for K. In addition to this validation experiment that used randomly sampled pairs of paragraphs (and reflected the disproportionate rate of occurrence of dissimilar pairs), we performed a balanced experiment by randomly selecting 50 of the dissimilar pairs and 50 of the similar pairs, in a manner that guaranteed generation of an independent sample.3 Pairs in this subset were rated for simila